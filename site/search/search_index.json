{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to SYMaterials","text":"<p>Get Second Year Notes, Question Bank Solutions, etc for GHRCEM Pune. </p> <p>Only Computer Department notes, if anyone from any other department is interested to share their notes feel free to contact me. Also visit Tymaterials for Third Year Notes</p>"},{"location":"#subjects","title":"Subjects","text":"<ul> <li>First Sem:     Comming Soon</li> <li>Second Sem:<ul> <li>Apllication of Microprocessor and Microcontroller</li> <li>Computer Network</li> <li>Design and Analysis of Algorithm</li> <li>Operating System</li> <li>Transform Numerical Method</li> </ul> </li> </ul>"},{"location":"#about","title":"About","text":"<p>This project is just a reference from multiple educational sites geared towards syllabus from GHRCEM. The Website has Notes, Question Bank Solutions, Lab Manuals, Teacher's digital notes from Classroom, etc. The notes are created/extracted :skull: from sites such as geeksforgeeks, javatpoint, tutorialspoint, etc.</p> <p>Created by Vishal Pise</p>"},{"location":"AMM/","title":"APPLLICATION OF MICROPROCESSOR AND MICROCONTROLLER","text":"Unit Topic Duration Unit I Introduction 8 Microprocessor Technology: 8085/8086- architectural overview &amp; Programming model Unit II Microcontrollers 8 Introduction to microcontrollers, 8051 architecture, data types and directives, flag bits and PSW register, register bank and stack Unit III Assembly Language Programming 8 Jump, Loop and Call Instructions, I/O Port Programming, Addressing modes, Arithmetic, Logic instructions and programs, data types and time delay. Interfacing to External Memory Unit IV Programming 6 Programming: Timer/counter, Interrupts and serial communications, Serial I/O, Programming Tools, Program using C. Interfacing with 8051: ADC and DAC interfaces for microcontrollers, Real time interfacing with LED, Keypad, LCD display, Sensors interfacing Unit V Arduino 6 Introduction to Arduino, Pin configuration and architecture, coding of Ardunio using IDE. Interfacings"},{"location":"AMM/CAE-2_Question_Bank/","title":"COMING SOON!","text":""},{"location":"AMM/UNIT_1/","title":"Microprocessor","text":""},{"location":"AMM/UNIT_1/#microprocessor-8085-architecture","title":"Microprocessor-8085 Architecture","text":"<p>8085 is pronounced as \"eighty-eighty-five\" microprocessor. It is an 8-bit microprocessor designed by Intel in 1977 using NMOS technology.</p> <p>It has the following configuration \u2212</p> <ul> <li>8-bit data bus</li> <li>16-bit address bus, which can address upto 64KB</li> <li>A 16-bit program counter</li> <li>A 16-bit stack pointer</li> <li>Six 8-bit registers arranged in pairs: BC, DE, HL</li> <li>Requires +5V supply to operate at 3.2 MHZ single phase clock</li> </ul> <p>It is used in washing machines, microwave ovens, mobile phones, etc.</p>"},{"location":"AMM/UNIT_1/#8085-microprocessor-functional-units","title":"8085 Microprocessor \u2013 Functional Units","text":"<p>8085 consists of the following functional units \u2212</p>"},{"location":"AMM/UNIT_1/#accumulator","title":"Accumulator","text":"<p>It is an 8-bit register used to perform arithmetic, logical, I/O &amp; LOAD/STORE operations. It is connected to internal data bus &amp; ALU.</p>"},{"location":"AMM/UNIT_1/#arithmetic-and-logic-unit","title":"Arithmetic and logic unit","text":"<p>As the name suggests, it performs arithmetic and logical operations like Addition, Subtraction, AND, OR, etc. on 8-bit data.</p>"},{"location":"AMM/UNIT_1/#general-purpose-register","title":"General purpose register","text":"<p>There are 6 general purpose registers in 8085 processor, i.e. B, C, D, E, H &amp; L. Each register can hold 8-bit data.</p> <p>These registers can work in pair to hold 16-bit data and their pairing combination is like B-C, D-E &amp; H-L.</p>"},{"location":"AMM/UNIT_1/#program-counter","title":"Program counter","text":"<p>It is a 16-bit register used to store the memory address location of the next instruction to be executed. Microprocessor increments the program whenever an instruction is being executed, so that the program counter points to the memory address of the next instruction that is going to be executed.</p>"},{"location":"AMM/UNIT_1/#stack-pointer","title":"Stack pointer","text":"<p>It is also a 16-bit register works like stack, which is always incremented/decremented by 2 during push &amp; pop operations.</p>"},{"location":"AMM/UNIT_1/#temporary-register","title":"Temporary register","text":"<p>It is an 8-bit register, which holds the temporary data of arithmetic and logical operations.</p>"},{"location":"AMM/UNIT_1/#flag-register","title":"Flag register","text":"<p>It is an 8-bit register having five 1-bit flip-flops, which holds either 0 or 1 depending upon the result stored in the accumulator.</p> <p>These are the set of 5 flip-flops \u2212</p> <ul> <li>Sign (S)</li> <li>Zero (Z)</li> <li>Auxiliary Carry (AC)</li> <li>Parity (P)</li> <li>Carry (C)</li> </ul> <p>Its bit position is shown in the following table \u2212</p> D7 D6 D5 D4 D3 D2 D1 D0 S Z AC P CY #### Instruction register and decoder <p>It is an 8-bit register. When an instruction is fetched from memory then it is stored in the Instruction register. Instruction decoder decodes the information present in the Instruction register.</p>"},{"location":"AMM/UNIT_1/#timing-and-control-unit","title":"Timing and control unit","text":"<p>It provides timing and control signal to the microprocessor to perform operations. Following are the timing and control signals, which control external and internal circuits \u2212</p> <ul> <li>Control Signals: READY, RD\u2019, WR\u2019, ALE</li> <li>Status Signals: S0, S1, IO/M\u2019</li> <li>DMA Signals: HOLD, HLDA</li> <li>RESET Signals: RESET IN, RESET OUT</li> </ul>"},{"location":"AMM/UNIT_1/#interrupt-control","title":"Interrupt control","text":"<p>As the name suggests it controls the interrupts during a process. When a microprocessor is executing a main program and whenever an interrupt occurs, the microprocessor shifts the control from the main program to process the incoming request. After the request is completed, the control goes back to the main program.</p> <p>There are 5 interrupt signals in 8085 microprocessor: INTR, RST 7.5, RST 6.5, RST 5.5, TRAP.</p>"},{"location":"AMM/UNIT_1/#serial-inputoutput-control","title":"Serial Input/output control","text":"<p>It controls the serial data communication by using these two instructions: SID (Serial input data) and SOD (Serial output data).</p>"},{"location":"AMM/UNIT_1/#address-buffer-and-address-data-buffer","title":"Address buffer and address-data buffer","text":"<p>The content stored in the stack pointer and program counter is loaded into the address buffer and address-data buffer to communicate with the CPU. The memory and I/O chips are connected to these buses; the CPU can exchange the desired data with the memory and I/O chips.</p>"},{"location":"AMM/UNIT_1/#address-bus-and-data-bus","title":"Address bus and data bus","text":"<p>Data bus carries the data to be stored. It is bidirectional, whereas address bus carries the location to where it should be stored and it is unidirectional. It is used to transfer the data &amp; Address I/O devices.</p> <ul> <li>is Who</li> </ul>"},{"location":"AMM/UNIT_1/#microprocessor-8086-overview","title":"Microprocessor - 8086 Overview","text":"<p>8086 Microprocessor is an enhanced version of 8085Microprocessor that was designed by Intel in 1976. It is a 16-bit Microprocessor having 20 address lines and16 data lines that provides up to 1MB storage. It consists of powerful instruction set, which provides operations like multiplication and division easily.</p> <p>It supports two modes of operation, i.e. Maximum mode and Minimum mode. Maximum mode is suitable for system having multiple processors and Minimum mode is suitable for system having a single processor.</p>"},{"location":"AMM/UNIT_1/#features-of-8086","title":"Features of 8086","text":"<p>The most prominent features of a 8086 microprocessor are as follows \u2212</p> <ul> <li> <p>It has an instruction queue, which is capable of storing six instruction bytes from the memory resulting in faster processing.</p> </li> <li> <p>It was the first 16-bit processor having 16-bit ALU, 16-bit registers, internal data bus, and 16-bit external data bus resulting in faster processing.</p> </li> <li> <p>It is available in 3 versions based on the frequency of operation \u2212</p> <ul> <li> <p>8086 \u2192 5MHz</p> </li> <li> <p>8086-2 \u2192 8MHz</p> </li> <li> <p>(c)8086-1 \u2192 10 MHz</p> </li> </ul> </li> <li> <p>It uses two stages of pipelining, i.e. Fetch Stage and Execute Stage, which improves performance.</p> </li> <li> <p>Fetch stage can prefetch up to 6 bytes of instructions and stores them in the queue.</p> </li> <li> <p>Execute stage executes these instructions.</p> </li> <li> <p>It has 256 vectored interrupts.</p> </li> <li> <p>It consists of 29,000 transistors.</p> </li> </ul>"},{"location":"AMM/UNIT_1/#comparison-between-8085-8086-microprocessor","title":"Comparison between 8085 &amp; 8086 Microprocessor","text":"<ul> <li> <p>Size  \u2212 8085 is 8-bit microprocessor, whereas 8086 is 16-bit microprocessor.</p> </li> <li> <p>Address Bus  \u2212 8085 has 16-bit address bus while 8086 has 20-bit address bus.</p> </li> <li> <p>Memory  \u2212 8085 can access up to 64Kb, whereas 8086 can access up to 1 Mb of memory.</p> </li> <li> <p>Instruction  \u2212 8085 doesn\u2019t have an instruction queue, whereas 8086 has an instruction queue.</p> </li> <li> <p>Pipelining  \u2212 8085 doesn\u2019t support a pipelined architecture while 8086 supports a pipelined architecture.</p> </li> <li> <p>I/O  \u2212 8085 can address 2^8 = 256 I/O's, whereas 8086 can access 2^16 = 65,536 I/O's.</p> </li> <li> <p>Cost  \u2212 The cost of 8085 is low whereas that of 8086 is high.</p> </li> </ul>"},{"location":"AMM/UNIT_1/#architecture-of-8086","title":"Architecture of 8086","text":"<p>The following diagram depicts the architecture of a 8086 Microprocessor \u2212</p> <p></p>"},{"location":"AMM/UNIT_1/#8085-programming-model","title":"8085 Programming Model","text":""},{"location":"AMM/UNIT_1/#a-programming-model-8085","title":"A programming model 8085","text":"<p>1. Registers</p> <ul> <li>The 8085 has six general purpose registers to store 8 bit data; these are identifies as B, C, D, E, H, L.</li> <li>They can be combined as register pairs - BC, DE and HL to perform some 16-bit operations.</li> <li>The programmer can use these registers to store or copy data into the registers by using data copy instructions.</li> </ul> <p>2. Accumulator</p> <ul> <li>The accumulator is an 8-bit register that is a part of arithmetic/logic unit(ALU).</li> <li>This register is used to store 8-bit data and to perform arithmetic and logical operations.</li> <li>The result of an operation is stored in the accumulator.</li> <li>The accumulator is also identified as register A.</li> </ul> <p>3. Flags </p> <p></p> <p>Bit positions of various flags in the flag register of 8085</p> <ul> <li> <p>8085 has five flag registers:-</p> </li> <li> <p>Sign Flag (S): Sets or Resets based on the result stored in the accumulator.</p> </li> </ul> <p>If the result stored is positive, the flag resets else if the result stored is negative the flag is set.</p> <ul> <li>Zero Flag (Z): Sets or Resets based on the result stored in the accumulator.</li> </ul> <p>If the result stored is zero the flag is set else it is reset.</p> <ul> <li> <p>Auxiliary Carry Flag(AC)  : This flag is set if there is a carry from low nibble(lowest 4 bits) to high nibble(upper 4 bits) or a borrow from high nibble to low nibble, in the low order 8-bit portion of an addition or subtraction operation.</p> </li> <li> <p>Parity Flag (P): This flag is set if there is even parity else it resets.</p> </li> <li> <p>Carry Flag (CY): This flag is set if there is a carry bit else it resets.</p> </li> </ul> <p>4. Program Counter (PC)</p> <ul> <li>This 16-bit register deals with sequencing the execution of instructions this register is a memory pointer.</li> <li>Memory locations have 16 bit addresses and that is why this is a 16 bit register.</li> <li>The function of the PC is to point to the memory address from which the next byte is to be fetched.</li> <li>When a byte(machine code) is being fetched, the program counter is incremented by one to point to the next memory location.</li> </ul> <p>5. Stack Pointer (SP)</p> <ul> <li>The stack pointer is also a 16-bit register used as a memory pointer.</li> <li>It points to a memory location in R/W memory called stack.</li> <li>The beggining of the stack is defined by loading 16-bit address in the stack pointer.</li> </ul>"},{"location":"AMM/UNIT_1/#a-programming-model-of-8086","title":"A programming model of 8086","text":"<p>The programming model for a microprocessor shows the various internal registers that are accessible to the programmer.</p> <p>The Following Figure is a model for the 8086. In general, each register has a special function.</p> <p>In the programming model there are</p> <ul> <li> <p>4 General Purpose registers( Data Registers)</p> </li> <li> <p>4 Segment registers</p> </li> <li> <p>2 Pointer registers</p> </li> <li> <p>2 Index registers</p> </li> <li> <p>1 Instruction Pointer register</p> </li> <li> <p>1 Flag register</p> </li> </ul> <p>General purpose registers:</p> <p>AX Register (Accumulator): This is accumulator register. It gets used in arithmetic, logic and data transfer instructions. In manipulation and division, one of the numbers involved must be in AX or AL.</p> <p>BX Register (Base Register): This is base register. BX register is an address register. It usually contain a data pointer used for based, based indexed or register indirect addressing.</p> <p>CX Register (Counter register): This is Count register. This serves as a loop counter. Program loop constructions are facilitated by it. Count register can also be used as a counter in string manipulation and shift/rotate instruction.</p> <p>DX Register (Data Register): This is data register. Data register can be used as a port number in I/O operations. It is also used in multiplication and division.</p> <p>Segement Registers:</p> <p>There are four segment registers in Intel 8086:</p> <ol> <li> <p>Code Segment Register (CS),</p> </li> <li> <p>Data Segment Register (DS),</p> </li> <li> <p>Stack Segment Register (SS),</p> </li> <li> <p>Extra Segment Register (ES).</p> </li> </ol> <p>A segment register points to the starting address of a memory segment. Maximum capacity of a segment may be up to 64 KB.</p> <p>Code segment Register(CS):- It is a 16-bit register containing the starting address of 64 KB segment. The processor uses CS segment for all accesses to instructions referenced by instruction pointer (IP) register.</p> <p>Stack segment Register (SS):- It is a 16-bit register containing address of 64KB segment with program stack. By default, the processor assumes that all data referenced by the stack pointer (SP) and base pointer (BP) registers is located in the stack segment. SS register can be changed directly using POP instruction.</p> <p>Data segment Register (DS):- It is a 16-bit register containing address of 64KB segment with program data. By default, the processor assumes that all data referenced by general registers (AX, BX, CX, DX) and index register (SI, DI) is located in the data segment.</p> <p>Extra segment Register (ES):- It is a 16-bit register containing address of 64KB segment, usually with program data. By default, the processor assumes that the DI register references the ES segment in string manipulation instructions. It is possible to change default segments used by general and index registers by prefixing instructions with a CS, SS,DS or ES prefix.</p> <p>Pointer Registers:</p> <p>SP Register (Stack Pointer): This is stack pointer register pointing to program stack. It is used in conjunction with SS for accessing the stack segment.</p> <p>BP Register (Base Pointer): This is base pointer register pointing to data in stack segment. Unlike SP, we can use BP to access data in the other segments.</p> <p>Index Registers:</p> <p>SI Register (Source Index): This is used to point to memory locations in the data segment addressed by DS. By incrementing the contents of SI one can easily access consecutive memory locations.</p> <p>DI Register (Destination Index): This register performs the same function as SI. There is a class of instructions called string operations, that use DI to access the memory locations addressed by ES.</p> <p>Instruction Pointer: The Instruction Pointer (IP) points to the address of the next instruction to be executed. Its content is automatically incremented when the execution of a program proceeds further. The contents of the IP and Code Segment Register are used to compute the memory address of the instruction code to be fetched. This is done during the Fetch Cycle.</p> <p>Flag Register:  Status Flags determines the current state of the accumulator. They are modified automatically by CPU after mathematical operations. This allows to determine the type of the result. 8086 has 16-bit status register. It is also called Flag Register or Program Status Word (PSW). There are nine status flags and seven bit positions remain unused.</p> <p>8086 has 16 flag registers among which 9 are active. The purpose of the FLAGS register is to indicate the status of the processor. It does this by setting the individual bits called flags. There are two kinds of FLAGS;</p> <p>Status FLAGS and Control FLAGS. Status FLAGS reflect the result of an operation executed by the processor. The control FLAGS enable or disable certain operations of the processor.</p>"},{"location":"AMM/UNIT_1/#reference","title":"Reference","text":"<p>https://www.tutorialspoint.com/microprocessor/microprocessor_8085_architecture.htm https://www.tutorialspoint.com/microprocessor/microprocessor_8086_overview.htm https://csenotesforyou.blogspot.com/2016/06/8085-programming-model.html</p>"},{"location":"AMM/UNIT_2/","title":"Microcontroller","text":""},{"location":"AMM/UNIT_2/#microcontroller-and-its-types","title":"Microcontroller and its Types","text":"<p>Introduction : A microcontroller (MCU) is a small computer on a single integrated circuit that is designed to control specific tasks within electronic systems. It combines the functions of a central processing unit (CPU), memory, and input/output interfaces, all on a single chip.</p> <p>Microcontrollers are widely used in embedded systems, such as home appliances, automotive systems, medical devices, and industrial control systems. They are also used in consumer electronics products, such as gaming systems, digital cameras, and audio players.</p> <p>A typical microcontroller consists of a processor core, volatile and non-volatile memory, input/output peripherals, and various communication interfaces. The processor core is responsible for executing instructions and controlling the other components of the microcontroller. The memory is used to store data and program code, while the input/output peripherals are used to interact with the external environment.</p> <p>Microcontrollers are programmable, which means that they can be customized to perform specific tasks. The programming languages used to write code for microcontrollers vary depending on the manufacturer and the type of microcontroller. Some of the commonly used programming languages include C, C++, and assembly language.</p> <p>A microcontroller is a self-contained desktop that can be utilized in an embedded system. A few microcontrollers may run at clock rate rates and use four-bit expressions. Because many of the devices they control are battery-operated, microcontrollers must often be low-power. Microcontrollers are found in a wide range of products, including consumer electronics, automobile engines, computer peripherals, and test and measurement equipment. These are also well-suited to long-term battery usage. The vast majority of microcontrollers in use today are embedded in other devices.</p> <p>The microcontroller used in Embedded System. for example:   \u2022 Security Systems   \u2022 Laser Printers   \u2022 Automation System   \u2022 Robotics</p>"},{"location":"AMM/UNIT_2/#working-of-microcontroller","title":"Working of Microcontroller:","text":"<p>The microcontroller chip is a high-speed device, yet it is slow when compared to a computer. As a result, each command will be executed quickly within the microcontroller. The quartz oscillator is enabled and through control logic register once the supply is powered on. Parasite capacitors will be recharged for a few seconds while the early preparation is taking place. Once the voltage level reaches its maximum value and the oscillator\u2019s frequency stabilizes, the operation of writing bits through special function registers becomes stable. Everything is controlled by the oscillator\u2019s CLK, and the whole electronics will begin to function. All of this happens in a matter of nanoseconds.</p> <p>A microcontroller\u2019s major role is that it can be thought of as a self-contained system with a processor memory. Its peripherals can be used in the same way that an 8051 microcontroller can. The bulk of microcontrollers in use today are embedded in other types of machinery such as telephones, appliances, vehicles, and computer system peripherals.</p>"},{"location":"AMM/UNIT_2/#microcontrollers-8051-architecture","title":"Microcontrollers - 8051 Architecture","text":"<p>8051 microcontroller is designed by Intel in 1981. It is an 8-bit microcontroller. It is built with 40 pins DIP (dual inline package), 4kb of ROM storage and 128 bytes of RAM storage, 2 16-bit timers. It consists of are four parallel 8-bit ports, which are programmable as well as addressable as per the requirement. An on-chip crystal oscillator is integrated in the microcontroller having crystal frequency of 12 MHz.Let us now discuss the architecture of 8051 Microcontroller.</p> <p>In the following diagram, the system bus connects all the support devices to the CPU. The system bus consists of an 8-bit data bus, a 16-bit address bus and bus control signals. All other devices like program memory, ports, data memory, serial interface, interrupt control, timers, and the CPU are all interfaced together through the system bus.</p> <p></p>"},{"location":"AMM/UNIT_2/#data-types-and-directives","title":"Data types and directives","text":"<p>The 8051 microcontroller is a popular microcontroller architecture that was originally developed by Intel. It has since become widely used and is produced by various manufacturers. The 8051 microcontroller has a versatile architecture with a variety of data types and directives. Here are some of the key aspects:</p> <p>Data Types:</p> <ol> <li> <p>Bit: The smallest unit of data, representing a single binary digit (0 or 1).</p> </li> <li> <p>Byte: A group of 8 bits, the fundamental unit for most data operations in the 8051.</p> </li> <li> <p>Data (Internal) RAM: The 8051 has internal RAM (Random Access Memory) for data storage. The size of the RAM varies depending on the specific model of the 8051 microcontroller.</p> </li> <li> <p>Register Banks: The 8051 has four register banks, each containing register locations that can be used for various purposes. The register banks are named R0 to R7.</p> </li> <li> <p>Bit-Addressable RAM: Specific bits in the internal RAM can be individually addressed, allowing for efficient bit manipulation.</p> </li> </ol>"},{"location":"AMM/UNIT_2/#directives","title":"Directives:","text":"<ol> <li> <p>ORG (Origin): Specifies the starting address for the code or data in memory.</p> </li> <li> <p>DB (Define Byte): Allocates space in memory to store one or more bytes of data.</p> </li> <li> <p>DW (Define Word): Allocates space in memory to store one or more 16-bit words.</p> </li> <li> <p>DS (Define Storage): Reserves a block of memory for a specified number of bytes.</p> </li> <li> <p>END: Marks the end of the assembly program.</p> </li> <li> <p>EQU (Equate): Defines a constant or assigns a value to a symbol.</p> </li> <li> <p>CODE: Specifies the segment of the program where the code is located.</p> </li> <li> <p>DATA: Specifies the segment of the program where data is located.</p> </li> <li> <p>SEGMENT: Declares a code or data segment.</p> </li> <li> <p>ENDS: Marks the end of a segment.</p> </li> </ol>"},{"location":"AMM/UNIT_2/#psw-register-in-8051-microcontroller-program-status-word","title":"PSW Register in 8051 Microcontroller | Program Status Word","text":"<p>2 Comments  / By  EFY  /  21/05/2023</p> <ul> <li>Flags are single bit register and used to store the result of certain function after executing instruction. Flags are grouped inside PSW and PCON registers.</li> <li>PSW register in  8051 microcontroller  contains math flags and PCON contains general user flags.</li> <li>Math flags are grouped in PSW of microcontroller 8051 and they are Carry(C), Auxiliary Carry (AC), Over flow (OV), and Parity (P). The general user flags are GF0 and GF1 which are grouped in PCON register.</li> </ul>"},{"location":"AMM/UNIT_2/#psw-register-in-8051","title":"PSW Register in 8051","text":"<ul> <li>The PSW is accessible fully as an 8-bit register, with the address D0H.</li> <li>The bit pattern of this flag register is</li> </ul> <p>Figure 1: Format of PSW register in 8051 Microcontroller</p>"},{"location":"AMM/UNIT_2/#parity-bit-p","title":"Parity Bit (P)","text":"<ul> <li> <ul> <li>This parity flag bit is used to show the number of 1s in the accumulator only. If the accumulator register contains an odd number of 1s, then this flag set to 1.</li> <li>If accumulator contains even number of 1s, then this flag cleared to 0.</li> </ul> </li> </ul>"},{"location":"AMM/UNIT_2/#overflow-flag-ov","title":"Overflow Flag (OV)","text":"<ul> <li> <ul> <li>This flag is set during ALU operations, to indicate overflow in the result. It is set to 1 if there is a carry out of either the D7 bit or the D6 bit of the accumulator.</li> <li>Overflow flag is set when arithmetic operations such as add and subtract result in sign conflict.</li> </ul> </li> <li> <ul> <li>The conditions under which the OV flag is set are as follows:         -   Positive + Positive = Negative         -   Negative + Negative = Positive         -   Positive \u2013 Negative = Negative         -   Negative \u2013 Positive = Positive</li> </ul> </li> </ul>"},{"location":"AMM/UNIT_2/#register-bank-select-bits-rs1-and-rs0","title":"Register Bank Select Bits (RS1 And RS0)","text":"<ul> <li> <ul> <li>These two bits are used to select one of four register banks of RAM. By setting and clearing these bits, registers R0-R7 are stored in one of four banks of RAM as follows.</li> </ul> </li> </ul> RS1 RS0 Bank Selected Address of Registers 0 0 Bank 0 00h-07h 0 1 Bank 1 08h-0Fh 1 0 Bank 2 10h-17h 1 1 Bank 3 18h-1Fh -  -   These bits are user-programmable. They can be set by the programmer to point to the correct register banks. -   The register bank selection in the programs can be changed using these two bits."},{"location":"AMM/UNIT_2/#general-purpose-flag-f0","title":"General-Purpose Flag (F0)","text":"<ul> <li> <ul> <li>This is a user-programmable flag; the user can program and store any bit of his/her choice in this flag, using the bit address.</li> </ul> </li> </ul>"},{"location":"AMM/UNIT_2/#auxiliary-carry-flag-ac","title":"Auxiliary Carry Flag (AC)","text":"<ul> <li> <ul> <li>It is used in association with BCD arithmetic. This flag is set when there is a carry out of the D3 bit of the accumulator.</li> </ul> </li> </ul>"},{"location":"AMM/UNIT_2/#carry-flag-cy","title":"Carry Flag (CY)","text":"<ul> <li> <ul> <li>This flag is used to indicate the carry generated after arithmetic operations. It can also be used as an accumulator, to store one of the data bits for bit-related Boolean instructions.</li> </ul> </li> <li> <p>The 8051 supports bit manipulation instructions.</p> </li> <li>This means that in addition to the byte operations, bit operations can also be done using bit data.</li> <li>For this purpose, the contents of the PSW are bit-addressable.</li> </ul> <p></p>"},{"location":"AMM/UNIT_2/#8051-register-bank-and-stack","title":"8051 Register Bank and Stack","text":"<p>The 8051 microcontroller has a total of 128 bytes of RAM, organized into three groups:</p> <ol> <li>Register Bank and Stack (00H-1FH): 32 bytes</li> <li>Bit Addressable Read/Write Memory (20H-2FH): 16 bytes</li> <li>Scratch Pad - Read/Write Storage (30H-7FH): 80 bytes</li> </ol>"},{"location":"AMM/UNIT_2/#register-bank","title":"Register Bank:","text":"<p>There are 4 register banks, each with 8 registers (R0 to R7), and each register is 8 bits wide. By default, Register Bank 0 is selected when the 8051 is powered up. The selection of other banks is done using bits D4 and D3 of the PSW (Program Status Word) register.</p>"},{"location":"AMM/UNIT_2/#stack","title":"Stack:","text":"<p>The stack is a section of RAM used by the CPU to temporarily store information. The stack is accessed through the stack pointer (SP) register, which is 8 bits wide and can take values from 00 to FFH. Upon power-up, the SP register contains the value 07, indicating that RAM location 08 is the first location used for the stack. Storing data in the stack is referred to as a PUSH operation, and retrieving data from the stack into a CPU register is called a POP operation.</p>"},{"location":"AMM/UNIT_2/#example-code","title":"Example Code:","text":"<pre><code>ORG 00H\nMOV R1, #25H\nMOV R4, #45H\nPUSH 1\nPUSH 4\nPOP 3\nPOP 6\nEND\n</code></pre> <ul> <li>The instruction \"PUSH 1\" increments SP to 08H and pushes register R1 onto the stack location 08H.</li> <li>The \"PUSH 4\" instruction increments SP to 09H and pushes register R4 onto the stack location 09H.</li> <li>The instruction \"POP 3\" copies the top of the stack (location 09H) to register R3 and decrements SP to 08H.</li> <li>The \"POP 6\" instruction copies the top of the stack (location 08H) to register R6 and decrements SP to 07H.</li> </ul> <p>Locations 08 to 1F can be used for the stack, with the upper limit of the stack being 1FH. If a program needs more than 24 bytes (08 to 1FH = 24 bytes) of stack, the SP can be changed to point to RAM locations 30 - 7FH using the instruction \"MOV SP, #xxH\". Initially, when the 8051 is powered up, SP is 07, and the first location of the stack is RAM location 08, which also belongs to register R0 of register bank 1. In other words, register bank 1 and the stack are using the same memory space.</p> <p>If a program needs to use register banks 1 and 2, another section of RAM can be reallocated to the stack.</p>"},{"location":"AMM/UNIT_2/#reference","title":"Reference","text":"<p>https://www.geeksforgeeks.org/microcontroller-and-its-types/ https://www.tutorialspoint.com/microprocessor/microcontrollers_8051_architecture.htm https://electronicsforyou.in/psw-register-in-8051-microcontroller/ https://www.refreshnotes.com/2016/03/8051-register-bank-and-stack.html</p>"},{"location":"AMM/UNIT_3/","title":"COMING SOON!","text":""},{"location":"AMM/UNIT_4/","title":"COMING SOON!","text":""},{"location":"AMM/UNIT_5/","title":"COMING SOON!","text":""},{"location":"AMM/cae1/","title":"Question bank","text":""},{"location":"AMM/cae1/#1illustrate-microprocessor-technology","title":"1.Illustrate Microprocessor Technology.","text":"<p>Microprocessor technology refers to the design, development, and application of integrated circuits that contain the processing unit of a computer system. Here's an illustration of microprocessor technology:</p> <p>1.Architecture: Microprocessors are built on a specific architecture, which defines the organization of its components and the set of instructions it can execute. Common architectures include x86, ARM, MIPS, and PowerPC, each with its own instruction set and design philosophy.</p> <p>2.Components: A microprocessor typically consists of several key components:    - Central Processing Unit (CPU): This is the core component responsible for executing instructions, performing arithmetic and logic operations, and controlling the flow of data within the system.    - Registers: These are small, high-speed storage locations within the CPU used to store data temporarily during processing.    - Control Unit (CU): This component manages the execution of instructions, fetching them from memory, decoding them, and controlling the operation of other components.    - Arithmetic Logic Unit (ALU): The ALU performs arithmetic and logic operations on data, such as addition, subtraction, AND, OR, etc.    - Cache Memory: This is a small, high-speed memory located close to the CPU that stores frequently accessed data and instructions to speed up processing.    - Clock: Microprocessors operate synchronously with a clock signal, which regulates the timing of operations and ensures coordination between different components.</p> <p>3.Instruction Set: Microprocessors understand and execute instructions encoded in machine language, which is represented as binary code. The instruction set architecture (ISA) defines the set of instructions that the microprocessor can execute, including arithmetic, logic, data transfer, and control instructions.</p> <p>4.Memory Interface: Microprocessors interact with memory devices (RAM, ROM, etc.) to store and retrieve data and instructions. They use memory addresses to access specific locations in memory and transfer data between memory and the CPU.</p> <p>5. Peripheral Interfaces**: Microprocessors communicate with external devices, such as input/output (I/O) devices, through various interfaces like serial ports, parallel ports, USB ports, Ethernet, etc. These interfaces allow the microprocessor to interact with the external world, enabling functions like data input, output, and communication.</p> <p>6.Applications: Microprocessors are used in a wide range of applications, including personal computers, smartphones, embedded systems, automotive electronics, industrial control systems, and consumer electronics. Their versatility, high performance, and cost-effectiveness make them suitable for diverse computing tasks.</p> <p>In summary, microprocessor technology encompasses the design, architecture, components, instruction set, memory interface, peripheral interfaces, and applications of microprocessors, which are essential components of modern computing systems.</p>"},{"location":"AMM/cae1/#2draw-the-architectural-diagram-of-microprocessor-8085","title":"2.Draw the Architectural diagram of microprocessor 8085.","text":""},{"location":"AMM/cae1/#3explain-the-architectural-diagram-of-microprocessor-8085","title":"3.Explain the Architectural diagram of microprocessor 8085.","text":"<p>Microprocessor-8085 Architecture</p> <p>8085 is pronounced as \"eighty-eighty-five\" microprocessor. It is an 8-bit microprocessor designed by Intel in 1977 using NMOS technology.</p> <p>It has the following configuration \u2212</p> <ul> <li>8-bit data bus</li> <li>16-bit address bus, which can address upto 64KB</li> <li>A 16-bit program counter</li> <li>A 16-bit stack pointer</li> <li>Six 8-bit registers arranged in pairs: BC, DE, HL</li> <li>Requires +5V supply to operate at 3.2 MHZ single phase clock</li> </ul> <p>It is used in washing machines, microwave ovens, mobile phones, etc.</p> <p>8085 Microprocessor \u2013 Functional Units</p> <p>8085 consists of the following functional units \u2212</p> <p>Accumulator</p> <p>It is an 8-bit register used to perform arithmetic, logical, I/O &amp; LOAD/STORE operations. It is connected to internal data bus &amp; ALU.</p> <p>Arithmetic and logic unit</p> <p>As the name suggests, it performs arithmetic and logical operations like Addition, Subtraction, AND, OR, etc. on 8-bit data.</p> <p>General purpose register</p> <p>There are 6 general purpose registers in 8085 processor, i.e. B, C, D, E, H &amp; L. Each register can hold 8-bit data.</p> <p>These registers can work in pair to hold 16-bit data and their pairing combination is like B-C, D-E &amp; H-L.</p> <p>Program counter</p> <p>It is a 16-bit register used to store the memory address location of the next instruction to be executed. Microprocessor increments the program whenever an instruction is being executed, so that the program counter points to the memory address of the next instruction that is going to be executed.</p> <p>Stack pointer</p> <p>It is also a 16-bit register works like stack, which is always incremented/decremented by 2 during push &amp; pop operations.</p> <p>Temporary register</p> <p>It is an 8-bit register, which holds the temporary data of arithmetic and logical operations.</p> <p>Flag register</p> <p>It is an 8-bit register having five 1-bit flip-flops, which holds either 0 or 1 depending upon the result stored in the accumulator.</p> <p>These are the set of 5 flip-flops \u2212</p> <ul> <li>Sign (S)</li> <li>Zero (Z)</li> <li>Auxiliary Carry (AC)</li> <li>Parity (P)</li> <li>Carry (C)</li> </ul> <p>Its bit position is shown in the following table \u2212</p> D7 D6 D5 D4 D3 D2 D1 D0 S Z AC P CY Instruction register and decoder <p>It is an 8-bit register. When an instruction is fetched from memory then it is stored in the Instruction register. Instruction decoder decodes the information present in the Instruction register.</p> <p>Timing and control unit</p> <p>It provides timing and control signal to the microprocessor to perform operations. Following are the timing and control signals, which control external and internal circuits \u2212</p> <ul> <li>Control Signals: READY, RD\u2019, WR\u2019, ALE</li> <li>Status Signals: S0, S1, IO/M\u2019</li> <li>DMA Signals: HOLD, HLDA</li> <li>RESET Signals: RESET IN, RESET OUT</li> </ul> <p>Interrupt control</p> <p>As the name suggests it controls the interrupts during a process. When a microprocessor is executing a main program and whenever an interrupt occurs, the microprocessor shifts the control from the main program to process the incoming request. After the request is completed, the control goes back to the main program.</p> <p>There are 5 interrupt signals in 8085 microprocessor: INTR, RST 7.5, RST 6.5, RST 5.5, TRAP.</p> <p>Serial Input/output control</p> <p>It controls the serial data communication by using these two instructions: SID (Serial input data) and SOD (Serial output data).</p> <p>Address buffer and address-data buffer</p> <p>The content stored in the stack pointer and program counter is loaded into the address buffer and address-data buffer to communicate with the CPU. The memory and I/O chips are connected to these buses; the CPU can exchange the desired data with the memory and I/O chips.</p> <p>Address bus and data bus</p> <p>Data bus carries the data to be stored. It is bidirectional, whereas address bus carries the location to where it should be stored and it is unidirectional. It is used to transfer the data &amp; Address I/O devices.</p> <p></p>"},{"location":"AMM/cae1/#4draw-the-architectural-diagram-of-microprocessor-8086","title":"4.Draw the Architectural diagram of microprocessor 8086.","text":""},{"location":"AMM/cae1/#5explain-the-architectural-diagram-of-microprocessor-8086","title":"5.Explain the Architectural diagram of microprocessor 8086.","text":"<p>8086 Microprocessor is an enhanced version of 8085Microprocessor that was designed by Intel in 1976. It is a 16-bit Microprocessor having 20 address lines and16 data lines that provides up to 1MB storage. It consists of powerful instruction set, which provides operations like multiplication and division easily.</p> <p>It supports two modes of operation, i.e. Maximum mode and Minimum mode. Maximum mode is suitable for system having multiple processors and Minimum mode is suitable for system having a single processor.</p> <p>Features of 8086</p> <p>The most prominent features of a 8086 microprocessor are as follows \u2212</p> <ul> <li> <p>It has an instruction queue, which is capable of storing six instruction bytes from the memory resulting in faster processing.</p> </li> <li> <p>It was the first 16-bit processor having 16-bit ALU, 16-bit registers, internal data bus, and 16-bit external data bus resulting in faster processing.</p> </li> <li> <p>It is available in 3 versions based on the frequency of operation \u2212</p> <ul> <li> <p>8086 \u2192 5MHz</p> </li> <li> <p>8086-2 \u2192 8MHz</p> </li> <li> <p>(c)8086-1 \u2192 10 MHz</p> </li> </ul> </li> <li> <p>It uses two stages of pipelining, i.e. Fetch Stage and Execute Stage, which improves performance.</p> </li> <li> <p>Fetch stage can prefetch up to 6 bytes of instructions and stores them in the queue.</p> </li> <li> <p>Execute stage executes these instructions.</p> </li> <li> <p>It has 256 vectored interrupts.</p> </li> <li> <p>It consists of 29,000 transistors.</p> </li> </ul> <p>Architecture of 8086</p> <p>The following diagram depicts the architecture of a 8086 Microprocessor \u2212</p> <p></p>"},{"location":"AMM/cae1/#6what-are-the-different-features-of-8085-designer-must-considered-to-develop-the-8085-based-system","title":"6.What are the different features of 8085 designer must considered to develop the 8085 based system?","text":"<p>To develop an 8085-based system effectively, designers must consider various features and specifications of the Intel 8085 microprocessor. Here are the key features that designers should take into account:</p> <ol> <li> <p>Architecture: Understand the architecture of the 8085 microprocessor, including its organization of registers, data bus, address bus, control signals, and instruction set architecture (ISA). This knowledge is essential for designing the overall system and interfacing with peripheral devices.</p> </li> <li> <p>Clock Frequency: Determine the operating frequency of the 8085 microprocessor, which affects the overall performance of the system. Design the system to provide a stable clock signal within the specified frequency range to ensure proper synchronization of operations.</p> </li> <li> <p>Power Supply Requirements: Consider the power supply specifications of the 8085 microprocessor, including voltage levels, current requirements, and power consumption. Design the power supply circuitry to meet these requirements and ensure reliable operation of the system.</p> </li> <li> <p>Memory Interface: Understand the memory addressing capabilities of the 8085 microprocessor, including its support for various types of memory devices such as RAM, ROM, and I/O ports. Design the memory interface circuitry to accommodate the memory requirements of the system and facilitate efficient data transfer.</p> </li> <li> <p>Input/Output Interface: Take into account the input/output (I/O) capabilities of the 8085 microprocessor, including its support for interfacing with external devices such as keyboards, displays, sensors, and actuators. Design the I/O interface circuitry to enable communication between the microprocessor and external peripherals.</p> </li> <li> <p>Interrupt Handling: Understand the interrupt handling mechanism of the 8085 microprocessor, including its support for different types of interrupts and interrupt priority levels. Design the system to handle interrupts effectively and ensure timely response to interrupt requests from external devices.</p> </li> <li> <p>Address Decoding: Implement proper address decoding logic to enable the microprocessor to access different memory and I/O devices within the system. Design the address decoding circuitry to generate chip select signals for the selected memory or I/O device based on the address lines provided by the microprocessor.</p> </li> <li> <p>Peripheral Interfacing: Ensure compatibility with standard peripheral interface protocols such as RS-232, SPI, I2C, etc., to facilitate communication with external devices. Design the interface circuitry to support the required communication protocol and data transfer rates.</p> </li> <li> <p>System Integration and Testing: Integrate the 8085 microprocessor into the overall system design and conduct thorough testing to verify proper functionality and performance. Test the system with different input scenarios and verify the output to ensure that it meets the desired specifications.</p> </li> </ol> <p>By considering these features and specifications of the 8085 microprocessor, designers can develop efficient and reliable systems tailored to specific application requirements.</p>"},{"location":"AMM/cae1/#7explain-the-flag-register-of-8085-microprocessor","title":"7.Explain the Flag Register of 8085 Microprocessor.","text":"<p>Flag register in 8085 microprocessor</p> <p>The  Flag register  is a Special Purpose Register. Depending upon the value of the result after any arithmetic and logical operation, the flag bits become set (1) or reset (0). In 8085 microprocessor, the flag register consists of 8 bits and only 5 of them are useful. The 5 flags are:</p> <p></p> <p>1.Sign Flag (S) \u2013  After any operation if the MSB (B(7)) of the result is 1, it indicates the number is negative and the sign flag becomes set, i.e. 1. If the MSB is 0, it indicates the number is positive and the sign flag becomes reset i.e. 0. from 00H to 7F, sign flag is 0 from 80H to FF, sign flag is 1 1- MSB is 1 (negative) 0- MSB is 0 (positive)  </p> <p>Example:  MVI A 30 (load 30H in register A) MVI B 40 (load 40H in register B) SUB B (A = A \u2013 B) These set of instructions will set the sign flag to 1 as 30 \u2013 40 is a negative number. MVI A 40 (load 40H in register A) MVI B 30 (load 30H in register B) SUB B (A = A \u2013 B) These set of instructions will reset the sign flag to 0 as 40 \u2013 30 is a positive number.</p> <p>2.Zero Flag (Z) \u2013  After any arithmetical or logical operation if the result is 0 (00)H, the zero flag becomes set i.e. 1, otherwise it becomes reset i.e. 0. 00H zero flags is 1. from 01H to FFH zero flag is 0 1- zero-result 0- non-zero result  </p> <p>Example:  MVI A 10 (load 10H in register A) SUB A (A = A \u2013 A) These set of instructions will set the zero flag to 1 as 10H \u2013 10H is 00H</p> <p>3.Auxiliary Carry Flag (AC) \u2013  This flag is used in the BCD number system(0-9). If after any arithmetic or logical operation D(3) generates any carry and passes it on to D(4) this flag becomes set i.e. 1, otherwise, it becomes reset i.e. 0. This is the only flag register that is not accessible by the programmer 1-carry out from bit 3 on addition or borrows into bit 3 on subtraction 0-otherwise  </p> <p>Example:  MVI A 2BH (load 2BH in register A) MVI 39H (load 39H in register B) ADD B (A = A + B) These set of instructions will set the auxiliary carry flag to 1, as on adding 2B and 39, the addition of lower-order nibbles B and 9 will generate a carry.</p> <p>4.Parity Flag (P) \u2013  If after any arithmetic or logical operation the result has even parity, an even number of 1 bit, the parity register becomes set i.e. 1, otherwise it becomes reset i.e. 0. 1-accumulator has an even number of 1 bits 0-accumulator has odd parity Example:  MVI A 05 (load 05H in register A) This instruction will set the parity flag to 1 as the BCD code of 05H is 00000101, which contains an even number of ones i.e. 2.</p> <p>5.Carry Flag (CY) \u2013  Carry is generated when performing n bit operations and the result is more than n bits, then this flag becomes set i.e. 1, otherwise, it becomes reset i.e. 0. During subtraction (A-B), if A&gt;B it becomes reset, and if (A&lt;B) it becomes set. Carry flag is also called the borrow flag. 1-carry out from MSB bit on addition or borrow into MSB bit on subtraction 0-no carry out or borrow into MSB bit.  </p> <p>Example:  MVI A 30 (load 30H in register A) MVI B 40 (load 40H in register B) SUB B (A = A \u2013 B) These set of instructions will set the carry flag to 1 as 30 \u2013 40 generates a carry/borrow. MVI A 40 (load 40H in register A) MVI B 30 (load 30H in register B) SUB B (A = A \u2013 B) These set of instructions will reset the carry flag to 0 as 40 \u2013 30 does not generate any carry/borrow.</p>"},{"location":"AMM/cae1/#8what-are-the-different-features-of-8086-designer-must-considered-to-develop-the-8085-based-system","title":"8.What are the different features of 8086 designer must considered to develop the 8085 based system?","text":"<ul> <li>Architecture: Understand the differences in architecture between the 8086 and 8085 processors, including the register set, instruction set, and memory addressing modes.</li> <li>Compatibility Mode: The 8086 can operate in a backward-compatible mode (real mode) to execute 8085 instructions. Designers should consider this mode for compatibility with existing software.</li> <li>Memory Segmentation: The 8086 uses memory segmentation, unlike the 8085. Designers must account for this and handle memory addressing accordingly.</li> <li>Interrupt Handling: The interrupt handling mechanism in the 8086 differs from that of the 8085. Designers should ensure compatibility or adapt interrupt handling routines accordingly.</li> <li>Data and Address Bus: The 8086 has a 16-bit data bus and a 20-bit address bus, whereas the 8085 has an 8-bit data bus and a 16-bit address bus. Designers need to interface the 8086 appropriately to accommodate these differences.</li> </ul>"},{"location":"AMM/cae1/#9explain-the-flag-register-of-8086-microprocessor","title":"9.Explain the Flag Register of 8086 Microprocessor.","text":"<p>The flag register, also known as the FLAGS register, is a crucial component of the Intel 8086 microprocessor architecture. It contains a set of status flags that reflect the outcomes of arithmetic and logic operations performed by the CPU. Understanding the flag register is essential for writing efficient assembly language programs and for implementing conditional branching and decision-making logic. Here's an explanation of the flag register of the 8086 microprocessor:</p> <p>1. Bit Structure: The flag register is a 16-bit register, with each bit representing a specific flag. The flags are numbered from 0 to 15, with some flags having specific meanings and others being reserved for future use.</p> <p>2. Common Flags:</p> <ul> <li>Carry Flag (CF): This flag indicates whether a carry occurred during arithmetic operations like addition or subtraction. It is also used in multi-precision arithmetic and logical shift operations.</li> <li>Zero Flag (ZF): This flag is set when the result of an operation is zero. It is cleared when the result is non-zero.</li> <li>Sign Flag (SF): This flag reflects the sign of the result. It is set if the result is negative (has the most significant bit set) and cleared otherwise.</li> <li>Overflow Flag (OF): This flag indicates whether an overflow occurred during signed arithmetic operations. An overflow occurs when the result cannot be represented within the available number of bits.</li> <li>Auxiliary Carry Flag (AF): This flag is used for binary-coded decimal (BCD) arithmetic operations. It indicates whether a carry occurred from the low nibble (bits 0-3) to the high nibble (bits 4-7) during addition or subtraction.</li> <li>Parity Flag (PF): This flag indicates the parity of the least significant byte of the result. It is set if the number of set bits in the least significant byte is even and cleared if it is odd.</li> </ul> <p>3. Conditional Branching: The flags in the flag register are used to implement conditional branching instructions such as JUMP IF ZERO (JZ), JUMP IF NOT ZERO (JNZ), JUMP IF CARRY (JC), etc. These instructions allow the CPU to change the flow of program execution based on the current state of the flags.</p> <p>4. Status Reporting: In addition to influencing program flow, the flags in the flag register can also be examined by the program to make decisions or perform specific actions based on the results of previous operations.</p> <p>5. Flag Manipulation: Assembly language instructions exist to manipulate the flags directly, such as the CLC (clear carry flag), STC (set carry flag), and CMC (complement carry flag) instructions. These instructions are useful for controlling program flow or preparing the CPU for subsequent operations.</p> <p>In summary, the flag register of the 8086 microprocessor is a critical component that reflects the outcomes of arithmetic and logic operations, influences program flow through conditional branching, and can be directly manipulated by assembly language instructions. Understanding the flag register is essential for effective programming and utilization of the 8086 microprocessor.</p>"},{"location":"AMM/cae1/#10explain-the-functionality-of-each-pin-of-8085-microprocessor-with-neat-diagram","title":"10.Explain the functionality of each Pin of 8085 Microprocessor with neat diagram?","text":"<p>The following image depicts the pin diagram of 8085 Microprocessor \u2212</p> <p></p> <p>The pins of a 8085 microprocessor can be classified into seven groups \u2212</p> <p>Address bus</p> <p>A15-A8, it carries the most significant 8-bits of memory/IO address.</p> <p>Data bus</p> <p>AD7-AD0, it carries the least significant 8-bit address and data bus.</p> <p>Control and status signals</p> <p>These signals are used to identify the nature of operation. There are 3 control signal and 3 status signals.</p> <p>Three control signals are RD, WR &amp; ALE.</p> <ul> <li> <p>RD  \u2212 This signal indicates that the selected IO or memory device is to be read and is ready for accepting data available on the data bus.</p> </li> <li> <p>WR  \u2212 This signal indicates that the data on the data bus is to be written into a selected memory or IO location.</p> </li> <li> <p>ALE  \u2212 It is a positive going pulse generated when a new operation is started by the microprocessor. When the pulse goes high, it indicates address. When the pulse goes down it indicates data.</p> </li> </ul> <p>Three status signals are IO/M, S0 &amp; S1.</p> <p>IO/M</p> <p>This signal is used to differentiate between IO and Memory operations, i.e. when it is high indicates IO operation and when it is low then it indicates memory operation.</p> <p>S1 &amp; S0</p> <p>These signals are used to identify the type of current operation.</p> <p>Power supply</p> <p>There are 2 power supply signals \u2212 VCC &amp; VSS. VCC indicates +5v power supply and VSS indicates ground signal.</p> <p>Clock signals</p> <p>There are 3 clock signals, i.e. X1, X2, CLK OUT.</p> <ul> <li> <p>X1, X2  \u2212 A crystal (RC, LC N/W) is connected at these two pins and is used to set frequency of the internal clock generator. This frequency is internally divided by 2.</p> </li> <li> <p>CLK OUT  \u2212 This signal is used as the system clock for devices connected with the microprocessor.</p> </li> </ul> <p>Interrupts &amp; externally initiated signals</p> <p>Interrupts are the signals generated by external devices to request the microprocessor to perform a task. There are 5 interrupt signals, i.e. TRAP, RST 7.5, RST 6.5, RST 5.5, and INTR. We will discuss interrupts in detail in interrupts section.</p> <ul> <li> <p>INTA  \u2212 It is an interrupt acknowledgment signal.</p> </li> <li> <p>RESET IN  \u2212 This signal is used to reset the microprocessor by setting the program counter to zero.</p> </li> <li> <p>RESET OUT  \u2212 This signal is used to reset all the connected devices when the microprocessor is reset.</p> </li> <li> <p>READY  \u2212 This signal indicates that the device is ready to send or receive data. If READY is low, then the CPU has to wait for READY to go high.</p> </li> <li> <p>HOLD  \u2212 This signal indicates that another master is requesting the use of the address and data buses.</p> </li> <li> <p>HLDA (HOLD Acknowledge)  \u2212 It indicates that the CPU has received the HOLD request and it will relinquish the bus in the next clock cycle. HLDA is set to low after the HOLD signal is removed.</p> </li> </ul> <p>Serial I/O signals</p> <p>There are 2 serial signals, i.e. SID and SOD and these signals are used for serial communication.</p> <ul> <li> <p>SOD  (Serial output data line) \u2212 The output SOD is set/reset as specified by the SIM instruction.</p> </li> <li> <p>SID  (Serial input data line) \u2212 The data on this line is loaded into accumulator whenever a RIM instruction is executed.</p> </li> </ul>"},{"location":"AMM/cae1/#11compare-microcontroller-and-microprocessor","title":"11.Compare Microcontroller and Microprocessor.","text":"Parameter Microprocessor Microcontroller Definition Heart of a computer system Heart of an embedded system What is it? Processor with memory and I/O connected externally Controlling device with internal memory and I/O components Circuit complexity Complex due to external connections Less complex due to on-chip memory Memory and I/O components Connected externally Internal memory and I/O components available Compact system compatibility Can't be used in compact systems Compatible with compact systems Efficiency Less efficient More efficient Zero status flag Has a zero status flag Doesn't have a zero status flag Number of registers Less number of registers More number of registers Applications Generally used in personal computers Commonly used in appliances like washing machines, air conditioners"},{"location":"AMM/cae1/#12draw-the-architectural-diagram-of-8051-microcontrollers","title":"12.Draw the Architectural diagram of 8051 microcontrollers.","text":""},{"location":"AMM/cae1/#13explain-the-architectural-diagram-of-8051-microcontrollers","title":"13.Explain the Architectural diagram of 8051 microcontrollers.","text":"<p>8051 Microcontroller Architecture</p> <p>Let's see the internal architecture of 8051 Microcontroller represented in form of block diagram as shown below:</p> <p></p> <p>Basic components present internally inside 8051 Microcontroller architecture are:</p> <p>CPU (Central Processing Unit): CPU act as a mind of any processing machine. It synchronizes and manages all processes that are carried out in microcontroller. User has no power to control the functioning of CPU. It interprets the program stored in ROM and carries out from storage and then performs it projected duty. CPU manage the different types of registers available in 8051 microcontroller.</p> <p>Interrupts: Interrupts is a sub-routine call that given by the microcontroller when some other program with high priority is request for acquiring the system buses the n interrupts occur in current running program.</p> <p>Interrupts provide a method to postpone or delay the current process, performs a sub-routine task and then restart the standard program again.</p> <p>Types of interrupt in 8051 Microcontroller:</p> <p>Let's see the five sources of interrupts in 8051 Microcontroller:</p> <ul> <li>Timer 0 overflow interrupt - TF0</li> <li>Timer 1 overflow interrupt - TF1</li> <li>External hardware interrupt - INT0</li> <li>External hardware interrupt - INT1</li> <li>Serial communication interrupt - RI/TI</li> </ul> <p>Memory: For operation Micro-controller required a program. This program guides the microcontroller to perform the specific tasks. This program installed in microcontroller required some on chip memory for the storage of the program.</p> <p>Microcontroller also required memory for storage of data and operands for the short duration. In microcontroller 8051 there is code or program memory of 4 KB that is it has 4 KB ROM and it also comprise of data memory (RAM) of 128 bytes.</p> <p>Bus : Bus is a group of wires which uses as a communication canal or acts as means of data transfer. The different bus configuration includes 8, 16 or more cables. Therefore, a bus can bear 8 bits, 16 bits all together.</p> <p>Types of buses in 8051 Microcontroller:</p> <p>Let's see the two types of bus used in 8051 microcontroller:</p> <ul> <li>Address Bus: 8051 microcontrollers is consisting of 16 bit address bus. It is generally be used for transferring the data from Central Processing Unit to Memory.</li> <li>Data bus: 8051 microcontroller is consisting of 8 bits data bus. It is generally be used for transferring the data from one peripherals position to other peripherals.</li> </ul> <p>Oscillator: As the microcontroller is digital circuit therefore it needs timer for their operation. To perform timer operation inside microcontroller it required externally connected or on-chip oscillator. Microcontroller is used inside an embedded system for managing the function of devices. Therefore, 8051 uses the two 16 bit counters and timers. For the operation of this timers and counters the oscillator is used inside microcontroller.</p>"},{"location":"AMM/cae1/#14illustrate-data-types-and-directives-of-8051-microcontroller","title":"14.Illustrate data types and directives of 8051 microcontroller.","text":"<p>In the 8051 microcontroller architecture, data types and directives play crucial roles in defining data elements, organizing memory, and guiding the assembler during the compilation process. Let's illustrate the commonly used data types and directives in the context of programming the 8051 microcontroller:</p> <p>Data Types in 8051 Microcontroller:</p> <ol> <li> <p>Byte (8-bit): This is the most basic data type in the 8051 microcontroller. It occupies one byte (8 bits) of memory and can represent values from 0 to 255 (unsigned) or -128 to 127 (signed).</p> </li> <li> <p>Word (16-bit): A word consists of two bytes (16 bits) of memory. It can represent larger values than a byte, ranging from 0 to 65535 (unsigned) or -32768 to 32767 (signed).</p> </li> <li> <p>Bit: The 8051 microcontroller provides support for bit-level operations. Individual bits within memory locations can be manipulated using bitwise operators. Bit variables are often used for flags, status indicators, or control signals.</p> </li> <li> <p>Data Pointer (DPTR): The Data Pointer is a 16-bit register used for accessing external memory locations. It is commonly used for indirect addressing and accessing data stored in external memory devices.</p> </li> <li> <p>Special Function Registers (SFRs): These are memory-mapped registers within the 8051 microcontroller that control various on-chip peripherals and functions. SFRs have specific addresses and bit-level access for configuring and controlling the microcontroller's behavior.</p> </li> </ol> <p>Directives in 8051 Microcontroller:</p> <ol> <li> <p>ORG (Origin): This directive specifies the starting address of the code or data in memory. It is used to define the memory location where the subsequent code or data will be stored.</p> </li> <li> <p>DB (Define Byte): DB directive is used to define byte-sized data elements in memory. It allows programmers to assign initial values to memory locations or reserve memory space for variables.</p> </li> <li> <p>DW (Define Word): DW directive is similar to DB but is used to define word-sized (16-bit) data elements in memory. It is commonly used for storing larger numerical values or data structures.</p> </li> <li> <p>DS (Define Storage): DS directive is used to reserve memory space without initializing it. It specifies the number of bytes to allocate in memory for variables or data structures.</p> </li> <li> <p>END: The END directive marks the end of the assembly source file. It informs the assembler that it has reached the end of the program and stops the assembly process.</p> </li> <li> <p>INCLUDE: The INCLUDE directive is used to include the contents of another file into the current assembly source file. It is helpful for modularizing code and reusing common routines or data definitions.</p> </li> </ol> <p>By utilizing these data types and directives effectively, programmers can write efficient and well-organized assembly language programs for the 8051 microcontroller, ensuring optimal utilization of resources and ease of maintenance.</p>"},{"location":"AMM/cae1/#15explain-the-psw-register-of-8051-microcontroller","title":"15.Explain the PSW Register of 8051 Microcontroller.","text":"<p>PSW Register in 8051 Microcontroller | Program Status Word</p> <ul> <li>Flags are single bit register and used to store the result of certain function after executing instruction. Flags are grouped inside PSW and PCON registers.</li> <li>PSW register in  8051 microcontroller  contains math flags and PCON contains general user flags.</li> <li>Math flags are grouped in PSW of microcontroller 8051 and they are Carry(C), Auxiliary Carry (AC), Over flow (OV), and Parity (P). The general user flags are GF0 and GF1 which are grouped in PCON register.</li> </ul> <p>PSW Register in 8051</p> <ul> <li>The PSW is accessible fully as an 8-bit register, with the address D0H.</li> <li>The bit pattern of this flag register is</li> </ul> <p></p> <p>Figure 1: Format of PSW register in 8051 Microcontroller</p> <p>Parity Bit (P)</p> <ul> <li> <ul> <li>This parity flag bit is used to show the number of 1s in the accumulator only. If the accumulator register contains an odd number of 1s, then this flag set to 1.</li> <li>If accumulator contains even number of 1s, then this flag cleared to 0.</li> </ul> </li> </ul> <p>Overflow Flag (OV)</p> <ul> <li> <ul> <li>This flag is set during ALU operations, to indicate overflow in the result. It is set to 1 if there is a carry out of either the D7 bit or the D6 bit of the accumulator.</li> <li>Overflow flag is set when arithmetic operations such as add and subtract result in sign conflict.</li> </ul> </li> <li> <ul> <li>The conditions under which the OV flag is set are as follows:         -   Positive + Positive = Negative         -   Negative + Negative = Positive         -   Positive \u2013 Negative = Negative         -   Negative \u2013 Positive = Positive</li> </ul> </li> </ul> <p>Register Bank Select Bits (RS1 And RS0)</p> <ul> <li> <ul> <li>These two bits are used to select one of four register banks of RAM. By setting and clearing these bits, registers R0-R7 are stored in one of four banks of RAM as follows.</li> </ul> </li> </ul> RS1 RS0 Bank Selected Address of Registers 0 0 Bank 0 00h-07h 0 1 Bank 1 08h-0Fh 1 0 Bank 2 10h-17h 1 1 Bank 3 18h-1Fh <ul> <li> <ul> <li>These bits are user-programmable. They can be set by the programmer to point to the correct register banks.</li> <li>The register bank selection in the programs can be changed using these two bits.</li> </ul> </li> </ul> <p>General-Purpose Flag (F0)</p> <ul> <li> <ul> <li>This is a user-programmable flag; the user can program and store any bit of his/her choice in this flag, using the bit address.</li> </ul> </li> </ul> <p>Auxiliary Carry Flag (AC)</p> <ul> <li> <ul> <li>It is used in association with BCD arithmetic. This flag is set when there is a carry out of the D3 bit of the accumulator.</li> </ul> </li> </ul> <p>Carry Flag (CY)</p> <ul> <li> <ul> <li>This flag is used to indicate the carry generated after arithmetic operations. It can also be used as an accumulator, to store one of the data bits for bit-related Boolean instructions.</li> </ul> </li> <li> <p>The 8051 supports bit manipulation instructions.</p> </li> <li>This means that in addition to the byte operations, bit operations can also be done using bit data.</li> <li>For this purpose, the contents of the PSW are bit-addressable.</li> </ul> <p></p> <p>Figure 2: Instructions that affect the flags in 8051 microcontroller</p>"},{"location":"AMM/cae1/#16list-the-features-of-8051-microcontroller","title":"16.List the features of 8051 Microcontroller.","text":"<ul> <li>CPU Core: 8-bit microcontroller with a Harvard architecture.</li> <li>Memory: Typically includes on-chip ROM, RAM, and EEPROM.</li> <li>I/O Ports: Multiple I/O ports for interfacing with external devices.</li> <li>Timers/Counters: Integrated timers/counters for time-sensitive applications.</li> <li>Serial Communication: UART for serial communication.</li> <li>Interrupt System: Supports external and internal interrupts.</li> <li>Clock Circuitry: Built-in oscillator or support for external clock sources.</li> </ul>"},{"location":"AMM/cae1/#17discuss-the-programming-model-of-microcontroller-8051","title":"17.Discuss the programming model of microcontroller 8051.","text":"<p>The programming model of the 8051 microcontroller provides a framework for understanding how instructions are executed, how data is accessed, and how the various components of the microcontroller interact. The programming model of the 8051 consists of several key elements, including registers, memory, and I/O ports. Let's discuss each component in detail:</p> <p>1. Registers:</p> <ul> <li>Accumulator (ACC): The accumulator is an 8-bit register used for arithmetic and logic operations. It holds one of the operands during these operations and stores the result.</li> <li>B Register: Similar to the accumulator, the B register is an 8-bit register used for arithmetic and logic operations. It can be used as a second accumulator or as a general-purpose register.</li> <li>Data Pointer (DPTR): The Data Pointer is a 16-bit register used for accessing external memory locations. It is commonly used for indirect addressing and accessing data stored in external memory devices.</li> <li>Program Counter (PC): The program counter is a 16-bit register that holds the address of the next instruction to be executed. It is automatically incremented after each instruction fetch.</li> <li>Stack Pointer (SP): The stack pointer is an 8-bit register that points to the top of the stack. It is used to manage subroutine calls and interrupt handling.</li> <li>Status Register (PSW): The status register, also known as the Program Status Word, is an 8-bit register that contains various flags indicating the outcomes of arithmetic and logic operations, as well as the status of the microcontroller.</li> <li>Timer/Counter Registers (TMRx, THx, TLx): The 8051 microcontroller has one or more timer/counter registers used for timing and counting operations. These registers are used to generate timing delays, measure time intervals, and interface with external devices.</li> </ul> <p>2. Memory:</p> <ul> <li>Internal RAM: The 8051 microcontroller typically contains on-chip random-access memory (RAM) used for storing data and variables during program execution. The size of the internal RAM varies depending on the specific model of the 8051.</li> <li>Internal ROM: Some variants of the 8051 microcontroller include on-chip read-only memory (ROM) used for storing the program code. The size of the internal ROM varies, and it typically contains the bootloader or firmware code.</li> <li>External RAM/ROM: The 8051 microcontroller can also interface with external memory devices such as RAM and ROM chips. The Data Pointer (DPTR) register is used for accessing external memory locations.</li> </ul> <p>3. I/O Ports:</p> <ul> <li>The 8051 microcontroller features multiple input/output (I/O) ports used for interfacing with external devices such as sensors, actuators, displays, and communication modules.</li> <li>Each I/O port typically consists of 8 bits and can be configured as input or output using software instructions.</li> <li>Special Function Registers (SFRs) are used to control and configure the behavior of the I/O ports.</li> </ul> <p></p> <p>In summary, the programming model of the 8051 microcontroller encompasses registers, memory, and I/O ports, which are essential for writing assembly language programs and controlling the behavior of the microcontroller. Understanding the programming model helps programmers effectively utilize the resources of the 8051 microcontroller and develop efficient embedded systems applications.</p>"},{"location":"AMM/cae1/#18explain-the-stack-of-microcontroller-8051","title":"18.Explain the Stack of microcontroller 8051.","text":"<p>Stack of Microcontroller 8051:</p> <ul> <li>The 8051 microcontroller uses a stack to store return addresses, register values, and other data during subroutine calls and interrupt handling.</li> <li>It typically consists of a stack pointer (SP) register, which points to the top of the stack.</li> <li>The stack grows downwards in memory, meaning that as items are pushed onto the stack, the stack pointer decrements.</li> <li>The stack is used to store the return address when a subroutine is called, allowing the program to return to the correct location after the subroutine finishes execution.</li> <li>Additionally, the stack is used to save the context (register values) when an interrupt occurs, ensuring that the main program can resume execution after handling the interrupt.</li> </ul>"},{"location":"AMM/cae1/#19illustrate-the-concept-of-register-bank-of-microcontroller-8051","title":"19.Illustrate the concept of register bank of microcontroller 8051.","text":"<p>Register Bank of Microcontroller 8051:</p> <ul> <li>The 8051 microcontroller features four register banks, labeled as bank 0, bank 1, bank 2, and bank 3.</li> <li>Each register bank contains the same set of registers: R0 to R7 (eight general-purpose registers) and a few special function registers (SFRs).</li> <li>The register banks are used to provide more register space for data storage and manipulation, especially in applications with a large number of variables or complex calculations.</li> <li>The 8051's architecture allows the programmer to switch between register banks using certain instructions, enabling efficient use of the available registers and facilitating context switching in multitasking applications.</li> </ul>"},{"location":"AMM/cae1/#20list-the-data-type-of-8051-describe-the-functions-of-assembler-directives-of-8051","title":"20.List the data type of 8051? Describe the functions of assembler directives of 8051.","text":"<p>Data Types of 8051 and Functions of Assembler Directives:</p> <ul> <li> <p>Data Types: The 8051 supports various data types, including:</p> <ul> <li>8-bit unsigned integers (unsigned char).</li> <li>16-bit unsigned integers (unsigned int).</li> <li>8-bit signed integers (signed char).</li> <li>16-bit signed integers (signed int).</li> <li>Bit (Boolean) data type.</li> </ul> </li> <li> <p>Assembler Directives: Assembler directives in 8051 assembly language provide instructions to the assembler rather than the CPU. They include:</p> <ul> <li>ORG: Specifies the origin address for the subsequent code or data.</li> <li>DB (Define Byte): Defines byte-sized data.</li> <li>DW (Define Word): Defines word-sized data.</li> <li>DS (Define Storage): Reserves memory space without initializing it.</li> <li>END: Marks the end of the assembly file.</li> <li>INCLUDE: Includes contents of another file in the current assembly file.</li> </ul> </li> </ul>"},{"location":"AMM/cae3/","title":"COMING SOON!","text":""},{"location":"CN/","title":"COMPUTER NETWORK","text":"Unit Topic Duration Unit I Introduction to Computer Networks and Logical Link Medium Access Control 8 Introduction Network architecture - Design Reference models - The OSI Reference Model - The TCP/IP Reference Model - A Comparison of the OSI and TCP/IP Reference Models Design Issues, Switching Techniques: Circuit and Packet Switching, Connectionless and Connection-oriented Services, Virtual Circuit and Datagram Subnets Autonomous system Unit II Network Layer-I 8 Routing Algorithms: Optimality principle, shortest path routing, flooding, Distance Vector routing, link state routing, hierarchical routing Network layer services, IP protocol, IPv4, Problems with IPv4, IPV6, Subnetting Network layer Protocols: ARP, RARP, ICMP, DHCP, Unicast Routing Algorithms: RIP, OSPF, BGP Unit III Transport Layer 8 UDP : UDP functionality, UDP Header TCP : TCP Features, byte-stream, Connection-oriented, TCP Header Format, 2-way, 3-way 32 Handshake, TCP State Diagram, TCP Sliding Window, Congestion Control Algorithms, Leaky Bucket, Token Bucket, Congestion Avoidance, TCP Tahoe, Fast Retransmit, Fast Recovery, Timer Management Unit IV Application Layer 6 Domain Name System (DNS), Naming and Address Schemes, DNS servers, Email: MIME, SMTP and POP3. Remote login, File Transfer Protocol (FTP), SNMP, DHCP and BOOTP. World Wide Web, HTTP Unit V WIRELESS LAN, MAN, WAN 6 Introduction (Infrastructure and Ad-hoc Networks), Fundamentals of WLAN \u2013 technical issues, Network Architecture, IEEE 802.11- physical layer, Mac Layer Mechanism, CSMA/CA, Bluetooth - Specification, Transport Layer, Middleware Protocol Group, Bluetooth Profiles of IEEE 802.16, Sensor Node Architecture (hardware components), Sensor Network Architectures"},{"location":"CN/#lab-manual","title":"Lab Manual","text":""},{"location":"CN/UNIT_1/","title":"Computer Network","text":""},{"location":"CN/UNIT_1/#computer-network-architecture","title":"Computer Network Architecture","text":"<p>Computer Network Architecture is defined as the physical and logical design of the software, hardware, protocols, and media of the transmission of data. Simply we can say that how computers are organized and how tasks are allocated to the computer.</p> <p>The two types of network architectures are used:</p> <p></p> <ul> <li>Peer-To-Peer network</li> <li>Client/Server network</li> </ul>"},{"location":"CN/UNIT_1/#peer-to-peer-network","title":"Peer-To-Peer network","text":"<ul> <li>Peer-To-Peer network is a network in which all the computers are linked together with equal privilege and responsibilities for processing the data.</li> <li>Peer-To-Peer network is useful for small environments, usually up to 10 computers.</li> <li>Peer-To-Peer network has no dedicated server.</li> <li>Special permissions are assigned to each computer for sharing the resources, but this can lead to a problem if the computer with the resource is down.</li> </ul>"},{"location":"CN/UNIT_1/#advantages-of-peer-to-peer-network","title":"Advantages Of Peer-To-Peer Network:","text":"<ul> <li>It is less costly as it does not contain any dedicated server.</li> <li>If one computer stops working but, other computers will not stop working.</li> <li>It is easy to set up and maintain as each computer manages itself.</li> </ul>"},{"location":"CN/UNIT_1/#disadvantages-of-peer-to-peer-network","title":"Disadvantages Of Peer-To-Peer Network:","text":"<ul> <li>In the case of Peer-To-Peer network, it does not contain the centralized system . Therefore, it cannot back up the data as the data is different in different locations.</li> <li>It has a security issue as the device is managed itself.</li> </ul>"},{"location":"CN/UNIT_1/#clientserver-network","title":"Client/Server Network","text":"<ul> <li>Client/Server network is a network model designed for the end users called clients, to access the resources such as songs, video, etc. from a central computer known as Server.</li> <li>The central controller is known as a  server  while all other computers in the network are called  clients.</li> <li>A server performs all the major operations such as security and network management.</li> <li>A server is responsible for managing all the resources such as files, directories, printer, etc.</li> <li>All the clients communicate with each other through a server. For example, if client1 wants to send some data to client 2, then it first sends the request to the server for the permission. The server sends the response to the client 1 to initiate its communication with the client 2.</li> </ul>"},{"location":"CN/UNIT_1/#advantages-of-clientserver-network","title":"Advantages Of Client/Server network:","text":"<ul> <li>A Client/Server network contains the centralized system. Therefore we can back up the data easily.</li> <li>A Client/Server network has a dedicated server that improves the overall performance of the whole system.</li> <li>Security is better in Client/Server network as a single server administers the shared resources.</li> <li>It also increases the speed of the sharing resources.</li> </ul>"},{"location":"CN/UNIT_1/#disadvantages-of-clientserver-network","title":"Disadvantages Of Client/Server network:","text":"<ul> <li>Client/Server network is expensive as it requires the server with large memory.</li> <li>A server has a Network Operating System(NOS) to provide the resources to the clients, but the cost of NOS is very high.</li> <li>It requires a dedicated network administrator to manage all the resources.</li> </ul>"},{"location":"CN/UNIT_1/#osi-model-layers-of-osi-model","title":"OSI Model \u2013 Layers of OSI Model","text":"<p>OSI stands for Open Systems Interconnection. It was developed by ISO \u2013 \u2018International Organization for Standardization\u2019, in the year 1984. It is a 7-layer architecture with each layer having specific functionality to perform. All these 7 layers work collaboratively to transmit the data from one person to another across the globe.</p> <p>Prerequisite:  Basics of Computer Networking</p>"},{"location":"CN/UNIT_1/#osi-model","title":"OSI Model","text":"<p>The OSI model, created in 1984 by ISO, is a reference framework that explains the process of transmitting data between computers. It is divided into seven layers that work together to carry out specialised network functions, allowing for a more systematic approach to networking.</p> <p></p>"},{"location":"CN/UNIT_1/#the-7-layers-of-the-osi-model","title":"The 7 layers of the OSI Model?","text":"<p>The OSI model consists of seven abstraction layers arranged in a top-down order:</p> <ol> <li>Physical Layer</li> <li>Data Link Layer</li> <li>Network Layer</li> <li>Transport Layer</li> <li>Session Layer</li> <li>Presentation Layer</li> <li>Application Layer</li> </ol>"},{"location":"CN/UNIT_1/#physical-layer-layer-1","title":"Physical Layer \u2013 Layer 1","text":"<p>The lowest layer of the OSI reference model is the physical layer. It is responsible for the actual physical connection between the devices. The physical layer contains information in the form of bits.  It is responsible for transmitting individual bits from one node to the next. When receiving data, this layer will get the signal received and convert it into 0s and 1s and send them to the Data Link layer, which will put the frame back together.</p> <p></p>"},{"location":"CN/UNIT_1/#functions-of-the-physical-layer","title":"Functions of the Physical Layer","text":"<ul> <li>Bit synchronization:  The physical layer provides the synchronization of the bits by providing a clock. This clock controls both sender and receiver thus providing synchronization at the bit level.</li> <li>Bit rate control:  The Physical layer also defines the transmission rate i.e. the number of bits sent per second.</li> <li>Physical topologies:  Physical layer specifies how the different, devices/nodes are arranged in a network i.e. bus, star, or mesh topology.</li> <li>Transmission mode:  Physical layer also defines how the data flows between the two connected devices. The various transmission modes possible are Simplex, half-duplex and full-duplex.</li> </ul> <p>Note:</p> <ol> <li>Hub, Repeater, Modem, and Cables are Physical Layer devices.</li> <li>Network Layer, Data Link Layer, and Physical Layer are also known as  Lower Layers  or  Hardware Layers.</li> </ol>"},{"location":"CN/UNIT_1/#data-link-layer-dll-layer-2","title":"Data Link Layer (DLL) \u2013 Layer 2","text":"<p>The data link layer is responsible for the node-to-node delivery of the message. The main function of this layer is to make sure data transfer is error-free from one node to another, over the physical layer. When a packet arrives in a network, it is the responsibility of the DLL to transmit it to the Host using its MAC address. The Data Link Layer is divided into two sublayers:</p> <ol> <li>Logical Link Control (LLC)</li> <li>Media Access Control (MAC)</li> </ol> <p>The packet received from the Network layer is further divided into frames depending on the frame size of the NIC(Network Interface Card). DLL also encapsulates Sender and Receiver\u2019s MAC address in the header.</p> <p>The Receiver\u2019s MAC address is obtained by placing an  ARP(Address Resolution Protocol) request onto the wire asking \u201cWho has that IP address?\u201d and the destination host will reply with its MAC address.</p>"},{"location":"CN/UNIT_1/#functions-of-the-data-link-layer","title":"Functions of the Data Link Layer","text":"<ul> <li>Framing: Framing is a function of the data link layer. It provides a way for a sender to transmit a set of bits that are meaningful to the receiver. This can be accomplished by attaching special bit patterns to the beginning and end of the frame.</li> <li>Physical addressing:  After creating frames, the Data link layer adds physical addresses (MAC addresses) of the sender and/or receiver in the header of each frame.</li> <li>Error control:  The data link layer provides the mechanism of error control in which it detects and retransmits damaged or lost frames.</li> <li>Flow Control:  The data rate must be constant on both sides else the data may get corrupted thus, flow control coordinates the amount of data that can be sent before receiving an acknowledgment.</li> <li>Access control: When a single communication channel is shared by multiple devices, the MAC sub-layer of the data link layer helps to determine which device has control over the channel at a given time.</li> </ul> <p>Note:</p> <ol> <li>Packet in the Data Link layer is referred to as  Frame.</li> <li>Data Link layer is handled by the NIC (Network Interface Card) and device drivers of host machines.</li> <li>Switch &amp; Bridge are Data Link Layer devices.</li> </ol>"},{"location":"CN/UNIT_1/#network-layer-layer-3","title":"Network Layer \u2013 Layer 3","text":"<p>The network layer works for the transmission of data from one host to the other located in different networks. It also takes care of packet routing i.e. selection of the shortest path to transmit the packet, from the number of routes available. The sender &amp; receiver\u2019s IP addresses are placed in the header by the network layer.</p>"},{"location":"CN/UNIT_1/#functions-of-the-network-layer","title":"Functions of the Network Layer","text":"<ul> <li>Routing:  The network layer protocols determine which route is suitable from source to destination. This function of the network layer is known as routing.</li> <li>Logical Addressing: To identify each device on Internetwork uniquely, the network layer defines an addressing scheme. The sender &amp; receiver\u2019s IP addresses are placed in the header by the network layer. Such an address distinguishes each device uniquely and universally.</li> </ul> <p>Note:</p> <ol> <li>Segment in the Network layer is referred to as  Packet.</li> <li>Network layer is implemented by networking devices such as routers and switches.</li> </ol>"},{"location":"CN/UNIT_1/#transport-layer-layer-4","title":"Transport Layer \u2013 Layer 4","text":"<p>The transport layer provides services to the application layer and takes services from the network layer. The data in the transport layer is referred to as  Segments. It is responsible for the End to End Delivery of the complete message. The transport layer also provides the acknowledgment of the successful data transmission and re-transmits the data if an error is found.</p> <p>At the sender\u2019s side: The transport layer receives the formatted data from the upper layers, performs  Segmentation, and also implements  Flow &amp; Error control  to ensure proper data transmission. It also adds Source and Destination port numbers in its header and forwards the segmented data to the Network Layer.</p> <p>Note:  The sender needs to know the port number associated with the receiver\u2019s application.</p> <p>Generally, this destination port number is configured, either by default or manually. For example, when a web application requests a web server, it typically uses port number 80, because this is the default port assigned to web applications. Many applications have default ports assigned.</p> <p>At the receiver\u2019s side: Transport Layer reads the port number from its header and forwards the Data which it has received to the respective application. It also performs sequencing and reassembling of the segmented data.</p>"},{"location":"CN/UNIT_1/#functions-of-the-transport-layer","title":"Functions of the Transport Layer","text":"<ul> <li>Segmentation and Reassembly:  This layer accepts the message from the (session) layer, and breaks the message into smaller units. Each of the segments produced has a header associated with it. The transport layer at the destination station reassembles the message.</li> <li>Service Point Addressing:  To deliver the message to the correct process, the transport layer header includes a type of address called service point address or port address. Thus by specifying this address, the transport layer makes sure that the message is delivered to the correct process.</li> </ul>"},{"location":"CN/UNIT_1/#services-provided-by-transport-layer","title":"Services Provided by Transport Layer","text":"<ol> <li>Connection-Oriented Service</li> <li>Connectionless Service</li> </ol> <p>1. Connection-Oriented Service:  It is a three-phase process that includes</p> <ul> <li>Connection Establishment</li> <li>Data Transfer</li> <li>Termination/disconnection</li> </ul> <p>In this type of transmission, the receiving device sends an acknowledgment, back to the source after a packet or group of packets is received. This type of transmission is reliable and secure.</p> <p>2. Connectionless service:  It is a one-phase process and includes Data Transfer. In this type of transmission, the receiver does not acknowledge receipt of a packet. This approach allows for much faster communication between devices. Connection-oriented service is more reliable than connectionless Service.</p> <p>Note:</p> <ol> <li>Data in the Transport Layer is called  Segments.</li> <li>Transport layer is operated by the Operating System. It is a part of the OS and communicates with the Application Layer by making system calls.</li> <li>The transport layer is called as  Heart of the OSI  model.</li> <li>Device or Protocol Use :  TCP, UDP NetBIOS, PPTP</li> </ol>"},{"location":"CN/UNIT_1/#session-layer-layer-5","title":"Session Layer \u2013 Layer 5","text":"<p>This layer is responsible for the establishment of connection, maintenance of sessions, and authentication, and also ensures security.</p>"},{"location":"CN/UNIT_1/#functions-of-the-session-layer","title":"Functions of the Session Layer","text":"<ul> <li>Session establishment, maintenance, and termination:  The layer allows the two processes to establish, use and terminate a connection.</li> <li>Synchronization:  This layer allows a process to add checkpoints that are considered synchronization points in the data. These synchronization points help to identify the error so that the data is re-synchronized properly, and ends of the messages are not cut prematurely and data loss is avoided.</li> <li>Dialog Controller:  The session layer allows two systems to start communication with each other in half-duplex or full-duplex.</li> </ul> <p>Note:</p> <ol> <li>All the below 3 layers(including Session Layer) are integrated as a single layer in the TCP/IP model as the ????pplication Layer\u201d.</li> <li>Implementation of these 3 layers is done by the network application itself. These are also known as  Upper Layers or Software Layers.</li> <li>Device or Protocol Use :  NetBIOS, PPTP.</li> </ol> <p>for Example:-</p> <p>Let us consider a scenario where a user wants to send a message through some Messenger application running in his browser. The \u201cMessenger\u201d here acts as the application layer which provides the user with an interface to create the data. This message or so-called Data is compressed, encrypted (if any secure data), and converted into bits (0\u2019s and 1\u2019s) so that it can be transmitted.</p> <p></p> <p>Communication in Session Layer</p>"},{"location":"CN/UNIT_1/#presentation-layer-layer-6","title":"Presentation Layer \u2013 Layer 6","text":"<p>The presentation layer is also called the  Translation layer. The data from the application layer is extracted here and manipulated as per the required format to transmit over the network.</p>"},{"location":"CN/UNIT_1/#functions-of-the-presentation-layer","title":"Functions of the Presentation Layer","text":"<ul> <li>Translation:  For example, ASCII to EBCDIC.</li> <li>Encryption/ Decryption:  Data encryption translates the data into another form or code. The encrypted data is known as the ciphertext and the decrypted data is known as plain text. A key value is used for encrypting as well as decrypting data.</li> <li>Compression:  Reduces the number of bits that need to be transmitted on the network.</li> </ul> <p>Note:  Device or Protocol Use :  JPEG, MPEG, GIF</p>"},{"location":"CN/UNIT_1/#application-layer-layer-7","title":"Application Layer \u2013 Layer 7","text":"<p>At the very top of the OSI Reference Model stack of layers, we find the Application layer which is implemented by the network applications. These applications produce the data, which has to be transferred over the network. This layer also serves as a window for the application services to access the network and for displaying the received information to the user.</p> <p>Example: Application \u2013 Browsers, Skype Messenger, etc.</p> <p>Note:  1. The application Layer is also called Desktop Layer.</p> <ol> <li>Device or Protocol Use :  SMTP</li> </ol>"},{"location":"CN/UNIT_1/#functions-of-the-application-layer","title":"Functions of the Application Layer","text":"<p>The main functions of application layer are given below.</p> <ul> <li>Network Virtual Terminal: It allows a user to log on to a remote host.</li> <li>FTAM- File transfer access and management : This application allows a user to     access file in a remote host, retrieve files in remote host and manage or     control files from a remote computer.</li> <li>Mail Services : Provide email service.</li> <li>Directory Services : This application provides distributed database sources     and access for global information about various objects and services.</li> </ul> <p>TCP/IP  Reference Model is a four-layered suite of communication protocols. It was developed by the DoD (Department of Defence) in the 1960s. It is named after the two main protocols that are used in the model, namely, TCP and IP.  TCP  stands for \"Transmission Control Protocol\" and  IP  stands for \"Internet Protocol\".</p> <p>The four layers in the TCP/IP protocol suite are \u2212</p> <ol> <li>Host-to- Network Layer \u2212It is the lowest layer that is concerned with the physical transmission of data. TCP/IP does not specifically define any protocol here but supports all the standard protocols.</li> <li>Internet Layer \u2212It defines the protocols for logical transmission of data over the network. The main protocol in this layer is  Internet Protocol (IP)  and it is supported by the protocols  ICMP,  IGMP,  RARP, and  ARP.</li> <li>Transport Layer \u2212  It is responsible for error-free end-to-end delivery of data. The protocols defined here are Transmission Control Protocol (TCP) and  User Datagram Protocol (UDP).</li> <li>Application Layer \u2212  This is the topmost layer and defines the interface of host programs with the transport layer services. This layer includes all high-level protocols like  Telnet,  DNS,  HTTP,  FTP,  SMTP, etc.</li> </ol> <p>The following diagram shows the layers and the protocols in each of the layers \u2212</p> <p></p> <p>[  </p>"},{"location":"CN/UNIT_1/#the-tcpip-reference-model","title":"The TCP/IP Reference Model","text":""},{"location":"CN/UNIT_1/#difference-between-osi-and-tcpip-reference-model","title":"Difference between OSI and TCP/IP Reference Model","text":"Feature OSI TCP/IP Representation Open System Interconnection (OSI) Transmission Control Protocol/Internet Protocol Independence Generic, protocol independent Depends on standard protocols Development Model first, protocols created later Protocols first, then built the model Quality of Services Provides quality services Does not provide quality services Administration and Conventions Defines administration, interfaces, and conventions Does not mention services, interfaces, and protocols Protocol Visibility Protocols are hidden and can be replaced easily Protocols are not hidden and cannot be easily replaced Complexity More complex than TCP/IP Simpler than OSI Connection Types in Network Layer Both connection and connectionless oriented transmission Connectionless transmission Connection Types in Transport Layer Connection-oriented transmission Supports both connection and connectionless-oriented transmission Approach Vertical Horizontal Header Size (Minimum) 5 bytes 20 bytes Protocol Handling Protocols may be unknown and replaced as technology evolves Returning protocol is not difficult"},{"location":"CN/UNIT_1/#design-issues","title":"Design Issues","text":"<p>In the code generation phase, various issues can arises:</p> <ol> <li>Input to the code generator</li> <li>Target program</li> <li>Memory management</li> <li>Instruction selection</li> <li>Register allocation</li> <li>Evaluation order</li> </ol>"},{"location":"CN/UNIT_1/#1-input-to-the-code-generator","title":"1. Input to the code generator","text":"<ul> <li>The input to the code generator contains the intermediate representation of the source program and the information of the symbol table. The source program is produced by the front end.</li> <li>Intermediate representation has the several choices:     a) Postfix notation     b) Syntax tree     c) Three address code</li> <li>We assume front end produces low-level intermediate representation i.e. values of names in it can directly manipulated by the machine instructions.</li> <li>The code generation phase needs complete error-free intermediate code as an input requires.</li> </ul>"},{"location":"CN/UNIT_1/#2-target-program","title":"2. Target program:","text":"<p>The target program is the output of the code generator. The output can be:</p> <p>a)  Assembly language:  It allows subprogram to be separately compiled.</p> <p>b)  Relocatable machine language:  It makes the process of code generation easier.</p> <p>c)  Absolute machine language:  It can be placed in a fixed location in memory and can be executed immediately.</p>"},{"location":"CN/UNIT_1/#3-memory-management","title":"3. Memory management","text":"<ul> <li>During code generation process the symbol table entries have to be mapped to actual p addresses and levels have to be mapped to instruction address.</li> <li>Mapping name in the source program to address of data is co-operating done by the front end and code generator.</li> <li>Local variables are stack allocation in the activation record while global variables are in static area.</li> </ul>"},{"location":"CN/UNIT_1/#4-instruction-selection","title":"4. Instruction selection:","text":"<ul> <li>Nature of instruction set of the target machine should be complete and uniform.</li> <li>When you consider the efficiency of target machine then the instruction speed and machine idioms are important factors.</li> <li>The quality of the generated code can be determined by its speed and size.</li> </ul>"},{"location":"CN/UNIT_1/#example","title":"Example:","text":"<p>The Three address code is:</p> <ol> <li>a:= b + c</li> <li>d:= a + e</li> </ol> <p>Inefficient assembly code is:</p> <ol> <li>MOV b, R0 R0\u2192b</li> <li>ADD c, R0 R0 c + R0</li> <li>MOV R0, a a \u2192 R0</li> <li>MOV a, R0 R0\u2192 a</li> <li>ADD e, R0 R0 \u2192 e + R0</li> <li>MOV R0, d d \u2192 R0</li> </ol>"},{"location":"CN/UNIT_1/#5-register-allocation","title":"5. Register allocation","text":"<p>Register can be accessed faster than memory. The instructions involving operands in register are shorter and faster than those involving in memory operand.</p> <p>The following sub problems arise when we use registers:</p> <p>Register allocation:  In register allocation, we select the set of variables that will reside in register.</p> <p>Register assignment:  In Register assignment, we pick the register that contains variable.</p> <p>Certain machine requires even-odd pairs of registers for some operands and result.</p>"},{"location":"CN/UNIT_1/#for-example","title":"For example:","text":"<p>Consider the following division instruction of the form:</p> <ol> <li>D x, y</li> </ol> <p>Where,</p> <p>x  is the dividend even register in even/odd register pair</p> <p>y  is the divisor</p> <p>Even register  is used to hold the reminder.</p> <p>Old register  is used to hold the quotient.</p>"},{"location":"CN/UNIT_1/#6-evaluation-order","title":"6. Evaluation order","text":"<p>The efficiency of the target code can be affected by the order in which the computations are performed. Some computation orders need fewer registers to hold results of intermediate than others.</p>"},{"location":"CN/UNIT_1/#switching-techniques","title":"Switching Techniques","text":"<p>In large networks, there may be more than one paths for transmitting data from  sender  to receiver. Selecting a path that data must take out of the available options is called  switching. There are two popular switching techniques \u2013 circuit switching and packet switching.</p> <p></p>"},{"location":"CN/UNIT_1/#circuit-switching","title":"Circuit Switching","text":"<p>When a dedicated path is established for data transmission between sender and receiver, it is called circuit switching. When any network node wants to send data, be it audio, video, text or any other type of information, a  call request signal  is sent to the receiver and acknowledged back to ensure availability of dedicated path. This dedicated path is then used to send data. ARPANET used circuit switching for communication over the network.</p>"},{"location":"CN/UNIT_1/#advantages-of-circuit-switching","title":"Advantages of Circuit Switching","text":"<p>Circuit switching provides these advantages over other switching techniques \u2212</p> <ul> <li>Once path is set up, the only delay is in data transmission speed</li> <li>No problem of congestion or garbled message</li> </ul>"},{"location":"CN/UNIT_1/#disadvantages-of-circuit-switching","title":"Disadvantages of Circuit Switching","text":"<p>Circuit switching has its disadvantages too \u2212</p> <ul> <li> <p>Long set up time is required</p> </li> <li> <p>A request token must travel to the receiver and then acknowledged before any transmission can happen</p> </li> <li> <p>Line may be held up for a long time</p> </li> </ul>"},{"location":"CN/UNIT_1/#packet-switching","title":"Packet Switching","text":"<p>As we discussed, the major problem with circuit switching is that it needs a dedicated line for transmission. In packet switching, data is broken down into small packets with each packet having source and destination addresses, travelling from one router to the next router.</p>"},{"location":"CN/UNIT_1/#connection-oriented-and-connectionless-service","title":"Connection-Oriented and Connectionless Service","text":"<p>Data communication is a telecommunication network to send and receive data between two or more computers over the same or different network. There are two ways to establish a connection before sending data from one device to another, that are  Connection-Oriented  and  Connectionless Service. Connection-oriented service involves the creation and termination of the connection for sending the data between two or more devices. In contrast, connectionless service does not require establishing any connection and termination process for transferring the data over a network.</p>"},{"location":"CN/UNIT_1/#connection-oriented-service","title":"Connection-Oriented Service","text":"<p>A connection-oriented service is a network service that was designed and developed after the telephone system. A connection-oriented service is used to create an end to end connection between the sender and the receiver before transmitting the data over the same or different networks. In connection-oriented service, packets are transmitted to the receiver in the same order the sender has sent them. It uses a handshake method that creates a connection between the user and sender for transmitting the data over the network. Hence it is also known as a reliable network service.</p> <p></p> <p>Suppose, a sender wants to send data to the receiver. Then, first, the sender sends a request packet to a receiver in the form of an  SYN  packet. After that, the receiver responds to the sender's request with an (SYN-ACK) signal/packets. That represents the confirmation is received by the receiver to start the communication between the sender and the receiver. Now a sender can send the message or data to the receiver.</p> <p>Similarly, a receiver can respond or send the data to the sender in the form of packets. After successfully exchanging or transmitting data, a sender can terminate the connection by sending a signal to the receiver. In this way, we can say that it is a reliable network service.</p>"},{"location":"CN/UNIT_1/#tcp","title":"TCP","text":"<p>TCP (Transmission Control Protocol)  is a connection-oriented protocol that allows communication between two or more computer devices by establishing connections in the same or different networks. It is the most important protocol that uses  internet protocol  to transfer the data from one end to another. Hence, it is sometimes referred to as TCP/IP. It ensures that the connection is established and maintained until the data packet is transferring between the sender and receiver is complete.</p>"},{"location":"CN/UNIT_1/#connectionless-service","title":"Connectionless Service","text":"<p>A connection is similar to a  postal system, in which each letter takes along different route paths from the source to the destination address. Connectionless service is used in the network system to transfer data from one end to another end without creating any connection. So it does not require establishing a connection before sending the data from the sender to the receiver. It is not a reliable network service because it does not guarantee the transfer of data packets to the receiver, and data packets can be received in any order to the receiver. Therefore we can say that the data packet does not follow a  defined  path. In connectionless service, the transmitted data packet is not received by the receiver due to network congestion, and the data may be lost.</p> <p></p> <p>For example, a sender can directly send any data to the receiver without establishing any connection because it is a connectionless service. Data sent by the sender will be in the packet or data streams containing the receiver's address. In connectionless service, the data can be travelled and received in any order. However, it does not guarantee to transfer of the packets to the right destination.</p>"},{"location":"CN/UNIT_1/#udp","title":"UDP","text":"<p>The  UDP (User Datagram Protocol)  is a connectionless protocol that allows communication between two or more devices without establishing any connection. In this protocol, a sender sends the data packets to the receiver that holds the destination address. A UDP does not ensure to deliver the data packets to the correct destination, and it does not generate any acknowledgment about the sender's data. Similarly, it does not acknowledge the receiver about the data. Hence, it is an unreliable protocol.</p> S. No Comparison Parameter Connection-oriented Service Connectionless Service 1. Related System Designed and developed based on the telephone system. Service based on the postal system. 2. Definition Used to create an end-to-end connection between the senders and receivers before transmitting data over the same or different networks. Used to transfer data packets between senders and receivers without creating any connection. 3. Virtual Path Creates a virtual path between the sender and receiver. Does not create any virtual connection or path between the sender and receiver. 4. Authentication Requires authentication before transmitting data packets to the receiver. Does not require authentication before transferring data packets. 5. Data Packets Path All data packets are received in the same order as sent by the sender. Not all data packets are received in the same order as sent by the sender. 6. Bandwidth Requirement Requires higher bandwidth to transfer data packets. Requires low bandwidth to transfer data packets. 7. Data Reliability More reliable connection service, guarantees data packet transfer from one end to the other end with a connection. Not a reliable connection service, does not guarantee the transfer of data packets from one end to another for establishing a connection. 8. Congestion No congestion as it provides an end-to-end connection between sender and receiver during data transmission. May be congestion due to not providing an end-to-end connection between the source and receiver for data packet transmission. 9. Examples Transmission Control Protocol (TCP) is an example of a connection-oriented service. User Datagram Protocol (UDP), Internet Protocol (IP), and Internet Control Message Protocol (ICMP) are examples of connectionless service."},{"location":"CN/UNIT_1/#virtual-circuit-in-computer-network","title":"Virtual Circuit in Computer Network","text":"<p>Virtual Circuit  is the computer network providing connection-oriented service. It is a connection-oriented network. In virtual circuit resource are reserve for the time interval of data transmission between two nodes. This network is a highly reliable medium of transfer. Virtual circuits are costly to implement.</p> <p></p> <p>Working of Virtual Circuit:</p> <ul> <li>In the first step a medium is set up between the two end nodes.</li> <li>Resources are reserved for the transmission of packets.</li> <li>Then a signal is sent to sender to tell the medium is set up and transmission can be started.</li> <li>It ensures the transmission of all packets.</li> <li>A global header is used in the first packet of the connection.</li> <li>Whenever data is to be transmitted a new connection is set up.</li> </ul> <p>Congestion Control in Virtual Circuit: Once the congestion is detected in virtual circuit network, closed-loop techniques is used. There are different approaches in this technique:</p> <ul> <li>No new connection \u2013     No new connections are established when the congestion is detected. This approach is used in telephone networks where no new calls are established when the exchange is overloaded.</li> <li>Participation of congested router invalid \u2013     Another approach to control congestion is allow all new connections but route these new connections in such a way that congested router is not part of this route.</li> <li>Negotiation \u2013     To negotiate different parameters between sender and receiver of the network, when the connection is established. During the set up time, host specifies the shape and volume of the traffic, quality of service and other parameters.</li> </ul> <p>Advantages of Virtual Circuit:</p> <ol> <li>Packets are delivered to the receiver in the same order sent by the sender.</li> <li>Virtual circuit is a reliable network circuit.</li> <li>There is no need for overhead in each packet.</li> <li>Single global packet overhead is used in virtual circuit.</li> </ol> <p>Disadvantages of Virtual Circuit:</p> <ol> <li>Virtual circuit is costly to implement.</li> <li>It provides only connection-oriented service.</li> <li>Always a new connection set up is required for transmission.</li> </ol>"},{"location":"CN/UNIT_1/#datagram-network","title":"Datagram Network","text":"<p>In a connectionless communication systems, datagram refers to the smallest unit via which data is transmitted. Datagrams are data packets which contain adequate header information so that they can be individually routed by all intermediate network switching devices to the destination. These networks are called datagram networks since communication occurs via datagrams. They exist in packet switching networks.</p>"},{"location":"CN/UNIT_1/#features-of-datagram-networks","title":"Features of Datagram Networks","text":"<ul> <li> <p>Datagram switching is done at the network layer of the communication system.</p> </li> <li> <p>In datagram networks, each data packet or datagram is routed independently from the source to the destination even if they belong to the same message. The network treats the packet as if it exists alone.</p> </li> <li> <p>Since the datagrams are treated as independent units, no dedicated path is fixed for data transfer. Each datagram is routed by the intermediate routers using dynamically changing routing tables. So two successive packets from the source may follow completely separate routes to reach destination.</p> </li> <li> <p>In these networks, no prior resource allocation is done for the individual packets. This implies that no resources like buffers, processors, bandwidth, etc. are reserved before the communication commences.</p> </li> <li> <p>In datagram networks, resources are allocated on demand on a First\u2212Come First\u2212Serve (FCFS) basis. When a packet arrives at a router, the packet must wait if there are other packets being processed, irrespective of its source or destination.</p> </li> <li> <p>Datagram communication is generally guided by User Datagram Protocol or UDP.</p> </li> </ul> <p>The following diagram shows datagram packets being send by host H1 to host H2. The four datagram packets labelled as A, B, C and D, all belonging to same message are being routed separately via separate routes. The packets in the message arrives in the destination out of order. It is the responsibility of H2 to reorder the packets in order to retrieve the original message.</p> <p></p>"},{"location":"CN/UNIT_1/#autonomous-system","title":"Autonomous System","text":"<p>Autonomous System (AS)  is a group of routers and networks working under a single administrative domain. It is a 16-bit value that defines the routing domain of the routers. These numbers range from 1 to 65535.  </p> <ul> <li> <p>Public Autonomous System Number \u2013     These are 16-bit values that range from 1 to 64511. The service provider will provide a public AS if the customer is connected to more than one ISPs such as multihoming. A global autonomous number, which will be unique, is provided when the customer wants to propagate its BGP routes through 2 ISPs.  </p> </li> <li> <p>Private Autonomous system Number \u2013     Private Autonomous System Number are 16-bit values that range from 64512 to 65535. The service provider will provide a private autonomous system number to the customer when the customer wants multi-connection to a single ISP (single home or dual home network) but not to more than one ISPs. These are provided in order to conserve the autonomous system numbers.  </p> </li> <li> <p>Assigning of AS numbers \u2013     The Autonomous numbers are first assigned by IANA (Internet Assign Number Authority) to the respective regional registries. Further, the regional registry distribute these autonomous numbers (from the block of autonomous numbers provided by IANA) to entities within their designated area.  </p> </li> <li> <p>Source IP address: The source is the one who is sending the data.</p> </li> <li>Destination IP address: The destination is a host that receives the data from the sender.</li> <li>Header length</li> <li>Packet length</li> <li>TTL (Time to Live): The number of hops occurs before the packet gets discarded.</li> <li>Transport protocol: The transport protocol used by the internet protocol, either it can be TCP or UDP.</li> </ul> <p>There is a total of 14 fields exist in the IP header, and one of them is optional.</p> <p>Payload:  Payload is the data that is to be transported.</p>"},{"location":"CN/UNIT_1/#references","title":"References","text":"<p>https://www.javatpoint.com/computer-network-architecture https://www.geeksforgeeks.org/open-systems-interconnection-model-osi/ https://www.tutorialspoint.com/The-TCP-IP-Reference-Model https://www.tutorialspoint.com/difference-between-osi-and-tcp-ip-reference-model https://www.javatpoint.com/design-issues https://www.tutorialspoint.com/communication_technologies/communication_technologies_switching_techniques.htm https://www.javatpoint.com/connection-oriented-vs-connectionless-service https://www.geeksforgeeks.org/virtual-circuit-in-computer-network/ https://www.tutorialspoint.com/datagram-network https://www.geeksforgeeks.org/administrative-distance-ad-and-autonomous-system-as/</p>"},{"location":"CN/UNIT_2/","title":"Optimality Principle in Network Topology","text":""},{"location":"CN/UNIT_2/#classification-of-routing-algorithms","title":"Classification of Routing Algorithms","text":"<p>Routing is the process of establishing the routes that data packets must follow to reach the destination. In this process, a routing table is created which contains information regarding routes that data packets follow. Various routing algorithms are used for the purpose of deciding which route an incoming data packet needs to be transmitted on to reach the destination efficiently.</p>"},{"location":"CN/UNIT_2/#classification-of-routing-algorithms_1","title":"Classification of Routing Algorithms","text":"<p>The routing algorithms can be classified as follows:</p> <ol> <li>Adaptive Algorithms</li> <li>Non-Adaptive Algorithms</li> <li>Hybrid Algorithms</li> </ol> <p></p> <p>Types of Routing Algorithm</p>"},{"location":"CN/UNIT_2/#1-adaptive-algorithms","title":"1. Adaptive Algorithms","text":"<p>These are the algorithms that change their  routing  decisions whenever network topology or traffic load changes. The changes in routing decisions are reflected in the topology as well as the traffic of the network. Also known as  dynamic routing, these make use of dynamic information such as current topology, load, delay, etc. to select routes. Optimization parameters are distance, number of hops, and estimated transit time.</p> <p>Further, these are classified as follows:</p> <ul> <li>Isolated:  In this method each, node makes its routing decisions using the information it has without seeking information from other nodes. The sending nodes don\u2019t have information about the status of a particular link. The disadvantage is that packets may be sent through a congested network which may result in delay. Examples: Hot potato routing, and backward learning.</li> <li>Centralized:  In this method, a centralized node has entire information about the network and makes all the routing decisions. The advantage of this is only one node is required to keep the information of the entire network and the disadvantage is that if the central node goes down the entire network is done. The link state algorithm is referred to as a centralized algorithm since it is aware of the cost of each link in the network.</li> <li>Distributed:  In this method, the node receives information from its neighbors and then takes the decision about routing the packets. A disadvantage is that the packet may be delayed if there is a change in between intervals in which it receives information and sends packets. It is also known as a decentralized algorithm as it computes the least-cost path between source and destination.</li> </ul>"},{"location":"CN/UNIT_2/#2-non-adaptive-algorithms","title":"2. Non-Adaptive Algorithms","text":"<p>These are the algorithms that do not change their routing decisions once they have been selected. This is also known as  static routing as a route to be taken is computed in advance and downloaded to routers when a router is booted.</p> <p>Further, these are classified as follows:</p> <ul> <li>Flooding:  This adapts the technique in which every incoming packet is sent on every outgoing line except from which it arrived. One problem with this is that packets may go in a loop and as a result of which a node may receive duplicate packets. These problems can be overcome with the help of sequence numbers, hop count, and spanning trees.</li> <li>Random walk:  In this method, packets are sent host by host or node by node to one of its neighbors randomly. This is a highly robust method that is usually implemented by sending packets onto the link which is least queued.</li> </ul> <p></p> <p>Random Walk</p>"},{"location":"CN/UNIT_2/#3-hybrid-algorithms","title":"3. Hybrid Algorithms","text":"<p>As the name suggests, these algorithms are a combination of both adaptive and non-adaptive algorithms. In this approach, the network is divided into several regions, and each region uses a different algorithm. Further, these are classified as follows:</p> <ul> <li>Link-state:  In this method, each router creates a detailed and complete map of the network which is then shared with all other routers. This allows for more accurate and efficient routing decisions to be made.</li> <li>Distance vector:  In this method, each router maintains a table that contains information about the distance and direction to every other node in the network. This table is then shared with other routers in the network. The disadvantage of this method is that it may lead to routing loops.</li> </ul>"},{"location":"CN/UNIT_2/#introduction","title":"Introduction :","text":"<p>A general statement is made about optimal routes without regard to network topology or traffic. This statement is known as the optimality principle( Bellman,1975).</p>"},{"location":"CN/UNIT_2/#statement-of-the-optimality-principle","title":"Statement of the optimality principle :","text":"<p>It states that if the router J is on the optimal path from router I to router K, then the optimal path from J to K also falls along the same route. Call the route from I to J  r1  and the rest of the route r2. it could be concatenated with r1  to improve the route from I to K, contradicting our statement that r1r2  is optimal only if a route better than r2 existed from J to K.</p>"},{"location":"CN/UNIT_2/#sink-tree-for-routers","title":"Sink Tree for routers :","text":"<p>We can see that the set of optimal routes from all sources to a given destination from a tree rooted at the destination as a directed consequence of the optimality principle. This tree is called a  sink tree  and is illustrated in fig(1).</p>"},{"location":"CN/UNIT_2/#description-of-figure","title":"Description of figure :","text":"<p>In the given figure the distance metric is the number of hops. Therefore, the goal of all routing algorithms is to discover and use the sink trees for all routers.</p> <p></p> <p>(a) A network</p> <p></p> <p>(b) A sink tree for router B</p> <p>The sink tree is not unique also other trees with the same path lengths may exist. If we allow all of the possible paths to be chosen, the tree becomes a more general structure called a  DAG (Directed Acyclic Graph). DAGs have no loops. We will use sink trees as a convenient shorthand for both cases. we will take technical assumption for both cases that the paths do not interfere with each other so, for example, a traffic jam on one path will not cause another path to divert.</p>"},{"location":"CN/UNIT_2/#conclusion","title":"Conclusion :","text":"<p>The sink tree does not contain any loops, so each packet will be delivered within a finite and bounded number of hops. In practice, life is not quite easy. Links and routers can go on and come back up during operation, so different routers may have different ideas about the current topology. Also, we have found the issue of whether each router has to individually acquire the information on which to base its sink tree computation or whether this information is collected by some other means. Sink tree and the optimality principle provide a benchmark against which other routing algorithms can be measured.</p>"},{"location":"CN/UNIT_2/#shortest-path-routing-in-computer-network","title":"Shortest Path Routing in Computer Network?","text":"<p>In this algorithm, to select a route, the algorithm discovers the shortest path between two nodes. It can use multiple hops, the geographical area in kilometres or labelling of arcs for measuring path length.</p> <p>The labelling of arcs can be done with mean queuing, transmission delay for a standard test packet on an hourly basis, or computed as a function of bandwidth, average distance traffic, communication cost, mean queue length, measured delay or some other factors.</p> <p>In shortest path routing, the topology communication network is defined using a directed weighted graph. The nodes in the graph define switching components and the directed arcs in the graph define communication connection between switching components. Each arc has a weight that defines the cost of sharing a packet between two nodes in a specific direction.</p> <p>This cost is usually a positive value that can denote such factors as delay, throughput, error rate, financial costs, etc. A path between two nodes can go through various intermediary nodes and arcs. The goal of shortest path routing is to find a path between two nodes that has the lowest total cost, where the total cost of a path is the sum of arc costs in that path.</p> <p>For example, Dijikstra uses the nodes labelling with its distance from the source node along the better-known route. Initially, all nodes are labelled with infinity, and as the algorithm proceeds, the label may change. The labelling graph is displayed in the figure.</p> <p></p> <p>It can be done in various passes as follows, with A as the source.</p> <ul> <li> <p>Pass 1. B (2, A), C(\u221e,\u2212), F(\u221e,\u2212), e(\u221e,\u2212), d(\u221e,\u2212), G 60</p> </li> <li> <p>Pass 2. B (2, A), C(4, B), D(5, B), E(4, B), F(\u221e,\u2212),G(\u221e,\u2212)</p> </li> <li> <p>Pass 3. B(2, A), C(4, B), D(5, B), E(4, B), F(7, C), G(9, D)</p> </li> </ul> <p>We can see that there can be two paths between A and G. One follows through ABCFG and the other through ABDG. The first one has a path length of 11, while the second one has 9. Hence, the second one, as G (9, D), is selected. Similarly, Node D has also three paths from A as ABD, ABCD and ABED. The first one has a path length of 5 rest two have 6. So, the first one is selected.</p> <p>All nodes are searched in various passes, and finally, the routes with the shortest path lengths are made permanent, and the nodes of the path are used as a working node for the next round.</p>"},{"location":"CN/UNIT_2/#flooding-in-computer-network","title":"Flooding in Computer Network","text":"<p>Flooding is a  non-adaptive routing technique  following this simple method: when a data packet arrives at a router, it is sent to all the outgoing links except the one it has arrived on.</p> <p>For example, let us consider the  network  in the figure, having six routers that are connected through transmission lines.</p> <p></p> <p>Using flooding technique \u2212</p> <ul> <li> <p>An incoming packet to A, will be sent to B, C and D.</p> </li> <li> <p>B will send the packet to C and E.</p> </li> <li> <p>C will send the packet to B, D and F.</p> </li> <li> <p>D will send the packet to C and F.</p> </li> <li> <p>E will send the packet to F.</p> </li> <li> <p>F will send the packet to C and E.</p> </li> </ul>"},{"location":"CN/UNIT_2/#types-of-flooding","title":"Types of Flooding","text":"<p>Flooding may be of three types \u2212</p> <ul> <li> <p>Uncontrolled flooding  \u2212 Here, each router unconditionally transmits the incoming data packets to all its neighbours.</p> </li> <li> <p>Controlled flooding  \u2212 They use some methods to control the transmission of packets to the neighbouring nodes. The two popular algorithms for controlled flooding are Sequence Number Controlled Flooding (SNCF) and Reverse Path Forwarding (RPF).</p> </li> <li> <p>Selective flooding  \u2212 Here, the routers don't transmit the incoming packets only along those paths which are heading towards approximately in the right direction, instead of every available paths.</p> </li> </ul>"},{"location":"CN/UNIT_2/#advantages-of-flooding","title":"Advantages of Flooding","text":"<ul> <li> <p>It is very simple to setup and implement, since a router may know only its neighbours.</p> </li> <li> <p>It is extremely robust. Even in case of malfunctioning of a large number routers, the packets find a way to reach the destination.</p> </li> <li> <p>All nodes which are directly or indirectly connected are visited. So, there are no chances for any node to be left out. This is a main criteria in case of broadcast messages.</p> </li> <li> <p>The shortest path is always chosen by flooding.</p> </li> </ul>"},{"location":"CN/UNIT_2/#limitations-of-flooding","title":"Limitations of Flooding","text":"<ul> <li> <p>Flooding tends to create an infinite number of duplicate data packets, unless some measures are adopted to damp packet generation.</p> </li> <li> <p>It is wasteful if a single destination needs the packet, since it delivers the data packet to all nodes irrespective of the destination.</p> </li> <li> <p>The network may be clogged with unwanted and duplicate data packets. This may hamper delivery of other data packets.</p> </li> </ul>"},{"location":"CN/UNIT_2/#distance-vector-routing-dvr-protocol","title":"Distance Vector Routing (DVR) Protocol","text":"<p>A  distance-vector routing (DVR)  protocol requires that a router inform its neighbors of topology changes periodically. Historically known as the old ARPANET routing algorithm (or known as Bellman-Ford algorithm).</p> <p>Bellman Ford Basics \u2013  Each router maintains a Distance Vector table containing the distance between itself and ALL possible destination nodes. Distances,based on a chosen metric, are computed using information from the neighbors\u2019 distance vectors.</p> <p>Information kept by DV router -</p> <ul> <li>Each router has an ID</li> <li>Associated with each link connected to a router,      there is a link cost (static or dynamic).</li> <li>Intermediate hops</li> </ul> <p>Distance Vector Table Initialization -</p> <ul> <li>Distance to itself = 0</li> <li>Distance to ALL other routers = infinity number.</li> </ul> <p>Distance Vector Algorithm \u2013</p> <ol> <li>A router transmits its distance vector to each of its neighbors in a routing packet.</li> <li>Each router receives and saves the most recently received distance vector from each of its neighbors.</li> <li>A router recalculates its distance vector when:<ul> <li>It receives a distance vector from a neighbor containing different information than before.</li> <li>It discovers that a link to a neighbor has gone down.</li> </ul> </li> </ol> <p>The DV calculation is based on minimizing the cost to each destination</p> <p>Dx(y) = Estimate of least cost from x to y  C(x,v) =  Node x knows cost to each neighbor v Dx   =  [Dx(y): y ? N ] = Node x maintains distance vector Node x also maintains its neighbors' distance vectors \u2013 For each neighbor v, x maintains Dv = [Dv(y): y ? N ]</p> <p>Note \u2013</p> <ul> <li>From time-to-time, each node sends its own distance vector estimate to neighbors.</li> <li> <p>When a node x receives new DV estimate from any neighbor v, it saves v\u2019s distance vector and it updates its own DV using B-F equation:</p> <p>Dx(y) = min { C(x,v) + Dv(y), Dx(y) } for each node y ? N</p> </li> </ul> <p>Example \u2013  Consider 3-routers X, Y and Z as shown in figure. Each router have their routing table. Every routing table will contain distance to the destination nodes.  Consider router X , X will share it routing table to neighbors and neighbors will share it routing table to it to X and distance from node X to destination will be calculated using bellmen- ford equation.</p> <p>Dx(y) = min { C(x,v) + Dv(y)} for each node y ? N</p> <p>As we can see that distance will be less going from X to Z when Y is intermediate node(hop) so it will be update in routing table X.  Similarly for Z also \u2013 </p> <p>Finally the routing table for all \u2013 </p> <p>Advantages of Distance Vector routing \u2013</p> <ul> <li>It is simpler to configure and maintain than link state routing.</li> </ul> <p>Disadvantages of Distance Vector routing \u2013</p> <ul> <li>It is slower to converge than link state.</li> <li>It is at risk from the count-to-infinity problem.</li> <li>It creates more traffic than link state since a hop count change must be propagated to all routers and processed on each router. Hop count updates take place on a periodic basis, even if there are no changes in the network topology, so bandwidth-wasting broadcasts still occur.</li> <li>For larger networks, distance vector routing results in larger routing tables than link state since each router must know about all other routers. This can also lead to congestion on WAN links.</li> </ul>"},{"location":"CN/UNIT_2/#link-state-routing","title":"Link State Routing","text":"<p>Link state routing is a technique in which each router shares the knowledge of its neighborhood with every other router in the internetwork.</p> <p>The three keys to understand the Link State Routing algorithm:</p> <ul> <li>Knowledge about the neighborhood:  Instead of sending its routing table, a router sends the information about its neighborhood only. A router broadcast its identities and cost of the directly attached links to other routers.</li> <li>Flooding:  Each router sends the information to every other router on the internetwork except its neighbors. This process is known as Flooding. Every router that receives the packet sends the copies to all its neighbors. Finally, each and every router receives a copy of the same information.</li> <li>Information sharing:  A router sends the information to every other router only when the change occurs in the information.</li> </ul>"},{"location":"CN/UNIT_2/#link-state-routing-has-two-phases","title":"Link State Routing has two phases:","text":""},{"location":"CN/UNIT_2/#reliable-flooding","title":"Reliable Flooding","text":"<ul> <li>Initial state:  Each node knows the cost of its neighbors.</li> <li>Final state:  Each node knows the entire graph.</li> </ul>"},{"location":"CN/UNIT_2/#route-calculation","title":"Route Calculation","text":"<p>Each node uses Dijkstra's algorithm on the graph to calculate the optimal routes to all nodes.</p> <ul> <li>The Link state routing algorithm is also known as Dijkstra's algorithm which is used to find the shortest path from one node to every other node in the network.</li> <li>The Dijkstra's algorithm is an iterative, and it has the property that after kth  iteration of the algorithm, the least cost paths are well known for k destination nodes.</li> </ul>"},{"location":"CN/UNIT_2/#lets-describe-some-notations","title":"Let's describe some notations:","text":"<ul> <li>c( i , j):  Link cost from node i to node j. If i and j nodes are not directly linked, then c(i , j) = \u221e.</li> <li>D(v):  It defines the cost of the path from source code to destination v that has the least cost currently.</li> <li>P(v):  It defines the previous node (neighbor of v) along with current least cost path from source to v.</li> <li>N:  It is the total number of nodes available in the network.</li> </ul>"},{"location":"CN/UNIT_2/#algorithm","title":"Algorithm","text":"<p>Initialization N = {A}     // A is a root node. for all nodes v if v adjacent to A then D(v) = c(A,v) else D(v) = infinity loop find w not in N such that D(w) is a minimum. Add w to N Update D(v) for all v adjacent to w and not in N: D(v) = min(D(v) , D(w) + c(w,v)) Until all nodes in N</p> <p>In the above algorithm, an initialization step is followed by the loop. The number of times the loop is executed is equal to the total number of nodes available in the network.</p> <p>Let's understand through an example:</p> <p></p> <p>In the above figure, source vertex is A.</p>"},{"location":"CN/UNIT_2/#step-1","title":"Step 1:","text":"<p>The first step is an initialization step. The currently known least cost path from A to its directly attached neighbors, B, C, D are 2,5,1 respectively. The cost from A to B is set to 2, from A to D is set to 1 and from A to C is set to 5. The cost from A to E and F are set to infinity as they are not directly linked to A.</p> Step N D(B),P(B) D(C),P(C) D(D),P(D) D(E),P(E) D(F),P(F) 1 A 2,A 5,A 1,A \u221e \u221e"},{"location":"CN/UNIT_2/#step-2","title":"Step 2:","text":"<p>In the above table, we observe that vertex D contains the least cost path in step 1. Therefore, it is added in N. Now, we need to determine a least-cost path through D vertex.</p> <p>a) Calculating shortest path from A to B</p> <ol> <li>v = B, w = D</li> <li>D(B) = min( D(B) , D(D) + c(D,B) )</li> <li>= min( 2, 1+2)&gt;</li> <li>= min( 2, 3)</li> <li>The minimum value is 2. Therefore, the currently shortest path from A to B is 2.</li> </ol> <p>b) Calculating shortest path from A to C</p> <ol> <li>v = C, w = D</li> <li>D(B) = min( D(C) , D(D) + c(D,C) )</li> <li>= min( 5, 1+3)</li> <li>= min( 5, 4)</li> <li>The minimum value is 4. Therefore, the currently shortest path from A to C is 4.</li> </ol> <p>c) Calculating shortest path from A to E</p> <ol> <li>v = E, w = D</li> <li>D(B) = min( D(E) , D(D) + c(D,E) )</li> <li>= min( \u221e, 1+1)</li> <li>= min(\u221e, 2)</li> <li>The minimum value is 2. Therefore, the currently shortest path from A to E is 2.</li> </ol>"},{"location":"CN/UNIT_2/#note-the-vertex-d-has-no-direct-link-to-vertex-e-therefore-the-value-of-df-is-infinity","title":"Note: The vertex D has no direct link to vertex E. Therefore, the value of D(F) is infinity.","text":"Step N D(B),P(B) D(C),P(C) D(D),P(D) D(E),P(E) D(F),P(F) 1 A 2,A 5,A 1,A \u221e \u221e 2 AD 2,A 4,D 2,D \u221e"},{"location":"CN/UNIT_2/#step-3","title":"Step 3:","text":"<p>In the above table, we observe that both E and B have the least cost path in step 2. Let's consider the E vertex. Now, we determine the least cost path of remaining vertices through E.</p> <p>a) Calculating the shortest path from A to B.</p> <ol> <li>v = B, w = E</li> <li>D(B) = min( D(B) , D(E) + c(E,B) )</li> <li>= min( 2 , 2+ \u221e )</li> <li>= min( 2, \u221e)</li> <li>The minimum value is 2. Therefore, the currently shortest path from A to B is 2.</li> </ol> <p>b) Calculating the shortest path from A to C.</p> <ol> <li>v = C, w = E</li> <li>D(B) = min( D(C) , D(E) + c(E,C) )</li> <li>= min( 4 , 2+1 )</li> <li>= min( 4,3)</li> <li>The minimum value is 3. Therefore, the currently shortest path from A to C is 3.</li> </ol> <p>c) Calculating the shortest path from A to F.</p> <ol> <li>v = F, w = E</li> <li>D(B) = min( D(F) , D(E) + c(E,F) )</li> <li>= min( \u221e , 2+2 )</li> <li>= min(\u221e ,4)</li> <li>The minimum value is 4. Therefore, the currently shortest path from A to F is 4.</li> </ol> Step N D(B),P(B) D(C),P(C) D(D),P(D) D(E),P(E) D(F),P(F) 1 A 2,A 5,A 1,A \u221e \u221e 2 AD 2,A 4,D 2,D \u221e 3 ADE 2,A 3,E 4,E"},{"location":"CN/UNIT_2/#step-4","title":"Step 4:","text":"<p>In the above table, we observe that B vertex has the least cost path in step 3. Therefore, it is added in N. Now, we determine the least cost path of remaining vertices through B.</p> <p>a) Calculating the shortest path from A to C.</p> <ol> <li>v = C, w = B</li> <li>D(B) = min( D(C) , D(B) + c(B,C) )</li> <li>= min( 3 , 2+3 )</li> <li>= min( 3,5)</li> <li>The minimum value is 3. Therefore, the currently shortest path from A to C is 3.</li> </ol> <p>b) Calculating the shortest path from A to F.</p> <ol> <li>v = F, w = B</li> <li>D(B) = min( D(F) , D(B) + c(B,F) )</li> <li>= min( 4, \u221e)</li> <li>= min(4, \u221e)</li> <li>The minimum value is 4. Therefore, the currently shortest path from A to F is 4.</li> </ol> Step N D(B),P(B) D(C),P(C) D(D),P(D) D(E),P(E) D(F),P(F) 1 A 2,A 5,A 1,A \u221e \u221e 2 AD 2,A 4,D 2,D \u221e 3 ADE 2,A 3,E 4,E 4 ADEB 3,E 4,E"},{"location":"CN/UNIT_2/#step-5","title":"Step 5:","text":"<p>In the above table, we observe that C vertex has the least cost path in step 4. Therefore, it is added in N. Now, we determine the least cost path of remaining vertices through C.</p> <p>a) Calculating the shortest path from A to F.</p> <ol> <li>v = F, w = C</li> <li>D(B) = min( D(F) , D(C) + c(C,F) )</li> <li>= min( 4, 3+5)</li> <li>= min(4,8)</li> <li>The minimum value is 4. Therefore, the currently shortest path from A to F is 4.</li> </ol> Step N D(B),P(B) D(C),P(C) D(D),P(D) D(E),P(E) D(F),P(F) 1 A 2,A 5,A 1,A \u221e \u221e 2 AD 2,A 4,D 2,D \u221e 3 ADE 2,A 3,E 4,E 4 ADEB 3,E 4,E 5 ADEBC 4,E"},{"location":"CN/UNIT_2/#final-table","title":"Final table:","text":"Step N D(B),P(B) D(C),P(C) D(D),P(D) D(E),P(E) D(F),P(F) 1 A 2,A 5,A 1,A \u221e \u221e 2 AD 2,A 4,D 2,D \u221e 3 ADE 2,A 3,E 4,E 4 ADEB 3,E 4,E 5 ADEBC 4,E 6 ADEBCF"},{"location":"CN/UNIT_2/#disadvantage","title":"Disadvantage:","text":"<p>Heavy traffic is created in Line state routing due to Flooding. Flooding can cause an infinite looping, this problem can be solved by using Time-to-leave field</p>"},{"location":"CN/UNIT_2/#hierarchical-routing-protocol","title":"Hierarchical Routing Protocol:","text":"<p>Hierarchical Routing is the method of routing in networks that is based on hierarchical addressing. Most transmission control protocol, Internet protocol (TCPIP). Routing is based on two level of hierarchical routing in which IP address is divided into a network, person and a host person. Gateways use only the network a person tell an IP data until gateways delivered it directly. It addresses the growth of routing tables. Routers are further divided into regions and they know the route of their own regions only. It works like a telephone routing. Example \u2013 City, State, Country, Continent.</p>"},{"location":"CN/UNIT_2/#network-layer-services-packetizing-routing-and-forwarding","title":"Network Layer Services- Packetizing, Routing and Forwarding","text":"<p>The network Layer is the third layer in the OSI model of computer networks. Its main function is to transfer network packets from the source to the destination. It is involved both the source host and the destination host. At the source, it accepts a packet from the transport layer, encapsulates it in a datagram, and then delivers the packet to the data link layer so that it can further be sent to the receiver. At the destination, the datagram is decapsulated, and the packet is extracted and delivered to the corresponding transport layer.</p>"},{"location":"CN/UNIT_2/#features-of-network-layer","title":"Features of Network Layer","text":"<ol> <li>The main responsibility of the Network layer is to carry the data packets from the source to the destination without changing or using them.</li> <li>If the packets are too large for delivery, they are fragmented i.e., broken down into smaller packets.</li> <li>It decides the route to be taken by the packets to travel from the source to the destination among the multiple routes available in a network (also called routing).</li> <li>The source and destination addresses are added to the data packets inside the network layer.</li> </ol>"},{"location":"CN/UNIT_2/#services-offered-by-network-layer","title":"Services Offered by Network Layer","text":"<p>The  services  which are offered by the network layer protocol are as follows:</p> <ol> <li>Packetizing</li> <li>Routing</li> <li>Forwarding</li> </ol>"},{"location":"CN/UNIT_2/#1-packetizing","title":"1. Packetizing","text":"<p>The process of encapsulating the data received from the upper layers of the network (also called payload) in a network layer packet at the source and decapsulating the payload from the network layer packet at the destination is known as packetizing.</p> <p>The source host adds a header that contains the source and destination address and some other relevant information required by the network layer protocol to the payload received from the upper layer protocol and delivers the packet to the data link layer.</p> <p>The destination host receives the network layer packet from its data link layer, decapsulates the packet, and delivers the payload to the corresponding upper layer protocol. The routers in the path are not allowed to change either the source or the destination address. The routers in the path are not allowed to decapsulate the packets they receive unless they need to be fragmented.</p> <p></p> <p>Packetizing</p>"},{"location":"CN/UNIT_2/#2-routing","title":"2. Routing","text":"<p>Routing is the process of moving data from one device to another device. These are two other services offered by the network layer. In a network, there are a number of routes available from the source to the destination. The network layer specifies some strategies which find out the best possible route. This process is referred to as routing. There are a number of routing protocols that are used in this process and they should be run to help the routers coordinate with each other and help in establishing communication throughout the network.</p> <p></p> <p>Routing</p>"},{"location":"CN/UNIT_2/#3-forwarding","title":"3. Forwarding","text":"<p>Forwarding is simply defined as the action applied by each router when a packet arrives at one of its interfaces. When a router receives a packet from one of its attached networks, it needs to forward the packet to another attached network (unicast routing) or to some attached networks (in the case of multicast routing). Routers are used on the network for forwarding a packet from the local network to the remote network. So, the process of routing involves packet forwarding from an entry interface out to an exit interface.</p> <p></p> <p>Forwarding</p>"},{"location":"CN/UNIT_2/#internet-protocol","title":"Internet Protocol","text":"<p>Here, IP stands for  internet protocol. It is a protocol defined in the TCP/IP model used for sending the packets from source to destination. The main task of IP is to deliver the packets from source to the destination based on the IP addresses available in the packet headers. IP defines the packet structure that hides the data which is to be delivered as well as the addressing method that labels the datagram with a source and destination information.</p> <p>An IP protocol provides the connectionless service, which is accompanied by two transport protocols, i.e.,  TCP/IP  and UDP/IP, so internet protocol is also known as  TCP/IP  or  UDP/IP.</p> <p>The first version of IP (Internet Protocol) was IPv4. After IPv4, IPv6 came into the market, which has been increasingly used on the public internet since 2006.</p>"},{"location":"CN/UNIT_2/#history-of-internet-protocol","title":"History of Internet Protocol","text":"<p>The development of the protocol gets started in 1974 by  Bob Kahn and Vint Cerf. It is used in conjunction with the Transmission Control Protocol (TCP), so they together named the  TCP/IP.</p> <p>The first major version of the internet protocol was IPv4, which was version 4. This protocol was officially declared in RFC 791 by the Internet Engineering Task Force (IETF) in 1981.</p> <p>After IPv4, the second major version of the internet protocol was IPv6, which was version 6. It was officially declared by the IETF in 1998. The main reason behind the development of IPv6 was to replace IPv4. There is a big difference between IPv4 and IPv6 is that IPv4 uses 32 bits for addressing, while IPv6 uses 128 bits for addressing.</p>"},{"location":"CN/UNIT_2/#function","title":"Function","text":"<p>The main function of the internet protocol is to provide addressing to the hosts, encapsulating the data into a packet structure, and routing the data from source to the destination across one or more  IP  networks. In order to achieve these functionalities,  internet  protocol provides two major things which are given below.</p> <p>An internet protocol defines two things:</p> <ul> <li>Format of IP packet</li> <li>IP Addressing system</li> </ul>"},{"location":"CN/UNIT_2/#ip-packet","title":"IP packet","text":"<p>Before an IP packet is sent over the network, two major components are added in an IP packet, i.e.,  header  and a  payload. </p> <p>An IP header contains lots of information about the IP packet which includes:</p>"},{"location":"CN/UNIT_2/#ipv4","title":"IPv4","text":"<p>IP  stands for  Internet Protocol  and  v4  stands for  Version Four  (IPv4). IPv4 was the primary version brought into action for production within the ARPANET in 1983. IP version four addresses are 32-bit integers which will be expressed in decimal notation. Example- 192.0.2.126 could be an IPv4 address.</p>"},{"location":"CN/UNIT_2/#parts-of-ipv4","title":"Parts of IPv4","text":"<ul> <li>Network part:     The network part indicates the distinctive variety that\u2019s appointed to the network. The network part conjointly identifies the category of the network that\u2019s assigned.</li> <li>Host Part:     The host part uniquely identifies the machine on your network. This part of the IPv4 address is assigned to every host.     For each host on the network, the network part is the same, however, the host half must vary.</li> <li>Subnet number:     This is the nonobligatory part of IPv4. Local networks that have massive numbers of hosts are divided into subnets and subnet numbers are appointed to that.</li> </ul>"},{"location":"CN/UNIT_2/#characteristics-of-ipv4","title":"Characteristics of IPv4","text":"<ul> <li>IPv4 could be a 32-Bit IP Address.</li> <li>IPv4 could be a numeric address, and its bits are separated by a dot.</li> <li>The number of header fields is twelve and the length of the header field is twenty.</li> <li>It has Unicast, broadcast, and multicast style of addresses.</li> <li>IPv4 supports VLSM (Virtual Length Subnet Mask).</li> <li>IPv4 uses the Post Address Resolution Protocol to map to the MAC address.</li> <li>RIP may be a routing protocol supported by the routed daemon.</li> <li>Networks ought to be designed either manually or with DHCP.</li> <li>Packet fragmentation permits from routers and causing host.</li> </ul>"},{"location":"CN/UNIT_2/#advantages-of-ipv4","title":"Advantages of IPv4","text":"<ul> <li>IPv4 security permits encryption to keep up privacy and security.</li> <li>IPV4 network allocation is significant and presently has quite 85000 practical routers.</li> <li>It becomes easy to attach multiple devices across an outsized network while not NAT.</li> <li>This is a model of communication so provides quality service also as economical knowledge transfer.</li> <li>IPV4 addresses are redefined and permit flawless encoding.</li> <li>Routing is a lot of scalable and economical as a result of addressing is collective more effectively.</li> <li>Data communication across the network becomes a lot of specific in multicast organizations.<ul> <li>Limits net growth for existing users and hinders the use of the net for brand new users.</li> <li>Internet Routing is inefficient in IPv4.</li> <li>IPv4 has high System Management prices and it\u2019s labor-intensive, complex, slow &amp; frequent to errors.</li> <li>Security features are nonobligatory.</li> <li>Difficult to feature support for future desires as a result of adding it on is extremely high overhead since it hinders the flexibility to attach everything over IP.</li> </ul> </li> </ul>"},{"location":"CN/UNIT_2/#the-limitations-of-ipv4-addressing-structure","title":"The Limitations of IPv4 Addressing Structure","text":""},{"location":"CN/UNIT_2/#ipv4-address-space-limitation","title":"IPv4 Address Space Limitation","text":"<p>The IPv4 addressing structure uses a 32-bit address space, which allows for approximately four billion unique addresses. However, due to the growth of the internet and the increasing number of connected devices, this is no longer sufficient. Organizations requiring multiple IP addresses for their services and devices face a scarcity of available publicly routable addresses.</p>"},{"location":"CN/UNIT_2/#workarounds-nat-and-cidr","title":"Workarounds: NAT and CIDR","text":"<p>To address IPv4 limitations, workarounds such as Network Address Translation (NAT) and Classless Inter-Domain Routing (CIDR) have been employed. NAT enables multiple private IP addresses to share a single public IP address, while CIDR aggregates smaller networks into larger ones for more efficient address allocation. Although these solutions have helped delay exhaustion, they are not sustainable in the long term.</p>"},{"location":"CN/UNIT_2/#upgrading-to-ipv6","title":"Upgrading to IPv6","text":"<p>The transition to IPv6 is essential due to its significantly larger address space, providing enough unique addresses for future IoT-based applications and connected devices. Most newly installed technology comes equipped with native IPv6 support, integrated into operating systems like Windows and Linux, making them compliant \"out-of-the-box.\" Upgrading to IPv6 will resolve the limitations of the IPv4 addressing structure, enabling sustainable growth and connectivity for the foreseeable future.</p>"},{"location":"CN/UNIT_2/#problems-with-ipv4","title":"Problems with IPv4","text":"<p>IPv4 exhaustion has resulted in difficulties in connecting new devices to the internet, increased costs for obtaining IP addresses, and reduced innovation and growth in the technology sector.</p>"},{"location":"CN/UNIT_2/#difficulty-in-connecting-new-devices-to-the-internet","title":"Difficulty in Connecting New Devices to the Internet","text":"<p>IPv4 exhaustion results in difficulties connecting new devices to the internet due to limited availability of publicly routable addresses. This issue affects businesses and organizations that require multiple IP addresses for their services. Solutions like transitioning to IPv6 addressing structure and implementing Network Address Translation (NAT) can help alleviate this problem.</p>"},{"location":"CN/UNIT_2/#increased-costs-for-obtaining-ip-addresses","title":"Increased Costs for Obtaining IP Addresses","text":"<p>The shortage of IPv4 addresses has led to increased costs for obtaining IP addresses, particularly affecting smaller companies with limited budgets. Transitioning from IPv4 to IPv6 can help address this issue, but it requires time and resources for proper planning and execution.</p>"},{"location":"CN/UNIT_2/#reduced-innovation-and-growth-in-the-technology-sector","title":"Reduced Innovation and Growth in the Technology Sector","text":"<p>IPv4 exhaustion has negatively impacted the technology sector by limiting growth and innovation. Startups may struggle to enter the market, and established companies can face difficulties expanding their online presence or launching new products due to addressing constraints. The cost of obtaining additional IP addresses can also stifle innovation, especially for small businesses and individuals. Overall, IPv4 exhaustion poses significant challenges to the global economy by limiting accessibility and increasing expenses related to finding alternative solutions with their own set of issues, such as network performance problems and compatibility issues with certain applications requiring inbound connections from external sources.</p>"},{"location":"CN/UNIT_2/#internet-protocol-version-6-ipv6-header","title":"Internet Protocol version 6 (IPv6) Header","text":"<p>IP version 6 is the new version of Internet Protocol, which is way better than IP version 4 in terms of complexity and efficiency. Let\u2019s look at the header of IP version 6 and understand how it is different from the IPv4 header.</p> <p>IP version 6 Header Format : </p> <p></p> <p>Version (4-bits):  Indicates version of Internet Protocol which contains bit sequence 0110.</p> <p>Traffic Class (8-bits):  The Traffic Class field indicates class or priority of IPv6 packet which is similar to  Service Field  in IPv4 packet. It helps routers to handle the traffic based on the priority of the packet. If congestion occurs on the router then packets with the least priority will be discarded. As of now, only 4-bits are being used (and the remaining bits are under research), in which 0 to 7 are assigned to Congestion controlled traffic and 8 to 15 are assigned to Uncontrolled traffic.</p> <p>Priority assignment of Congestion controlled traffic :  </p> <p></p> <p>Uncontrolled data traffic is mainly used for Audio/Video data. So we give higher priority to Uncontrolled data traffic. The source node is allowed to set the priorities but on the way, routers can change it. Therefore, the destination should not expect the same priority which was set by the source node.</p> <p>Flow Label (20-bits): Flow Label field is used by a source to label the packets belonging to the same flow in order to request special handling by intermediate IPv6 routers, such as non-default quality of service or real-time service. In order to distinguish the flow, an intermediate router can use the source address, a destination address, and flow label of the packets. Between a source and destination, multiple flows may exist because many processes might be running at the same time. Routers or Host that does not support the functionality of flow label field and for default router handling, flow label field is set to 0. While setting up the flow label, the source is also supposed to specify the lifetime of the flow.</p> <p>Payload Length (16-bits):  It is a 16-bit (unsigned integer) field, indicates the total size of the payload which tells routers about the amount of information a particular packet contains in its payload. The payload Length field includes extension headers(if any) and an upper-layer packet. In case the length of the payload is greater than 65,535 bytes (payload up to 65,535 bytes can be indicated with 16-bits), then the payload length field will be set to 0 and the jumbo payload option is used in the Hop-by-Hop options extension header.</p> <p>Next Header (8-bits):  Next Header indicates the type of extension header(if present) immediately following the IPv6 header. Whereas In some cases it indicates the protocols contained within upper-layer packets, such as TCP, UDP.</p> <p>Hop Limit (8-bits):  Hop Limit field is the same as TTL in IPv4 packets. It indicates the maximum number of intermediate nodes IPv6 packet is allowed to travel. Its value gets decremented by one, by each node that forwards the packet and the packet is discarded if the value decrements to 0. This is used to discard the packets that are stuck in an infinite loop because of some routing error.</p> <p>Source Address (128-bits):  Source Address is the 128-bit IPv6 address of the original source of the packet.</p> <p>Destination Address (128-bits):  The destination Address field indicates the IPv6 address of the final destination(in most cases). All the intermediate nodes can use this information in order to correctly route the packet.</p> <p>Extension Headers:  In order to rectify the limitations of the  IPv4 Option Field, Extension Headers are introduced in IP version 6. The extension header mechanism is a very important part of the IPv6 architecture. The next Header field of IPv6 fixed header points to the first Extension Header and this first extension header points to the second extension header and so on.</p> <p></p> <p>IPv6 packet may contain zero, one or more extension headers but these should be present in their recommended order:</p> <p></p> <p>Rule:  Hop-by-Hop options header(if present) should always be placed after the IPv6 base header.  </p> <p>Conventions :</p> <ol> <li>Any extension header can appear at most once except Destination Header because Destination Header is present two times in the above list itself.</li> <li>If Destination Header is present before Routing Header then it will be examined by all intermediate nodes specified in the routing header.</li> <li>If Destination Header is present just above the Upper layer then it will be examined only by the Destination node.</li> </ol> <p>Given order in which all extension header should be chained in IPv6 packet and working of each extension header :</p> <p></p>"},{"location":"CN/UNIT_2/#introduction-to-subnetting","title":"Introduction To Subnetting","text":"<p>When a bigger network is divided into smaller networks, to maintain security, then that is known as Subnetting. So, maintenance is easier for smaller networks. For example, if we consider a  class A address, the possible number of hosts is 224  for each network, it is obvious that it is difficult to maintain such a huge number of hosts, but it would be quite easier to maintain if we divide the network into small parts.</p>"},{"location":"CN/UNIT_2/#uses-of-subnetting","title":"Uses of Subnetting","text":"<ol> <li>Subnetting helps in organizing the network in an efficient way which helps in expanding the technology for large firms and companies.</li> <li>Subnetting is used for specific staffing structures to reduce traffic and maintain order and efficiency.</li> <li>Subnetting divides domains of the broadcast so that traffic is routed efficiently, which helps in improving network performance.</li> <li>Subnetting is used in increasing  network security.</li> </ol> <p>The network can be divided into two parts: To divide a network into two parts, you need to choose one bit for each Subnet from the host ID part.</p> <p></p> <p>In the above diagram, there are two Subnets.</p> <p>Note:  It is a  class C  IP so, there are 24 bits in the network id part and 8 bits in the host id part.</p>"},{"location":"CN/UNIT_2/#working-of-subnetting","title":"Working of Subnetting","text":"<p>The working of subnets starts in such a way that firstly it divides the subnets into smaller subnets. For communicating between subnets, routers are used. Each subnet allows its linked devices to communicate with each other. Subnetting for a network should be done in such a way that it does not affect the network bits.</p> <p>In  class C  the first 3 octets are network bits so it remains as it is.</p> <ul> <li>For Subnet-1:  The first bit which is chosen from the host id part is zero and the range will be from (193.1.2.00000000 till you get all 1\u2019s in the host ID part i.e, 193.1.2.01111111) except for the first bit which is chosen zero for subnet id part.</li> </ul> <p>Thus, the range of subnet 1 is:  193.1.2.0 to 193.1.2.127</p> <p>Subnet id of Subnet-1 is : 193.1.2.0 The direct Broadcast id of Subnet-1 is: 193.1.2.127 The total number of hosts possible is: 126 (Out of 128,  2 id's are used for Subnet id &amp; Direct Broadcast id) The subnet mask of Subnet- 1 is: 255.255.255.128</p> <ul> <li>For Subnet-2:  The first bit chosen from the host id part is one and the range will be from (193.1.2.100000000 till you get all 1\u2019s in the host ID part i.e, 193.1.2.11111111).</li> </ul> <p>Thus, the range of subnet-2 is:  193.1.2.128 to 193.1.2.255</p> <p>Subnet id of Subnet-2 is : 193.1.2.128 The direct Broadcast id of Subnet-2 is: 193.1.2.255 The total number of hosts possible is: 126 (Out of 128,  2 id's are used for Subnet id &amp;  Direct Broadcast id) The subnet mask of Subnet- 2 is: 255.255.255.128 The best way to find out the subnet mask of a subnet is to set the fixed bit of host-id to 1 and the rest to 0.</p> <p>Finally, after using the subnetting the total number of usable hosts is reduced from 254 to 252.</p> <p>Note:</p> <ol> <li>To divide a network into four (22) parts you need to choose two bits from the host id part for each subnet i.e, (00, 01, 10, 11).</li> <li>To divide a network into eight (23) parts you need to choose three bits from the host id part for each subnet i.e, (000, 001, 010, 011, 100, 101, 110, 111) and so on.</li> <li>We can say that if the total number of subnets in a network increases the total number of usable hosts decreases.</li> </ol> <p>Along with the advantage, there is a small disadvantage to subnetting that is, before subnetting to find the IP address first the network id is found then the host id followed by the process id, but after subnetting first network id is found then the subnet id then host id and finally process id by this the computation increases.</p> <p>Example 1: An organization is assigned a class C network address  of 201.35.2.0. It uses a netmask of 255.255.255.192 to divide this into sub-networks. Which of the following is/are valid host IP addresses?</p> <ol> <li>201.35.2.129</li> <li>201.35.2.191</li> <li>201.35.2.255</li> <li>Both (A) and (C)</li> </ol> <p>Solution:</p> <p>Converting the last octet of the  netmask into the binary form: 255.255.255.11000000 Converting the last octet of option 1  into the binary form: 201.35.2.10000001 Converting the last octet of option 2  into the binary form: 201.35.2.10111111 Converting the last octet of option 3  into the binary form: 201.35.2.11111111</p> <p>From the above, we see that Options 2 and 3 are not valid host IP addresses (as they are broadcast addresses of a subnetwork), and  OPTION 1  is not a broadcast address and it can be assigned to a host IP.</p>"},{"location":"CN/UNIT_2/#advantages-of-subnetting","title":"Advantages of Subnetting","text":"<p>The advantages of Subnetting are mentioned below:</p> <ol> <li>It provides security to one network from another network. eg) In an Organisation, the code of the Developer department must not be accessed by another department.</li> <li>It may be possible that a particular subnet might need higher network priority than others. For example, a Sales department needs to host webcasts or video conferences.</li> <li>In the case of Small networks, maintenance is easy.</li> </ol>"},{"location":"CN/UNIT_2/#disadvantages-of-subnetting","title":"Disadvantages of Subnetting","text":"<p>The disadvantages of Subnetting are mentioned below:</p> <ol> <li>In the case of a single network, only three steps are required to reach a Process i.e Source Host to Destination Network, Destination Network to Destination Host, and then Destination Host to Process.</li> <li>In the case of a Single Network only two IP addresses are wasted to represent Network Id and Broadcast address but in the case of Subnetting two IP addresses are wasted for each Subnet.</li> <li>The cost of the overall Network also increases. Subnetting requires internal routers, Switches, Hubs, Bridges, etc. which are very costly.</li> </ol>"},{"location":"CN/UNIT_2/#network-layer-protocols","title":"Network Layer Protocols","text":"<p>TCP/IP supports the following protocols:</p>"},{"location":"CN/UNIT_2/#arp","title":"ARP","text":"<ul> <li>ARP stands for Address Resolution Protocol.</li> <li>It is used to associate an IP address with the MAC address.</li> <li>Each device on the network is recognized by the MAC address imprinted on the NIC. Therefore, we can say that devices need the MAC address for communication on a local area network. MAC address can be changed easily. For example, if the NIC on a particular machine fails, the MAC address changes but IP address does not change. ARP is used to find the MAC address of the node when an internet address is known.</li> </ul>"},{"location":"CN/UNIT_2/#note-mac-address-the-mac-address-is-used-to-identify-the-actual-device","title":"Note: MAC address: The MAC address is used to identify the actual device.","text":"<p>IP address: It is an address used to locate a device on the network.</p>"},{"location":"CN/UNIT_2/#how-arp-works","title":"How ARP works","text":"<p>If the host wants to know the physical address of another host on its network, then it sends an ARP query packet that includes the IP address and broadcast it over the network. Every host on the network receives and processes the ARP packet, but only the intended recipient recognizes the IP address and sends back the physical address. The host holding the datagram adds the physical address to the cache memory and to the datagram header, then sends back to the sender.</p> <p> </p>"},{"location":"CN/UNIT_2/#steps-taken-by-arp-protocol","title":"Steps taken by ARP protocol","text":"<p>If a device wants to communicate with another device, the following steps are taken by the device:</p> <ul> <li>The device will first look at its internet list, called the ARP cache to check whether an IP address contains a matching MAC address or not. It will check the ARP cache in command prompt by using a command  arp-a.</li> </ul> <p></p> <ul> <li>If ARP cache is empty, then device broadcast the message to the entire network asking each device for a matching MAC address.</li> <li>The device that has the matching IP address will then respond back to the sender with its MAC address</li> <li>Once the MAC address is received by the device, then the communication can take place between two devices.</li> <li>If the device receives the MAC address, then the MAC address gets stored in the ARP cache. We can check the ARP cache in command prompt by using a command arp -a.</li> </ul> <p></p>"},{"location":"CN/UNIT_2/#note-arp-cache-is-used-to-make-a-network-more-efficient","title":"Note: ARP cache is used to make a network more efficient.","text":"<p>In the above screenshot, we observe the association of IP address to the MAC address.</p>"},{"location":"CN/UNIT_2/#there-are-two-types-of-arp-entries","title":"There are two types of ARP entries:","text":"<ul> <li>Dynamic entry:  It is an entry which is created automatically when the sender broadcast its message to the entire network. Dynamic entries are not permanent, and they are removed periodically.</li> <li>Static entry:  It is an entry where someone manually enters the IP to MAC address association by using the ARP command utility.</li> </ul>"},{"location":"CN/UNIT_2/#rarp","title":"RARP","text":"<ul> <li>RARP stands for  Reverse Address Resolution Protocol.</li> <li>If the host wants to know its IP address, then it broadcast the RARP query packet that contains its physical address to the entire network. A RARP server on the network recognizes the RARP packet and responds back with the host IP address.</li> <li>The protocol which is used to obtain the IP address from a server is known as  Reverse Address Resolution Protocol.</li> <li>The message format of the RARP protocol is similar to the ARP protocol.</li> <li>Like ARP frame, RARP frame is sent from one machine to another encapsulated in the data portion of a frame.</li> </ul>"},{"location":"CN/UNIT_2/#icmp","title":"ICMP","text":"<ul> <li>ICMP stands for Internet Control Message Protocol.</li> <li>The ICMP is a network layer protocol used by hosts and routers to send the notifications of IP datagram problems back to the sender.</li> <li>ICMP uses echo test/reply to check whether the destination is reachable and responding.</li> <li>ICMP handles both control and error messages, but its main function is to report the error but not to correct them.</li> <li>An IP datagram contains the addresses of both source and destination, but it does not know the address of the previous router through which it has been passed. Due to this reason, ICMP can only send the messages to the source, but not to the immediate routers.</li> <li>ICMP protocol communicates the error messages to the sender. ICMP messages cause the errors to be returned back to the user processes.</li> <li>ICMP messages are transmitted within IP datagram.</li> </ul>"},{"location":"CN/UNIT_2/#the-format-of-an-icmp-message","title":"The Format of an ICMP message","text":"<ul> <li>The first field specifies the type of the message.</li> <li>The second field specifies the reason for a particular message type.</li> <li>The checksum field covers the entire ICMP message.</li> </ul>"},{"location":"CN/UNIT_2/#error-reporting","title":"Error Reporting","text":"<p>ICMP protocol reports the error messages to the sender.</p> <p>Five types of errors are handled by the ICMP protocol:</p> <ul> <li>Destination unreachable</li> <li>Source Quench</li> <li>Time Exceeded</li> <li>Parameter problems</li> <li>Redirection</li> </ul> <p></p> <ul> <li>Destination unreachable:  The message of \"Destination Unreachable\" is sent from receiver to the sender when destination cannot be reached, or packet is discarded when the destination is not reachable.</li> <li>Source Quench:  The purpose of the source quench message is congestion control. The message sent from the congested router to the source host to reduce the transmission rate. ICMP will take the IP of the discarded packet and then add the source quench message to the IP datagram to inform the source host to reduce its transmission rate. The source host will reduce the transmission rate so that the router will be free from congestion.</li> <li>Time Exceeded:  Time Exceeded is also known as \"Time-To-Live\". It is a parameter that defines how long a packet should live before it would be discarded.</li> </ul> <p>There are two ways when Time Exceeded message can be generated:</p> <p>Sometimes packet discarded due to some bad routing implementation, and this causes the looping issue and network congestion. Due to the looping issue, the value of TTL keeps on decrementing, and when it reaches zero, the router discards the datagram. However, when the datagram is discarded by the router, the time exceeded message will be sent by the router to the source host.</p> <p>When destination host does not receive all the fragments in a certain time limit, then the received fragments are also discarded, and the destination host sends time Exceeded message to the source host.</p> <ul> <li>Parameter problems:  When a router or host discovers any missing value in the IP datagram, the router discards the datagram, and the \"parameter problem\" message is sent back to the source host.</li> <li>Redirection:  Redirection message is generated when host consists of a small routing table. When the host consists of a limited number of entries due to which it sends the datagram to a wrong router. The router that receives a datagram will forward a datagram to a correct router and also sends the \"Redirection message\" to the host to update its routing table.</li> </ul>"},{"location":"CN/UNIT_2/#igmp","title":"IGMP","text":"<ul> <li>IGMP stands for  Internet Group Message Protocol.</li> <li>The IP protocol supports two types of communication:<ul> <li>Unicasting:  It is a communication between one sender and one receiver. Therefore, we can say that it is one-to-one communication.</li> <li>Multicasting:  Sometimes the sender wants to send the same message to a large number of receivers simultaneously. This process is known as multicasting which has one-to-many communication.</li> </ul> </li> <li>The IGMP protocol is used by the hosts and router to support multicasting.</li> <li>The IGMP protocol is used by the hosts and router to identify the hosts in a LAN that are the members of a group.</li> </ul> <ul> <li>IGMP is a part of the IP layer, and IGMP has a fixed-size message.</li> <li>The IGMP message is encapsulated within an IP datagram.</li> </ul>"},{"location":"CN/UNIT_2/#the-format-of-igmp-message","title":"The Format of IGMP message","text":"<p>Where,</p> <p>Type:  It determines the type of IGMP message. There are three types of IGMP message: Membership Query, Membership Report and Leave Report.</p> <p>Maximum Response Time:  This field is used only by the Membership Query message. It determines the maximum time the host can send the Membership Report message in response to the Membership Query message.</p> <p>Checksum:  It determines the entire payload of the IP datagram in which IGMP message is encapsulated.</p> <p>Group Address:  The behavior of this field depends on the type of the message sent.</p> <ul> <li>For Membership Query, the group address is set to zero for General Query and set to multicast group address for a specific query.</li> <li>For Membership Report, the group address is set to the multicast group address.</li> <li>For Leave Group, it is set to the multicast group address.</li> </ul>"},{"location":"CN/UNIT_2/#dhcp","title":"DHCP","text":"<p>Dynamic Host Configuration Protocol (DHCP) is a network management protocol used to dynamically assign an IP address to nay device, or node, on a network so they can communicate using IP (Internet Protocol). DHCP automates and centrally manages these configurations. There is no need to manually assign IP addresses to new devices. Therefore, there is no requirement for any user configuration to connect to a DHCP based network.</p> <p>DHCP can be implemented on local networks as well as large enterprise networks. DHCP is the default protocol used by the most routers and networking equipment. DHCP is also called RFC (Request for comments) 2131.</p>"},{"location":"CN/UNIT_2/#dhcp-does-the-following","title":"DHCP does the following:","text":"<ul> <li>DHCP manages the provision of all the nodes or devices added or dropped from the network.</li> <li>DHCP maintains the unique IP address of the host using a DHCP server.</li> <li>It sends a request to the DHCP server whenever a client/node/device, which is configured to work with DHCP, connects to a network. The server acknowledges by providing an IP address to the client/node/device.</li> </ul> <p>DHCP is also used to configure the proper subnet mask, default gateway and DNS server information on the node or device.</p> <p>There are many versions of DCHP are available for use in IPV4 (Internet Protocol Version 4) and IPV6 (Internet Protocol Version 6)</p>"},{"location":"CN/UNIT_2/#unicast-routing-algorithms-rip-ospf-bgp","title":"Unicast Routing Algorithms: RIP, OSPF, BGP","text":"<p>Unicast routing algorithms are used to determine the optimal path for transmitting data from a source to a destination in a network. Here's an overview of three prominent unicast routing protocols: RIP (Routing Information Protocol), OSPF (Open Shortest Path First), and BGP (Border Gateway Protocol).</p> <ol> <li> <p>RIP (Routing Information Protocol):</p> <ul> <li>Type: Distance Vector Protocol.</li> <li>Algorithm: Bellman-Ford algorithm.</li> <li>Metric: Hop count (number of routers or hops to reach the destination).</li> <li>Updates: Periodic updates are sent (every 30 seconds) to share routing information with neighboring routers.</li> <li>Convergence: May experience slow convergence due to the periodic update mechanism.</li> <li>Use Case: Suitable for small to medium-sized networks; less scalable for large networks or those with complex topologies.</li> <li>Version: RIP version 1 and RIP version 2 (RIPv2) are commonly used.</li> <li> <p>OSPF (Open Shortest Path First):</p> </li> <li> <p>Type: Link State Protocol.</p> </li> <li>Algorithm: Dijkstra's Shortest Path First (SPF) algorithm.</li> <li>Metric: Cost based on bandwidth.</li> <li>Updates: Routers exchange link-state information only when there is a change in the network topology.</li> <li>Convergence: Faster convergence compared to RIP due to incremental updates.</li> <li>Use Case: Well-suited for large and complex networks, especially those with multiple paths and high bandwidth.</li> <li>Areas: Divides the network into areas to enhance scalability.</li> <li> <p>BGP (Border Gateway Protocol):</p> </li> <li> <p>Type: Path Vector Protocol.</p> </li> <li>Algorithm: Policy-based decision-making considering multiple factors (path attributes).</li> <li>Metric: Path attributes, including AS path, next-hop, and various policies set by network administrators.</li> <li>Updates: BGP routers exchange routing information only when there is a change in the network or policy.</li> <li>Convergence: Slower convergence compared to interior gateway protocols due to the policy-based decision-making process.</li> <li>Use Case: Primarily used for inter-domain routing on the Internet. Connects different autonomous systems (AS).</li> <li>Features: Provides rich policy control and is highly scalable, making it suitable for large-scale networks.</li> </ul> </li> </ol>"},{"location":"CN/UNIT_2/#references","title":"References","text":"<p>https://www.geeksforgeeks.org/classification-of-routing-algorithms/ https://www.geeksforgeeks.org/optimality-principle-in-network-topology/ https://www.tutorialspoint.com/what-is-the-shortest-path-routing-in-computer-network https://www.tutorialspoint.com/flooding-in-computer-network https://www.geeksforgeeks.org/distance-vector-routing-dvr-protocol/ https://www.javatpoint.com/link-state-routing-algorithm https://www.geeksforgeeks.org/difference-between-hierarchical-and-flat-routing-protocol/ https://www.javatpoint.com/ip https://www.geeksforgeeks.org/what-is-ipv4/ https://www.tutorialspoint.com/ipv4-exhaustion-in-computer-network https://www.geeksforgeeks.org/internet-protocol-version-6-ipv6-header/ https://www.geeksforgeeks.org/introduction-to-subnetting/ https://www.javatpoint.com/network-layer-protocols https://www.javatpoint.com/dynamic-host-configuration-protocol</p>"},{"location":"CN/UNIT_3/","title":"COMING SOON!","text":""},{"location":"CN/UNIT_4/","title":"COMING SOON!","text":""},{"location":"CN/UNIT_5/","title":"COMING SOON!","text":""},{"location":"CN/cae1/","title":"Question bank","text":""},{"location":"CN/cae1/#1-summarize-the-layers-of-osi-reference-model-with-neat-diagram","title":"1. Summarize the layers of OSI reference model with neat diagram.","text":"<p>The OSI (Open Systems Interconnection) reference model is a conceptual framework used to understand and describe how different networking protocols interact within a network. It consists of seven layers, each responsible for specific tasks. Here's a summary of each layer:</p> <p>Physical Layer (Layer 1):</p> <ul> <li>Concerned with the physical transmission of data over the network medium.</li> <li>Defines specifications such as voltage levels, cable types, data rates, and physical connectors.</li> <li>Examples include Ethernet, Wi-Fi, and optical fiber.</li> </ul> <p>Data Link Layer (Layer 2):</p> <ul> <li>Provides error-free transmission of data frames between adjacent nodes over a physical link.</li> <li>Responsible for framing, error detection, and flow control.</li> <li>Examples include Ethernet MAC (Media Access Control) and Point-to-Point Protocol (PPP).</li> </ul> <p>Network Layer (Layer 3):</p> <ul> <li>Handles routing of data packets between different networks.</li> <li>Translates logical network addresses (IP addresses) into physical addresses (MAC addresses).</li> <li>Examples include Internet Protocol (IP) and Internet Control Message Protocol (ICMP).</li> </ul> <p>Transport Layer (Layer 4):</p> <ul> <li>Ensures reliable end-to-end communication between hosts.</li> <li>Provides error detection, flow control, and segmentation of data.</li> <li>Examples include Transmission Control Protocol (TCP) and User Datagram Protocol (UDP).</li> </ul> <p>Session Layer (Layer 5):</p> <ul> <li>Establishes, manages, and terminates sessions between applications.</li> <li>Provides mechanisms for synchronization and checkpointing during data exchange.</li> <li>Examples include NetBIOS and Remote Procedure Call (RPC).</li> </ul> <p>Presentation Layer (Layer 6):</p> <ul> <li>Handles data translation, encryption, and compression to ensure compatibility between different systems.</li> <li>Converts data from application format to network format and vice versa.</li> <li>Examples include JPEG, MPEG, and ASCII.</li> </ul> <p>Application Layer (Layer 7):</p> <ul> <li>Provides network services directly to end-users or applications.</li> <li>Implements protocols for tasks such as file transfer, email, and web browsing.</li> <li>Examples include HTTP, FTP, SMTP, and DNS.</li> <li></li> </ul> <p>The diagram above illustrates the OSI model with each layer represented sequentially from the physical layer at the bottom to the application layer at the top.</p>"},{"location":"CN/cae1/#2-compare-of-osi-reference-model-and-tcpip-reference-model","title":"2. Compare of OSI reference model and TCP/IP reference model","text":"<p>Both OSI (Open Systems Interconnection) reference model and TCP/IP (Transmission Control Protocol/Internet Protocol) reference model are used to understand and standardize communication protocols in computer networks. Here's a comparison between the two:</p> <p>OSI Reference Model:</p> <ul> <li>Developed by the International Organization for Standardization (ISO).</li> <li>Consists of seven layers: Physical, Data Link, Network, Transport, Session, Presentation, and Application.</li> <li>Designed as a conceptual framework, providing a structured approach to networking.</li> <li>Each layer has specific functions and protocols associated with it.</li> <li>Offers a clear separation between different functions, promoting interoperability and modularity.</li> <li>Not widely implemented in practice but serves as a basis for understanding networking concepts.</li> </ul> <p>TCP/IP Reference Model:</p> <ul> <li>Developed by the U.S. Department of Defense (DoD).</li> <li>Consists of four layers: Network Interface (Link), Internet, Transport, and Application.</li> <li>More closely reflects the architecture of the Internet and is widely used in practice.</li> <li>Often considered a practical implementation of the OSI model, with fewer layers.</li> <li>TCP/IP protocols, such as TCP, IP, UDP, and ICMP, are central to this model.</li> <li>Offers a flexible and scalable framework suitable for diverse networking environments.</li> </ul> <p>Comparison:</p> <ul> <li>The OSI model provides a more detailed and theoretical framework, while the TCP/IP model is more practical and widely implemented.</li> <li>The OSI model has seven layers, while the TCP/IP model has four layers, with some overlapping functionality.</li> <li>Both models define standards for network communication but are used differently in practice.</li> <li>TCP/IP protocols are fundamental to the functioning of the Internet, whereas OSI protocols are less commonly implemented.</li> <li>The OSI model is often used for educational purposes and to understand networking concepts, while the TCP/IP model is used for actual network design and implementation.</li> </ul>"},{"location":"CN/cae1/#3-compare-lan-man-wan-in-detail","title":"3. Compare LAN, MAN, WAN in detail.","text":"Basis LAN MAN WAN Full-Form LAN stands for local area network. MAN stands for metropolitan area network. WAN stands for wide area network. Geographic Span Operates in small areas such as the same building or campus. Operates in large areas such as a city. Operates in larger areas such as country or continent. Ownership LAN\u2019s ownership is private. MAN\u2019s ownership can be private or public. WAN might not be owned by one organization. Transmission Speed The transmission speed of a LAN is high. The transmission speed of a MAN is average. The transmission speed of a WAN is low. Propagation delay The propagation delay is short in a LAN. There is a moderate propagation delay in a MAN. There is a long propagation delay in a WAN. Congestion There is less congestion in LAN. There is more congestion in MAN. There is more congestion than MAN in WAN. Design &amp; Maintenance LAN\u2019s design and maintenance are easy. MAN\u2019s design and maintenance are difficult than LAN. WAN\u2019s design and maintenance are also difficult than LAN as well MAN. Fault tolerance There is more fault tolerance in LAN. There is less fault tolerance in MAN. There is less fault tolerance in WAN."},{"location":"CN/cae1/#4-illustrate-the-levels-of-addressing-used-in-an-internet-employing-the-tcpip-protocols","title":"4. Illustrate the Levels of addressing used in an internet employing the TCP/IP protocols","text":"<p>In an internet employing TCP/IP protocols, addressing is crucial for identifying and routing data packets across the network. TCP/IP uses several levels of addressing to ensure effective communication:</p> <p>Link Layer Addressing (MAC Address):</p> <ul> <li>At the lowest level, each network interface (NIC) is assigned a unique Media Access Control (MAC) address.</li> <li>MAC addresses are 48 bits long and are typically represented in hexadecimal format.</li> <li>They are used for communication within the same physical network (LAN) and are assigned by the manufacturer of the network interface.</li> <li> <p>Internet Layer Addressing (IP Address):</p> </li> <li> <p>The Internet Protocol (IP) layer provides logical addressing for hosts on a network.</p> </li> <li>IP addresses are 32 bits (IPv4) or 128 bits (IPv6) long and are represented in decimal format.</li> <li>IPv4 addresses are divided into network and host portions, while IPv6 addresses use a hierarchical addressing structure.</li> <li>IP addresses are used for routing packets between networks and are assigned by network administrators or Internet Service Providers (ISPs).</li> <li>Transport Layer Addressing (Port Number):</li> </ul> <p>Within the TCP/IP stack, the transport layer uses port numbers to distinguish between different applications or services running on a host. Port numbers range from 0 to 65535 and are divided into well-known ports (0-1023), registered ports (1024-49151), and dynamic or private ports (49152-65535). Port numbers, along with IP addresses, are used to deliver data to the appropriate application or service on a host. Illustration:</p> <p>Suppose a host (Host A) wants to communicate with another host (Host B) over the internet using TCP/IP protocols. Host A encapsulates its data into packets, including the destination IP address of Host B. The network layer (IP) examines the destination IP address to determine the next-hop router or destination network. The link layer then encapsulates the IP packets into frames, adding the MAC address of the next-hop router or the destination host (if within the same LAN). Finally, the frames are transmitted over the physical network, and each intermediate router or switch forwards the packets based on MAC addresses and IP addresses until they reach the destination host (Host B).</p>"},{"location":"CN/cae1/#5-list-the-different-types-of-switching-techniques-explain-any-one","title":"5. List the different types of switching techniques. Explain any one?","text":"<p>Different types of switching techniques:</p> <ul> <li>Circuit Switching:</li> </ul> <p>In circuit switching, a dedicated communication path is established between two nodes before data transmission begins. The path remains reserved for the duration of the communication session, regardless of whether data is being transmitted or not. Examples of circuit-switched networks include traditional telephone networks (PSTN) and ISDN (Integrated Services Digital Network). - Packet Switching:</p> <p>Packet switching breaks data into small packets for transmission across a network. Each packet contains information about its source, destination, and sequence number. Packets are forwarded independently based on network conditions and available routes. - Types of packet switching include: Datagram Switching: Each packet is routed independently, and the route can vary for different packets. Virtual Circuit Switching: Similar to circuit switching, but the dedicated path is established only for the duration of the communication session. - Explanation of Packet Switching:</p> <p>Packet switching is a technique used in computer networks to transmit data in the form of packets. Here's how it works:</p> <p>Packetization: Data is divided into small packets for transmission. Each packet contains a portion of the original data along with header information.</p> <p>Routing: Each packet is routed independently based on the destination address contained in its header. Routers examine the destination address and make decisions about the best path to forward the packet.</p> <p>Transmission: Packets are transmitted across the network using available links and resources. They may take different routes and may arrive at the destination out of order.</p> <p>Reassembly: Upon reaching the destination, packets are reassembled into the original data stream based on sequence numbers contained in the headers.</p> <p>Delivery: The reassembled data is delivered to the destination application or service for processing.</p> <p>Packet switching offers several advantages, including efficient use of network resources, scalability, and resilience to network failures. It allows multiple users to share the same network infrastructure while dynamically adapting to changing traffic patterns. Examples of packet-switched networks include the Internet (using TCP/IP) and Ethernet LANs.</p>"},{"location":"CN/cae1/#6-differentiate-the-connection-less-connection-oriented-services","title":"6. Differentiate the Connection less &amp; Connection oriented Services","text":"SS No. Comparison Parameter Connection-oriented Service Connection Less Service 1. Related System Designed and developed based on the telephone system. Service based on the postal system. 2. Definition Used to create an end-to-end connection between senders and receivers before transmitting data over the same or different networks. Used to transfer data packets between senders and receivers without creating any connection. 3. Virtual Path Creates a virtual path between the sender and the receiver. Does not create any virtual connection or path between the sender and the receiver. 4. Authentication Requires authentication before transmitting data packets to the receiver. Does not require authentication before transferring data packets. 5. Data Packets Path All data packets are received in the same order as those sent by the sender. Not all data packets are received in the same order as those sent by the sender. 6. Bandwidth Requirement Requires higher bandwidth to transfer data packets. Requires low bandwidth to transfer data packets. 7. Data Reliability More reliable connection service because it guarantees data packet transfer from one end to the other end with a connection. Not a reliable connection service because it does not guarantee the transfer of data packets from one end to another for establishing a connection. 8. Congestion No congestion as it provides an end-to-end connection between sender and receiver during data transmission. May experience congestion due to not providing an end-to-end connection between the source and receiver for data packet transmission. 9. Examples Transmission Control Protocol (TCP) User Datagram Protocol (UDP), Internet Protocol (IP), and Internet Control Message Protocol (ICMP)"},{"location":"CN/cae1/#7-explain-various-connecting-devices-hub-switch-router-bridges-firewall-and-usage-of-each-device","title":"7. Explain various connecting devices- Hub, Switch ,Router, Bridges ,Firewall and usage of each device","text":"<p>1. Hub:</p> <ul> <li>A hub is a basic networking device that operates at the physical layer (Layer 1) of the OSI model.</li> <li>It is used to connect multiple Ethernet devices in a network, allowing them to communicate with each other.</li> <li>Hubs operate in a broadcast domain, meaning that when a packet is received on one port, it is broadcasted out to all other ports.</li> <li>They are simple and inexpensive but suffer from limitations such as collisions and limited bandwidth sharing among connected devices.</li> <li>Hubs are rarely used in modern networks due to their inefficiency and susceptibility to collisions.</li> </ul> <p>2. Switch:</p> <ul> <li>A switch is a more advanced networking device that operates at the data link layer (Layer 2) of the OSI model.</li> <li>It is used to connect multiple devices in a local area network (LAN) and provides dedicated communication channels between devices.</li> <li>Switches use MAC address tables to intelligently forward data only to the device intended to receive it, reducing collisions and improving network efficiency.</li> <li>They operate in a single collision domain per port, allowing full-duplex communication and higher bandwidth utilization.</li> <li>Switches are commonly used in modern networks to segment LANs, improve performance, and enhance security.</li> </ul> <p>3. Router:</p> <ul> <li>A router is a networking device that operates at the network layer (Layer 3) of the OSI model.</li> <li>It is used to connect multiple networks together and forward data packets between them based on IP addresses.</li> <li>Routers use routing tables to determine the best path for packet transmission, considering factors such as network topology, traffic load, and routing protocols.</li> <li>They provide traffic isolation between different network segments (subnets) and support features such as network address translation (NAT), DHCP, and firewall capabilities.</li> <li>Routers are essential components of both local area networks (LANs) and wide area networks (WANs) and are crucial for interconnecting devices across the Internet.</li> </ul> <p>4. Bridge:</p> <ul> <li>A bridge is a networking device that operates at the data link layer (Layer 2) of the OSI model.</li> <li>It is used to connect multiple network segments or LANs together and selectively forward data frames between them.</li> <li>Bridges use MAC addresses to filter and forward traffic, effectively reducing collision domains and improving network performance.</li> <li>They are commonly used to extend the size of LANs, segment network traffic, and isolate network problems.</li> <li>Bridges are less commonly used in modern networks compared to switches, but they are still relevant in specific scenarios, such as legacy network environments.</li> </ul> <p>5. Firewall:</p> <ul> <li>A firewall is a network security device that monitors and controls incoming and outgoing network traffic based on predetermined security rules.</li> <li>It is used to protect a network or device from unauthorized access, malware, and other security threats.</li> <li>Firewalls can be implemented in various forms, including hardware appliances, software applications, or virtual appliances.</li> <li>They inspect network packets, filter traffic based on IP addresses, port numbers, and application protocols, and enforce security policies to allow or block specific types of traffic.</li> <li>Firewalls are essential components of network security infrastructure and are deployed at the perimeter of networks, between internal network segments, and on individual devices to safeguard against cyber attacks and data breaches.</li> </ul> <p>Each of these connecting devices plays a crucial role in the functioning, performance, and security of computer networks, and their usage depends on the specific requirements and objectives of the network infrastructure.</p>"},{"location":"CN/cae1/#8-compare-circuit-switching-vs-packet-switching","title":"8. Compare circuit switching Vs packet switching","text":"S.No Parameter Circuit Switching Network Packet Switching Network 1 Path Dedicated path created between two points by setting the switches. No dedicated path created between two points. Only virtual circuit exists. 2 Store and forward transmission No concept of store and forward transmission. Each node may store incoming packets and forward them after use. 3 Dedicated Links making a path are dedicated and cannot be used for other connections. Links making a route can be shared with other connections. 4 Availability of Bandwidth Bandwidth is fixed and reserved in advance. Bandwidth requirement is dynamic and can be released as needed. 5 Route followed by packets Route followed by packets is always the same. Route followed by packets may or may not be different. 6 Call setup Call setup required. Call setup not required. 7 Congestion Congestion can occur at setup time. Congestion can occur on every packet. 8 Wastage of Bandwidth Unused bandwidth on allocated circuit is wasted. Unused bandwidth may be utilized by other packets. 9 Charging Users charged based on time and distance. Users charged based on time and number of bytes, not distance. 10 Application Telephone network for bidirectional, real-time transfer of voice signal. Internet for datagram and reliable stream service between computers. 11 Layers Implemented at the physical layer. Implemented at the data link and network layers. 12 Reliability Highly reliable. Low reliability, subject to congestion."},{"location":"CN/cae1/#9-differentiate-between-classful-and-classless-addressing","title":"9. Differentiate between Classful and classless addressing.","text":"Sr. No. Parameter Classful Addressing Classless Addressing 1 Basics IP addresses are allocated according to the classes - A to E. Came to replace classful addressing to handle the issue of rapid IP address exhaustion. 2 Practical Less practical. More practical. 3 Network ID and Host ID Changes in the Network ID and Host ID depend on the class. No such restriction of class in classless addressing. 4 VLSM Does not support Variable Length Subnet Mask (VLSM). Supports Variable Length Subnet Mask (VLSM). 5 Bandwidth Requires more bandwidth, making it slower and more expensive. Requires less bandwidth, making it faster and less expensive. 6 CIDR Does not support Classless Inter-Domain Routing (CIDR). Supports Classless Inter-Domain Routing (CIDR). 7 Updates Regular or periodic updates. Triggered Updates. 8 Troubleshooting and Problem detection Easier due to division of network, host, and subnet parts in the address. Not as easy as classful addressing. 9 Division of Address - Network - Network - Host - Host - Subnet - Subnet"},{"location":"CN/cae1/#10-write-short-note-on-autonomous-system","title":"10. Write short note on Autonomous system","text":"<p>An Autonomous System (AS) is a collection of IP networks and routers under the control of a single organization or entity that presents a common routing policy to the Internet. ASes are assigned unique identification numbers known as Autonomous System Numbers (ASNs) by regional Internet registries (RIRs) such as ARIN, RIPE NCC, and APNIC.</p> <p>Usage of AS: 1. Internet Connectivity: ASes provide connectivity to the Internet, allowing traffic to flow between networks. 2. Routing Control: ASes have control over routing decisions within their networks, determining how traffic is forwarded. 3. Peering Agreements: ASes establish peering agreements with other ASes to exchange traffic directly, reducing dependency on transit providers. 4. Traffic Engineering: ASes optimize routing paths to improve network performance, reduce latency, and manage congestion.</p>"},{"location":"CN/cae1/#11-192168513126-for-given-address-find-out-the","title":"11.  192.168.5.131/26 for given address find out the","text":"<p>i) Subnet mask? ii) What is first is first ip address for given series? iii) What is last ip address for given series?</p> <p>i) Subnet mask:     The subnet mask for the given address 192.168.5.131/26 is 255.255.255.192 (/26 indicates 26 bits are used for the network portion, leaving 6 bits for the host portion).</p> <p>ii) First IP address:     To find the first IP address in the given series, we need to determine the network address. Since the given IP address is in CIDR notation (/26), the network address is 192.168.5.128. So, the first IP address in the series is 192.168.5.129.</p> <p>iii) Last IP address:     The last IP address in the series can be calculated by taking the network address and adding the total number of host addresses in the subnet. For a /26 subnet, there are 64 host addresses (2^6 = 64). So, the last IP address in the series is 192.168.5.192.</p>"},{"location":"CN/cae1/#12-discuss-about-inter-network-routing-protocols-used-in-network-layer-in-detail","title":"12. Discuss about Inter-network Routing Protocols used in Network layer in detail?","text":"<p>Inter-network Routing Protocols operate at the network layer (Layer 3) of the OSI model and are used to exchange routing information between routers in different autonomous systems or networks. Some commonly used inter-network routing protocols include:</p> <ol> <li> <p>Border Gateway Protocol (BGP): BGP is an exterior gateway protocol used to exchange routing and reachability information between autonomous systems on the Internet. It is designed to provide scalable and flexible routing capabilities, supporting policies for route selection and traffic engineering.</p> </li> <li> <p>Open Shortest Path First (OSPF): OSPF is an interior gateway protocol used within autonomous systems to calculate the shortest path routes based on link-state information. It employs Dijkstra's shortest path algorithm to determine the best paths and supports features such as hierarchical routing, route summarization, and authentication.</p> </li> <li> <p>Intermediate System to Intermediate System (IS-IS): IS-IS is another interior gateway protocol similar to OSPF that operates within autonomous systems. It uses a link-state routing algorithm and is widely used in Service Provider networks for scalability and stability.</p> </li> </ol>"},{"location":"CN/cae1/#13explain-distance-vector-routing-protocol-along-with-example","title":"13.Explain Distance Vector Routing protocol along with example","text":"<p>Distance Vector Routing Protocol is a type of routing algorithm used by routers to dynamically calculate the best path to reach a destination network. It operates based on two main principles:</p> <ol> <li> <p>Distance: The distance refers to the metric or cost associated with reaching a particular network. It can be measured in various units such as hop count, bandwidth, delay, or a combination of these factors.</p> </li> <li> <p>Vector: The vector represents the direction or next-hop router towards the destination network.</p> </li> </ol> <p>Example:  One of the most common examples of a distance vector routing protocol is the Routing Information Protocol (RIP). In RIP, routers periodically broadcast routing updates containing information about directly connected networks and their associated costs (hop counts). Routers use these updates to maintain their routing tables and make forwarding decisions.</p>"},{"location":"CN/cae1/#14-why-count-to-infinity-problem-arises-and-how-does-to-get-solved","title":"14. Why count to infinity problem arises and how does to get solved?","text":"<p>The Count to Infinity problem arises in distance vector routing protocols when a router incorrectly believes it has discovered a shorter path to a destination network, leading to routing loops and network instability. This problem occurs due to the slow convergence of distance vector algorithms and the propagation of incorrect routing information.</p> <p>Solution: Several mechanisms are used to mitigate the Count to Infinity problem: 1. Split Horizon: Routers do not advertise routes back onto the interface from which they were learned. 2. Poison Reverse: Routers advertise a route with an infinite metric back to the router from which the route was learned. 3. Hold-down Timers: Routers temporarily ignore route updates for a certain period after detecting a change to prevent premature route selection. 4. Triggered Updates: Routers immediately send updates when a change in the network topology occurs to expedite convergence. 5. Route Poisoning: Routers advertise unreachable routes with an infinite metric to inform other routers about network failures.</p> <p>By implementing these techniques, distance vector routing protocols can effectively prevent routing loops and maintain network stability.</p>"},{"location":"CN/cae1/#15-sketch-and-explain-header-format-of-ipv4","title":"15. Sketch and explain Header format of IPV4.","text":"<p>The IPv4 (Internet Protocol version 4) header is a fundamental component of the IPv4 packet structure. It contains essential information required for the transmission and delivery of data packets across IP networks. Below is a sketch and explanation of the IPv4 header format:</p> <p></p> <p>Explanation of IPv4 Header Fields:</p> <p>1. Version (4 bits):    - Indicates the version of the IP protocol being used. For IPv4, the value is 4.</p> <p>2. IHL (Internet Header Length) (4 bits):    - Specifies the length of the IP header in 32-bit words. The minimum value is 5 (indicating a 20-byte header), and the maximum value is 15.</p> <p>3. Type of Service (TOS) (8 bits):    - Used to define the quality of service (QoS) requirements for the packet, including priority, delay, throughput, and reliability.</p> <p>4. Total Length (16 bits):    - Specifies the total length of the IP packet, including the header and data, in bytes. The maximum value is 65535 bytes.</p> <p>5. Identification (16 bits):    - An identifier assigned by the sender to uniquely identify the fragmented packets belonging to the same original datagram.</p> <p>6. Flags (3 bits):    - Used in conjunction with the Fragment Offset field for fragmentation and reassembly of IP packets.    - The three flags are:      - Bit 0: Reserved, must be zero.      - Bit 1: Don't Fragment (DF): Indicates that the packet should not be fragmented.      - Bit 2: More Fragments (MF): Indicates whether there are more fragments following the current one.</p> <p>7. Fragment Offset (13 bits):    - Indicates the offset of the data in the current fragment relative to the original datagram.</p> <p>8. Time to Live (TTL) (8 bits):    - Specifies the maximum number of hops (routers) that the packet can traverse before being discarded.    - Decremented by one at each hop, preventing packets from circulating indefinitely in the network.</p> <p>9. Protocol (8 bits):    - Indicates the protocol used in the data portion of the IP packet, such as TCP (6), UDP (17), ICMP (1), etc.</p> <p>10. Header Checksum (16 bits):     - A checksum calculated over the header to detect errors in the IP header during transmission.</p> <p>11. Source IP Address (32 bits):     - Specifies the source IP address of the sender.</p> <p>12. Destination IP Address (32 bits):     - Specifies the destination IP address of the recipient.</p> <p>13. Options (if any) (Variable length):     - Additional options and information that can be included in the IP header, such as record route, timestamp, etc.</p> <p>14. Padding (if any) (Variable length):     - Additional bits added to the header to ensure alignment to a 32-bit boundary.</p> <p>Each field in the IPv4 header serves a specific purpose in the routing, forwarding, and delivery of IP packets across networks.</p>"},{"location":"CN/cae1/#16-compare-ipv4-and-ipv6-addressing-system","title":"16. Compare IPV4 and IPV6 addressing system.","text":"Parameter IPv4 IPv6 Address length 32-bit address 128-bit address Fields Numeric address with 4 fields separated by dot (.) Alphanumeric address with 8 fields separated by colon (:) Classes 5 classes: Class A, B, C, D, and E Does not contain classes Number of IP address Limited number Large number VLSM Supports VLSM (Virtual Length Subnet Mask) Does not support VLSM Address configuration Manual and DHCP configuration Manual, DHCP, auto-configuration, and renumbering Address space Generates 4 billion unique addresses Generates 340 undecillion unique addresses End-to-end connection integrity Unachievable Achievable Security features Security depends on the application, no built-in security IPSEC developed for security Address representation Represented in decimal Represented in hexadecimal Fragmentation Done by senders and forwarding routers Done only by senders Packet flow identification Does not provide mechanism for packet flow identification Uses flow label field in header for packet flow identification Checksum field Available Not available Transmission scheme Broadcasting Multicasting, provides efficient network operations Encryption and Authentication Does not provide Provides Number of octets Consists of 4 octets 8 fields, each containing 2 octets, totaling 16 octets in IPv6"},{"location":"CN/cae1/#17-a-packet-has-arrived-in-which-the-offset-value-is-100-the-value-of-hlen-is-5-and-the-value-of-the-total-length-field-is-100-what-are-the-numbers-of-the-first-byte-and-the-last-byte","title":"17. A packet has arrived in which the offset value is 100, the value of HLEN is 5, and the value of the total length field is 100. What are the numbers of the first byte and the last byte?","text":"<p>Given:</p> <ul> <li>Offset value: 100</li> <li>HLEN (Header Length) value: 5</li> <li>Total Length field value: 100</li> </ul> <p>First, let's calculate the position of the first byte:</p> <ul> <li>Offset value represents the number of 8-byte blocks from the beginning of the IP packet.</li> <li>Since the header length is 5, each header block is 4 bytes long (5 * 4 = 20 bytes).</li> <li>Therefore, the first byte is at position: 20 + (100 * 8) = 820 bytes.</li> </ul> <p>Next, let's find the position of the last byte:</p> <ul> <li>Total Length field value represents the total length of the IP packet in bytes.</li> <li>The last byte is at position: 820 + (100 - 1) = 919 bytes.</li> </ul> <p>So, the first byte is at position 820, and the last byte is at position 919.</p>"},{"location":"CN/cae1/#18-find-the-class-net-id-host-id-and-address-range-of-the-following-ip-addresses-a208345412-2-1143428","title":"18. Find the class, Net ID, Host ID and address range of the following IP addresses. (a)208.34.54.12 (2) 114.34.2.8","text":"<p>(a) 208.34.54.12</p> <ul> <li>Class: Class C (192.0.0.0 to 223.255.255.255)</li> <li>Net ID: 208.34.54 (First three octets)</li> <li>Host ID: 12 (Last octet)</li> <li>Address Range: 208.34.54.1 to 208.34.54.254 (excluding network address and broadcast address)</li> </ul> <p>(b) 114.34.2.8</p> <ul> <li>Class: Class A (0.0.0.0 to 127.255.255.255)</li> <li>Net ID: 114 (First octet)</li> <li>Host ID: 34.2.8 (Last three octets)</li> <li>Address Range: 114.0.0.1 to 114.255.255.254 (excluding network address and broadcast address)</li> </ul>"},{"location":"CN/cae1/#19-explain-error-reporting-and-query-messages-of-icmp-in-detail","title":"19. Explain Error reporting and Query messages of ICMP in detail","text":"<p>Error Reporting:</p> <ul> <li>ICMP (Internet Control Message Protocol) is used to report errors and provide feedback about IP packet processing.</li> <li>When a router or host encounters an error while processing an IP packet, it sends an ICMP error message back to the source of the packet.</li> <li>Common ICMP error messages include:</li> <li>Destination Unreachable: Indicates that the destination host or network is unreachable.</li> <li>Time Exceeded: Indicates that the TTL (Time to Live) field has expired.</li> <li>Parameter Problem: Indicates an issue with the IP header or options.</li> <li>Error reporting ICMP messages help in diagnosing network connectivity issues and troubleshooting network problems.</li> </ul> <p>Query Messages:</p> <ul> <li>ICMP is also used to send query messages to request information or verify the reachability of hosts.</li> <li>Common ICMP query messages include:</li> <li>Echo Request (Ping): Used to check the reachability of a remote host by sending an ICMP Echo Request message.</li> <li>Timestamp Request: Used to request the current time from a remote host.</li> <li>Address Mask Request: Used to request the subnet mask of a remote host.</li> <li>Query messages are essential for network management and monitoring, allowing administrators to assess the status and performance of network devices.</li> </ul>"},{"location":"CN/cae1/#20-summarize-arp-rarp-protocols-in-detail","title":"20. Summarize ARP, RARP protocols in detail","text":"<p>ARP (Address Resolution Protocol):</p> <ul> <li>ARP is used to map IP addresses to MAC addresses within a local network.</li> <li>When a host wants to communicate with another host on the same subnet, it sends an ARP request broadcast containing the IP address of the target host.</li> <li>The target host with the corresponding IP address responds with its MAC address, allowing the requesting host to update its ARP cache.</li> <li>ARP operates at the data link layer (Layer 2) of the OSI model and is essential for Ethernet and other LAN technologies.</li> </ul> <p>RARP (Reverse Address Resolution Protocol):</p> <ul> <li>RARP is the reverse of ARP, used to map MAC addresses to IP addresses.</li> <li>It allows diskless devices such as diskless workstations to obtain their IP addresses from a RARP server based on their MAC addresses.</li> <li>RARP requests are broadcasted on the local network, and RARP servers respond with the corresponding IP address.</li> <li>RARP is less commonly used today due to the prevalence of DHCP (Dynamic Host Configuration Protocol) for IP address assignment.</li> </ul> <p>Both ARP and RARP play crucial roles in facilitating communication between devices on a local network by resolving IP and MAC addresses. However, DHCP has largely replaced RARP for dynamic IP address assignment, while ARP remains fundamental for IP address resolution in local networks.</p>"},{"location":"CN/cae2/","title":"COMING SOON!","text":""},{"location":"CN/cae3/","title":"COMING SOON!","text":""},{"location":"DAA/","title":"DESIGN ANALYSIS AND ALGORITHM","text":"Unit Topic Duration Unit I Mathematical foundations &amp; Asymptotic notations 8 Algorithm, Mathematical Notations, Algorithm specification, Analysis of Algorithm- Introduction, Analyzing control structures, Asymptotic notations, space complexity, time complexity, Performance measurement, analyzing control structures, best case, worst case and average case analysis, Iterative Algorithm analysis Unit II Divide and Conquer 8 Recurrence relations, solutions of recurrence relations by Master Methods. Divide and conquer basic strategy, binary search, quick sort, merge sort, maximum and minimum finding Unit III Greedy Method 8 Greedy method \u2013 basic strategy, application to job sequencing with deadlines problem, minimum cost spanning trees, single source shortest path etc. Unit IV Dynamic Programming 6 Dynamic Programming basic strategy, multistage graphs, all pairs shortest path, single source shortest paths, optimal binary search trees, traveling salesman problems Unit V Traversal And Search Techniques 6 Basic Traversal and Search Techniques, breadth first search and depth first search, Backtracking basic strategy, 8--Queen\u2019s problem, graph colouring, Hamiltonian cycles. NP, P Problems, Optimization Algorithms"},{"location":"DAA/#lab-manual","title":"Lab Manual","text":""},{"location":"DAA/UNIT_1/","title":"Unit1","text":""},{"location":"DAA/UNIT_1/#definition-of-algorithm","title":"Definition of Algorithm","text":"<p>The word *Algorithm* means \u201d A set of finite rules or instructions to be followed in calculations or other problem-solving operations \u201d Or \u201d A procedure for solving a mathematical problem in a finite number of steps that frequently involves recursive operations\u201d.</p> <p>Therefore Algorithm refers to a sequence of finite steps to solve a particular problem.</p> <p></p>"},{"location":"DAA/UNIT_1/#use-of-the-algorithms","title":"Use of the Algorithms:","text":"<p>Algorithms play a crucial role in various fields and have many applications. Some of the key areas where algorithms are used include:</p> <ol> <li>*Computer Science:* Algorithms form the basis of computer programming and are used to solve problems ranging from simple sorting and searching to complex tasks such as artificial intelligence and machine learning.</li> <li>*Mathematics:* Algorithms are used to solve mathematical problems, such as finding the optimal solution to a system of linear equations or finding the shortest path in a graph.</li> <li>*Operations Research*: Algorithms are used to optimize and make decisions in fields such as transportation, logistics, and resource allocation.</li> <li>*Artificial Intelligence:* Algorithms are the foundation of artificial intelligence and machine learning, and are used to develop intelligent systems that can perform tasks such as image recognition, natural language processing, and decision-making.</li> <li>*Data Science:* Algorithms are used to analyze, process, and extract insights from large amounts of data in fields such as marketing, finance, and healthcare. behavior.</li> </ol>"},{"location":"DAA/UNIT_1/#algorithm-specification-introduction-in-data-structure","title":"Algorithm Specification-Introduction in Data Structure","text":"<p>An algorithm is defined as a finite set of instructions that, if followed, performs a particular task. All algorithms must satisfy the following criteria</p> <p>Input. An algorithm has zero or more inputs, taken or collected from a specified set of objects.</p> <p>Output. An algorithm has one or more outputs having a specific relation to the inputs.</p> <p>Definiteness. Each step must be clearly defined; Each instruction must be clear and unambiguous.</p> <p>Finiteness. The algorithm must always finish or terminate after a finite number of steps.</p> <p>Effectiveness. All operations to be accomplished must be sufficiently basic that they can be done exactly and in finite length.</p> <p>We can depict an algorithm in many ways.</p> <ul> <li>Natural language: implement a natural language like English</li> <li>Flow charts: Graphic representations denoted flowcharts, only if the algorithm is small and simple.</li> <li>Pseudo code: This pseudo code skips most issues of ambiguity; no particularity regarding syntax programming language.</li> </ul> <p>Example 1: Algorithm for calculating factorial value of a number</p> <p>Step 1: a number n is inputted Step 2: variable final is set as 1 Step 3: final&lt;= final * n Step 4: decrease n Step 5: verify if n is equal to 0 Step 6: if n is equal to zero, goto step 8 (break out of loop) Step 7: else goto step 3 Step 8: the result final is printed</p>"},{"location":"DAA/UNIT_1/#recursive-algorithms","title":"Recursive Algorithms","text":"<p>A recursive algorithm calls itself which generally passes the return value as a parameter to the algorithm again. This parameter indicates the input while the return value indicates the output.</p> <p>Recursive algorithm is defined as a method of simplification that divides the problem into sub-problems of the same nature. The result of one recursion is treated as the input for the next recursion. The repletion is in the self-similar fashion manner. The algorithm calls itself with smaller input values and obtains the results by simply accomplishing the operations on these smaller values. Generation of factorial, Fibonacci number series are denoted as the examples of recursive algorithms.</p> <p>Example: Writing factorial function using recursion</p> <p>intfactorialA(int n) {    return n * factorialA(n-1); }</p>"},{"location":"DAA/UNIT_1/#introduction-to-analysis-of-algorithms","title":"Introduction to Analysis of Algorithms","text":"<p>In theoretical analysis of algorithms, it is common to estimate their complexity in the asymptotic sense, i.e., to estimate the complexity function for arbitrarily large input. The term  \"analysis of algorithms\"  was coined by Donald Knuth.</p> <p>Algorithm analysis is an important part of computational complexity theory, which provides theoretical estimation for the required resources of an algorithm to solve a specific computational problem. Most algorithms are designed to work with inputs of arbitrary length. Analysis of algorithms is the determination of the amount of time and space resources required to execute it.</p> <p>Usually, the efficiency or running time of an algorithm is stated as a function relating the input length to the number of steps, known as  time complexity, or volume of memory, known as  space complexity.</p>"},{"location":"DAA/UNIT_1/#analyzing-algorithm-control-structure","title":"Analyzing Algorithm Control Structure","text":"<p>To analyze a programming code or algorithm, we must notice that each instruction affects the overall performance of the algorithm and therefore, each instruction must be analyzed separately to analyze overall performance. However, there are some algorithm control structures which are present in each programming code and have a specific asymptotic analysis.</p> <p>Some Algorithm Control Structures are:</p> <ol> <li>Sequencing</li> <li>If-then-else</li> <li>for loop</li> <li>While loop</li> </ol>"},{"location":"DAA/UNIT_1/#1-sequencing","title":"1. Sequencing:","text":"<p>Suppose our algorithm consists of two parts A and B. A takes time tA  and B takes time tB  for computation. The total computation \"tA  + tB\" is according to the sequence rule. According to maximum rule, this computation time is (max (tA,tB)).</p> <p>Example:</p> <p>Suppose tA =O (n) and tB = \u03b8 (n2).  Then, the  total computation time can be calculated as  Computation Time = tA + tB  = (max (tA,tB)  = (max (O (n), \u03b8 (n2)) = \u03b8 (n2)</p>"},{"location":"DAA/UNIT_1/#2-if-then-else","title":"2. If-then-else:","text":"<p>The total time computation is according to the condition rule-\"if-then-else.\" According to the maximum rule, this computation time is max (tA,tB).</p> <p>Example:</p> <p>Suppose tA = O (n2) and tB = \u03b8 (n2) Calculate the total computation time for the following:</p> <p></p> <p>Total Computation = (max (tA,tB))                   = max (O (n2), \u03b8 (n2) = \u03b8 (n2)</p>"},{"location":"DAA/UNIT_1/#3-for-loop","title":"3. For loop:","text":"<p>The general format of for loop is:</p> <ol> <li> <p>For (initialization; condition; updation)</p> </li> <li> <p>Statement(s);</p> </li> </ol>"},{"location":"DAA/UNIT_1/#complexity-of-for-loop","title":"Complexity of for loop:","text":"<p>The outer loop executes N times. Every time the outer loop executes, the inner loop executes M times. As a result, the statements in the  inner  loop execute a total of N * M times. Thus, the total complexity for the two loops is O (N2)</p> <p>Consider the following loop:</p> <ol> <li>for i \u2190 1 to n</li> <li>{</li> <li>P (i)</li> <li>}</li> </ol> <p>If the computation time ti  for ( PI) various as a function of \"i\", then the total computation time for the loop is given not by a multiplication but by a sum i.e.</p> <ol> <li>For i \u2190 1 to n</li> <li>{</li> <li>P (i)</li> <li>}</li> </ol> <p>Takes  </p> <p>If the algorithms consist of nested \"for\" loops, then the total computation time is</p> <p>For i \u2190 1 to n  {       For j \u2190  1 to n            {       P (ij)     }  }  </p> <p>Example:</p> <p>Consider the following \"for\" loop, Calculate the total computation time for the following:</p> <ol> <li>For i \u2190 2 to n-1</li> <li>{</li> <li>For j \u2190 3 to i</li> <li>{</li> <li>Sum \u2190 Sum+A [i] [j]</li> <li>}</li> <li>}</li> </ol> <p>Solution:</p> <p>The total Computation time is:</p> <p></p>"},{"location":"DAA/UNIT_1/#4-while-loop","title":"4. While loop:","text":"<p>The Simple technique for analyzing the loop is to determine the function of variable involved whose value decreases each time around. Secondly, for terminating the loop, it is necessary that value must be a positive integer. By keeping track of how many times the value of function decreases, one can obtain the number of repetition of the loop. The other approach for analyzing \"while\" loop is to treat them as recursive algorithms.</p>"},{"location":"DAA/UNIT_1/#algorithm","title":"Algorithm:","text":"<ol> <li> <ol> <li>[Initialize] Set k: =1, LOC: =1 and MAX: = DATA [1]</li> </ol> </li> <li> <ol> <li>Repeat steps 3 and 4  while K\u2264N</li> </ol> </li> <li> <ol> <li>if MAX&lt;DATA [k],then:</li> </ol> </li> <li>Set LOC: = K and MAX: = DATA [k]</li> <li> <ol> <li>Set k: = k+1</li> </ol> </li> <li>[End of step 2 loop]</li> <li> <ol> <li>Write: LOC, MAX</li> </ol> </li> <li> <ol> <li>EXIT</li> </ol> </li> </ol> <p>Example:</p> <p>The running time of algorithm array Max of computing the maximum element in an array of n integer is O (n).</p> <p>Solution:</p> <ol> <li>array Max (A, n)</li> <li> <ol> <li>Current max \u2190 A [0]</li> </ol> </li> <li> <ol> <li>For i \u2190 1 to n-1</li> </ol> </li> <li> <ol> <li>do  if current max &lt; A [i]</li> </ol> </li> <li> <ol> <li>then current max \u2190 A [i]</li> </ol> </li> <li> <ol> <li>return current max.</li> </ol> </li> </ol> <p>The number of primitive operation t (n) executed by this algorithm is at least.</p> <ol> <li>2 + 1 + n +4 (n-1) + 1=5n</li> <li>2 + 1 + n + 6 (n-1) + 1=7n-2</li> </ol> <p>The best case T(n) =5n occurs when A [0] is the maximum element. The worst case T(n) = 7n-2 occurs when element are sorted in increasing order.</p> <p>We may, therefore, apply the big-Oh definition with c=7 and n0=1 and conclude the running time of this is O (n).</p>"},{"location":"DAA/UNIT_1/#asymptotic-notations-and-how-to-calculate-them","title":"Asymptotic Notations and how to calculate them","text":"<p>In mathematics, *asymptotic analysis*, also known as *asymptotics, is a method of describing the limiting behavior of a function. In computing, asymptotic analysis of an algorithm refers to defining the mathematical boundation of its run-time performance based on the input size. For example, the running time of one operation is computed as  _f_(n), and maybe for another operation, it is computed as _g_(n*2**). This means the first operation running time will increase linearly with the increase in n and the running time of the second operation will increase exponentially when n increases. Similarly, the running time of both operations will be nearly the same if n** is small in value.</p> <p>Usually, the analysis of an algorithm is done based on three cases:</p> <ol> <li>*Best Case (Omega Notation (\u03a9))*</li> <li>*Average Case (Theta Notation (\u0398))*</li> <li>*Worst Case (O Notation(O))*</li> </ol> <p>All of these notations are discussed below in detail:</p> <p>*Omega (\u03a9) Notation:*</p> <p>Omega  (\u03a9) notation specifies the asymptotic lower bound for a function f(n). For a given function g(n), \u03a9(g(n)) is denoted by:</p> <p>\u03a9 (g(n)) = {f(n): there exist positive constants c and n0 such that 0 \u2264 c*g(n) \u2264 f(n) for all n \u2265 n0}.</p> <p>This means that, f(n) = \u03a9(g(n)), If there are positive constants n0 and c such that, to the right of n0 the f(n) always lies on or above c*g(n).</p> <p></p> <p>Graphical representation</p> <p>Follow the steps below to calculate \u03a9 for a program:</p> <ol> <li>Break the program into smaller segments.</li> <li>Find the number of operations performed for each segment(in terms of the input size) assuming the given input is such that the program takes the least amount of time.</li> <li>Add up all the operations and simplify it, let\u2019s say it is f(n).</li> <li>Remove all the constants and choose the term having the least order or any other function which is always less than f(n) when n tends to infinity, let say it is g(n) then, Omega (\u03a9) of f(n) is \u03a9(g(n)).</li> </ol> <p>Omega notation doesn\u2019t really help to analyze an algorithm because it is bogus to evaluate an algorithm for the best cases of inputs.</p> <p>*Theta (\u0398) Notation:*</p> <p>Big-Theta(\u0398) notation specifies a bound for a function f(n). For a given function g(n), \u0398(g(n)) is denoted by:</p> <p>\u0398 (g(n)) = {f(n): there exist positive constants c1, c2 and n0 such that 0 \u2264 c1g(n) \u2264 f(n) \u2264 c2g(n) for all n \u2265 n0}.</p> <p>This means that, f(n) = \u0398(g(n)), If there are positive constants n0 and c such that, to the right of n0 the f(n) always lies on or above c1g(n) and below c2g(n).</p> <p></p> <p>Graphical representation</p> <p>Follow the steps below to calculate \u0398 for a program:</p> <ol> <li>Break the program into smaller segments.</li> <li>Find all types of inputs and calculate the number of operations they take to be executed. Make sure that the input cases are equally distributed.</li> <li>Find the sum of all the calculated values and divide the sum by the total number of inputs let say the function of n obtained is g(n) after removing all the constants, then in \u0398 notation, it\u2019s represented as \u0398(g(n)).</li> </ol> <p>*Example:* In a linear search problem, let\u2019s assume that all the cases are uniformly distributed (including the case when the key is absent in the array). So, sum all the cases when the key is present at positions 1, 2, 3, \u2026\u2026, n and not present, and divide the sum by n + 1.</p> <p>Average case time complexity = </p> <p>\u21d2 </p> <p>\u21d2 </p> <p>\u21d2 </p> <p>Since all the types of inputs are considered while calculating the average time complexity, it is one of the best analysis methods for an algorithm.</p> <p>*Big \u2013 O Notation:*</p> <p>Big \u2013 O (O) notation specifies the asymptotic upper bound for a function f(n). For a given function g(n), O(g(n)) is denoted by:</p> <p>O (g(n)) = {f(n): there exist positive constants c and n0 such that f(n) \u2264 c*g(n) for all n \u2265 n0}.</p> <p>This means that, f(n) = O(g(n)), If there are positive constants n0 and c such that, to the right of n0 the f(n) always lies on or below c*g(n).</p> <p></p> <p>Graphical representation</p> <p>Follow the steps below to calculate O for a program:</p> <ol> <li>Break the program into smaller segments.</li> <li>Find the number of operations performed for each segment (in terms of the input size) assuming the given input is such that the program takes the maximum time i.e the worst-case scenario.</li> <li>Add up all the operations and simplify it, let\u2019s say it is *f(n).*</li> <li>Remove all the constants and choose the term having the highest order because for *n tends to infinity the constants and the lower order terms in f(n) will be insignificant, let say the function is g(n) then, big-O notation is O(g(n)).*</li> </ol> <p>It is the most widely used notation as it is easier to calculate since there is no need to check for every type of input as it was in the case of theta notation, also since the worst case of input is taken into account it pretty much gives the upper bound of the time the program will take to execute.</p>"},{"location":"DAA/UNIT_1/#space-complexity","title":"Space complexity","text":""},{"location":"DAA/UNIT_1/#space-complexity_1","title":"Space Complexity","text":"<p>Space complexity is a function describing the amount of memory (space) an algorithm takes in terms of the amount of input to the algorithm.</p> <p>We often speak of extra memory needed, not counting the memory needed to store the input itself. Again, we use natural (but fixed-length) units to measure this.</p> <p>We can use bytes, but it's easier to use, say, the number of integers used, the number of fixed-sized structures, etc.</p> <p>In the end, the function we come up with will be independent of the actual number of bytes needed to represent the unit.</p> <p>Space complexity is sometimes ignored because the space used is minimal and/or obvious, however sometimes it becomes as important an issue as time complexity.</p>"},{"location":"DAA/UNIT_1/#definition","title":"Definition","text":"<p>Let M be a deterministic Turing machine (TM) that halts on all inputs. The space complexity of M is the function f: N -&gt; N, where f(n) is the maximum number of cells of tape and M scans any input of length M. If the space complexity of M is f(n), we can say that M runs in space f(n).</p> <p>We estimate the space complexity of a Turing machine by using asymptotic notation.</p> <p>Let f: N -&gt; R\u207a be a function. The space complexity classes can be defined as follows:</p> <ul> <li>SPACE = {L | L is a language decided by an O(f(n)) space deterministic TM}</li> <li>SPACE = {L | L is a language decided by an O(f(n)) space non-deterministic TM}</li> <li>PSPACE is the class of languages that are decidable in polynomial space on a deterministic Turing machine. In other words, PSPACE = \u22c3 SPACE (n\u1d4f)</li> </ul>"},{"location":"DAA/UNIT_1/#savitchs-theorem","title":"Savitch's Theorem","text":"<p>One of the earliest theorems related to space complexity is Savitch\u2019s theorem. According to this theorem, a deterministic machine can simulate non-deterministic machines using a small amount of space.</p> <p>For time complexity, such a simulation seems to require an exponential increase in time. For space complexity, this theorem shows that any non-deterministic Turing machine that uses f(n) space can be converted to a deterministic TM that uses f\u00b2(n) space.</p> <p>Hence, Savitch\u2019s theorem states that, for any function, f: N -&gt; R\u207a, where f(n) \u2265 n: NSPACE(f(n)) \u2286 SPACE(f(n))</p>"},{"location":"DAA/UNIT_1/#relationship-among-complexity-classes","title":"Relationship Among Complexity Classes","text":"<p>The following diagram depicts the relationship among different complexity classes.</p> <p></p> <p>Till now, we have not discussed P and NP classes in this tutorial. These will be discussed later.</p>"},{"location":"DAA/UNIT_1/#time-complexity","title":"Time complexity","text":"<p>Time complexity of an algorithm signifies the total time required by the program to run till its completion.</p> <p>The time complexity of algorithms is most commonly expressed using the  big O notation. It's an asymptotic notation to represent the time complexity. We will study about it in detail in the next tutorial.</p> <p>Time Complexity is most commonly estimated by counting the number of elementary steps performed by any algorithm to finish execution. Like in the example above, for the first code the loop will run  <code>n</code>  number of times, so the time complexity will be  <code>n</code>  atleast and as the value of  <code>n</code>  will increase the time taken will also increase. While for the second code, time complexity is constant, because it will never be dependent on the value of  <code>n</code>, it will always give the result in 1 step.</p> <p>And since the algorithm's performance may vary with different types of input data, hence for an algorithm we usually use the  worst-case Time complexity  of an algorithm because that is the maximum time taken for any input size.</p>"},{"location":"DAA/UNIT_1/#performance-measurement","title":"Performance measurement","text":"<p>Performance measurement is the process used to assess the efficiency and effectiveness of projects, programs and initiatives. It is a systematic approach to collecting, analyzing and evaluating how \u201con track\u201d a project/program is to achieve its desired outcomes, goals and objectives.</p> <p>Performance measurement is typically done by an organization to demonstrate accountability, support decision making and improve processes. Note that It is not an approach that prescribes what must be measured; organizations need to develop their own performance measures based on their project plans and situation.</p> <p>Performance measurement should be treated as an integral part of any planning process from the outset and should be built into any plan or project that has clear goals and objectives.</p> <p>Performance measures provide the information to assist in making strategic decisions about what an organization does and how it performs. Performance measurement frameworks are flexible and can be used to measure the effectiveness of a pilot project, a multi-year program or a strategic planning process and can be applied to a new or existing initiative.</p>"},{"location":"DAA/UNIT_1/#key-terminology","title":"Key terminology","text":"<p>Performance measures are also called performance metrics and performance indicators, and the terms can be used interchangeably</p>"},{"location":"DAA/UNIT_1/#benefits-of-performance-measures","title":"Benefits of performance measures","text":"<p>The benefits of measuring performance are numerous and range from measuring the effectiveness of a single project to contributing to a culture of continuous improvement throughout an organization.</p> <p>Using performance measures on a regular basis helps to inform decisions and means a plan can be adjusted mid-course or priorities can be reset to take advantage of emerging opportunities. An internal performance measurement system will drive results and enable an organization to learn from its successes and failures.</p> <p>Other benefits of performance measures include:</p> <ul> <li>Creates \u201cbuy-in\u201d through stakeholders setting targets and goals together.</li> <li>Develops \u201cbest practices\u201d and \u201clessons learned\u201d that can be applied to future initiatives.</li> <li>Increases accountability by demonstrating the effectiveness and value of plans and activities in achieving desired goals/outcomes.</li> <li>Informs decision-making including budgeting and resource allocation in an environment where there may be competition over limited resources.</li> <li>Helps to demonstrate and document changes over time.</li> <li>Helps to communicate an organization\u2019s story.</li> <li>Develops relationships through engaging stakeholders and building a common understanding of the process.</li> </ul>"},{"location":"DAA/UNIT_1/#analyzing-control-structure","title":"Analyzing Control Structure","text":"<p>To analyze a programming code or algorithm, we must notice that each instruction affects the overall performance of the algorithm and therefore, each instruction must be analyzed separately to analyze overall performance. However, there are some algorithm control structures which are present in each programming code and have a specific asymptotic analysis.</p> <p>Some Algorithm Control Structures are:</p> <ol> <li>Sequencing</li> <li>If-then-else</li> <li>for loop</li> <li>While loop</li> </ol>"},{"location":"DAA/UNIT_1/#1-sequencing_1","title":"1. Sequencing:","text":"<p>Suppose our algorithm consists of two parts A and B. A takes time tA  and B takes time tB  for computation. The total computation \"tA  + tB\" is according to the sequence rule. According to maximum rule, this computation time is (max (tA,tB)).</p> <p>Example:</p> <p>Suppose tA =O (n) and tB = \u03b8 (n2).  Then, the  total computation time can be calculated as  Computation Time = tA + tB  = (max (tA,tB)  = (max (O (n), \u03b8 (n2)) = \u03b8 (n2)</p>"},{"location":"DAA/UNIT_1/#2-if-then-else_1","title":"2. If-then-else:","text":"<p>The total time computation is according to the condition rule-\"if-then-else.\" According to the maximum rule, this computation time is max (tA,tB).</p> <p>Example:</p> <p>Suppose tA = O (n2) and tB = \u03b8 (n2) Calculate the total computation time for the following:</p> <p></p> <p>Total Computation = (max (tA,tB))                   = max (O (n2), \u03b8 (n2) = \u03b8 (n2)</p>"},{"location":"DAA/UNIT_1/#3-for-loop_1","title":"3. For loop:","text":"<p>The general format of for loop is:</p> <ol> <li> <p>For (initialization; condition; updation)</p> </li> <li> <p>Statement(s);</p> </li> </ol>"},{"location":"DAA/UNIT_1/#complexity-of-for-loop_1","title":"Complexity of for loop:","text":"<p>The outer loop executes N times. Every time the outer loop executes, the inner loop executes M times. As a result, the statements in the  inner  loop execute a total of N * M times. Thus, the total complexity for the two loops is O (N2)</p> <p>Consider the following loop:</p> <ol> <li>for i \u2190 1 to n</li> <li>{</li> <li>P (i)</li> <li>}</li> </ol> <p>If the computation time ti  for ( PI) various as a function of \"i\", then the total computation time for the loop is given not by a multiplication but by a sum i.e.</p> <ol> <li>For i \u2190 1 to n</li> <li>{</li> <li>P (i)</li> <li>}</li> </ol> <p>Takes  </p> <p>If the algorithms consist of nested \"for\" loops, then the total computation time is</p> <p>For i \u2190 1 to n  {       For j \u2190  1 to n            {       P (ij)     }  }  </p> <p>Example:</p> <p>Consider the following \"for\" loop, Calculate the total computation time for the following:</p> <ol> <li>For i \u2190 2 to n-1</li> <li>{</li> <li>For j \u2190 3 to i</li> <li>{</li> <li>Sum \u2190 Sum+A [i] [j]</li> <li>}</li> <li>}</li> </ol> <p>Solution:</p> <p>The total Computation time is:</p> <p></p>"},{"location":"DAA/UNIT_1/#4-while-loop_1","title":"4. While loop:","text":"<p>The Simple technique for analyzing the loop is to determine the function of variable involved whose value decreases each time around. Secondly, for terminating the loop, it is necessary that value must be a positive integer. By keeping track of how many times the value of function decreases, one can obtain the number of repetition of the loop. The other approach for analyzing \"while\" loop is to treat them as recursive algorithms.</p>"},{"location":"DAA/UNIT_1/#algorithm_1","title":"Algorithm:","text":"<ol> <li> <ol> <li>[Initialize] Set k: =1, LOC: =1 and MAX: = DATA [1]</li> </ol> </li> <li> <ol> <li>Repeat steps 3 and 4  while K\u2264N</li> </ol> </li> <li> <ol> <li>if MAX&lt;DATA [k],then:</li> </ol> </li> <li>Set LOC: = K and MAX: = DATA [k]</li> <li> <ol> <li>Set k: = k+1</li> </ol> </li> <li>[End of step 2 loop]</li> <li> <ol> <li>Write: LOC, MAX</li> </ol> </li> <li> <ol> <li>EXIT</li> </ol> </li> </ol> <p>Example:</p> <p>The running time of algorithm array Max of computing the maximum element in an array of n integer is O (n).</p> <p>Solution:</p> <ol> <li>array Max (A, n)</li> <li> <ol> <li>Current max \u2190 A [0]</li> </ol> </li> <li> <ol> <li>For i \u2190 1 to n-1</li> </ol> </li> <li> <ol> <li>do  if current max &lt; A [i]</li> </ol> </li> <li> <ol> <li>then current max \u2190 A [i]</li> </ol> </li> <li> <ol> <li>return current max.</li> </ol> </li> </ol> <p>The number of primitive operation t (n) executed by this algorithm is at least.</p> <ol> <li>2 + 1 + n +4 (n-1) + 1=5n</li> <li>2 + 1 + n + 6 (n-1) + 1=7n-2</li> </ol> <p>The best case T(n) =5n occurs when A [0] is the maximum element. The worst case T(n) = 7n-2 occurs when element are sorted in increasing order.</p> <p>We may, therefore, apply the big-Oh definition with c=7 and n0=1 and conclude the running time of this is O (n).</p>"},{"location":"DAA/UNIT_1/#worst-average-and-best-case-analysis-of-algorithms","title":"Worst, Average and Best Case Analysis of Algorithms","text":""},{"location":"DAA/UNIT_1/#popular-notations-in-complexity-analysis-of-algorithms","title":"Popular Notations in Complexity Analysis of Algorithms","text":""},{"location":"DAA/UNIT_1/#1-big-o-notation","title":"*1. Big-O Notation*","text":"<p>We define an algorithm\u2019s *worst-case* time complexity by using the Big-O notation, which determines the set of functions grows slower than or at the same rate as the expression. Furthermore, it explains the maximum amount of time an algorithm requires to consider all input values.</p>"},{"location":"DAA/UNIT_1/#2-omega-notation","title":"*2. Omega Notation*","text":"<p>It defines the *best case* of an algorithm\u2019s time complexity, the Omega notation defines whether the set of functions will grow faster or at the same rate as the expression. Furthermore, it explains the minimum amount of time an algorithm requires to consider all input values.</p>"},{"location":"DAA/UNIT_1/#3-theta-notation","title":"*3. Theta Notation*","text":"<p>It defines the *average case of an algorithm\u2019s time complexity, the Theta notation defines when the set of functions lies in both O(expression) and Omega(expression)*, then Theta notation is used. This is how we define a time complexity average case for an algorithm.</p>"},{"location":"DAA/UNIT_1/#measurement-of-complexity-of-an-algorithm","title":"Measurement of Complexity of an Algorithm","text":"<p>Based on the above three notations of Time Complexity there are three cases to analyze an algorithm:</p>"},{"location":"DAA/UNIT_1/#1-worst-case-analysis-mostly-used","title":"*1. Worst Case Analysis (Mostly used)*","text":"<p>In the worst-case analysis, we calculate the upper bound on the running time of an algorithm. We must know the case that causes a maximum number of operations to be executed. For Linear Search, the worst case happens when the element to be searched (x) is not present in the array. When x is not present, the search()  function compares it with all the elements of arr[] one by one. Therefore, the worst-case time complexity of the linear search would be *O(n)*.</p>"},{"location":"DAA/UNIT_1/#2-best-case-analysis-very-rarely-used","title":"*2. Best Case Analysis (Very Rarely used)*","text":"<p>In the best-case analysis, we calculate the lower bound on the running time of an algorithm. We must know the case that causes a minimum number of operations to be executed. In the linear search problem, the best case occurs when x is present at the first location. The number of operations in the best case is constant (not dependent on n). So time complexity in the best case would be ?(1)</p>"},{"location":"DAA/UNIT_1/#3-average-case-analysis-rarely-used","title":"*3. Average Case Analysis (Rarely used)*","text":"<p>In average case analysis, we take all possible inputs and calculate the computing time for all of the inputs. Sum all the calculated values and divide the sum by the total number of inputs. We must know (or predict) the distribution of cases. For the linear search problem, let us assume that all cases are uniformly distributed (including the case of x not being present in the array). So we sum all the cases and divide the sum by (n+1). Following is the value of average-case time complexity.</p>"},{"location":"DAA/UNIT_1/#iterative-algorithm-analysis","title":"Iterative Algorithm Analysis","text":"<p>Iterative algorithms are a class of algorithms that repeat a set of instructions or operations until a specific condition is met. These algorithms use iteration, which involves repeating a process multiple times, often with the aim of converging to a solution or achieving a desired result. Iterative algorithms are common in various fields, including computer science, optimization, numerical analysis, and machine learning.</p> <p>When analyzing iterative algorithms, several key factors are typically considered:</p> <ol> <li> <p>Termination Condition: Iterative algorithms continue executing until a certain condition is satisfied. This condition is known as the termination condition. It is crucial to ensure that the algorithm terminates, preventing an infinite loop.</p> </li> <li> <p>Convergence: For many iterative algorithms, especially those used in optimization or numerical methods, convergence is a critical aspect. Convergence refers to the algorithm's ability to approach a specific solution or a desired accuracy as the number of iterations increases.</p> </li> <li> <p>Time Complexity: Time complexity measures the amount of time an algorithm takes to complete as a function of the size of its input. Analyzing the time complexity of an iterative algorithm helps determine its efficiency in terms of execution time.</p> </li> <li> <p>Space Complexity: Space complexity measures the amount of memory an algorithm uses as a function of its input size. It helps assess the algorithm's efficiency in terms of memory usage.</p> </li> <li> <p>Initialization: The initial conditions or starting values can significantly affect the performance and convergence of an iterative algorithm. Proper initialization is often crucial for achieving accurate and efficient results.</p> </li> <li> <p>Optimality: In some cases, iterative algorithms are designed to find optimal solutions. Analyzing whether an algorithm consistently converges to the optimal solution is essential.</p> </li> <li> <p>Stability: Stability is important in iterative algorithms, especially in numerical methods. It ensures that small changes in input or initial conditions do not result in drastic changes in the output.</p> </li> <li> <p>Convergence Rate: The speed at which an iterative algorithm converges to a solution is known as the convergence rate. Faster convergence is generally desirable, especially in real-time or resource-constrained applications.</p> </li> <li> <p>Trade-offs: Consideration of trade-offs between time complexity, space complexity, and accuracy is often necessary. Some algorithms may be more computationally expensive but offer higher accuracy, while others may prioritize speed with some compromise in precision.</p> </li> <li> <p>Parallelization: Assessing the potential for parallelization is crucial, especially in the context of modern computing architectures. Some iterative algorithms can be parallelized to take advantage of multiple processing units, improving overall performance.</p> </li> </ol> <p>Analyzing these aspects helps in understanding the behavior, efficiency, and limitations of iterative algorithms, enabling practitioners to choose the most suitable algorithm for a specific problem.</p>"},{"location":"DAA/UNIT_1/#references","title":"References","text":"<p>https://www.geeksforgeeks.org/introduction-to-algorithms/ https://www.tutorialspoint.com/algorithm-specification-introduction-in-data-structure https://www.tutorialspoint.com/introduction-to-analysis-of-algorithms https://www.javatpoint.com/daa-analyzing-algorithm-control-structure https://www.geeksforgeeks.org/asymptotic-notations-and-how-to-calculate-them/ https://www.tutorialspoint.com/design_and_analysis_of_algorithms/design_and_analysis_of_algorithms_space_complexities.htm https://www.studytonight.com/data-structures/time-complexity-of-algorithms https://www.ontario.ca/document/performance-measurement-agriculture-agri-food-and-economic-development-organizations/what-performance-measurement https://www.javatpoint.com/daa-analyzing-algorithm-control-structure https://www.geeksforgeeks.org/worst-average-and-best-case-analysis-of-algorithms/</p>"},{"location":"DAA/UNIT_2/","title":"Recurrence Relation","text":""},{"location":"DAA/UNIT_2/#recurance-relation","title":"Recurance Relation","text":"<p>A recurrence is an equation or inequality that describes a function in terms of its values on smaller inputs. To solve a Recurrence Relation means to obtain a function defined on the natural numbers that satisfy the recurrence.</p> <p>For Example, the Worst Case Running Time T(n) of the MERGE SORT Procedures is described by the recurrence.</p> <p>T (n) = \u03b8 (1) if n=1  2T + \u03b8 (n) if n&gt;1</p> <p>There are four methods for solving Recurrence:</p> <ol> <li>Substitution Method</li> <li>Iteration Method</li> <li>Recursion Tree Method</li> <li>Master Method</li> </ol>"},{"location":"DAA/UNIT_2/#1-substitution-method","title":"1. Substitution Method:","text":"<p>The Substitution Method Consists of two main steps:</p> <ol> <li>Guess the Solution.</li> <li>Use the mathematical induction to find the boundary condition and shows that the guess is correct.</li> </ol> <p>For Example1  Solve the equation by Substitution Method.</p> <pre><code>T (n) = T![DAA Recurrence Relation](https://static.javatpoint.com/tutorial/daa/images/daa-recurrence-relation.png) + n\n</code></pre> <p>We have to show that it is asymptotically bound by O (log n).</p> <p>Solution:</p> <p>For T (n) = O (log n)</p> <p>We have to show that for some constant c</p> <ol> <li>T (n) \u2264c logn.</li> </ol> <p>Put this in given Recurrence Equation.</p> <pre><code>T (n) \u2264c log![DAA Recurrence Relation](https://static.javatpoint.com/tutorial/daa/images/daa-recurrence-relation.png)+ 1\n        \u2264c log![DAA Recurrence Relation](https://static.javatpoint.com/tutorial/daa/images/daa-recurrence-relation.png)+ 1 = c logn-clog2 2+1\n        \u2264c logn for c\u22651\n</code></pre> <p>Thus T (n) =O logn.</p> <p>Example2  Consider the Recurrence</p> <p>T (n) = 2T+ n n&gt;1</p> <p>Find an Asymptotic bound on T.</p> <p>Solution:</p> <p>We guess the solution is O (n (logn)).Thus for constant 'c'.  T (n) \u2264c n logn Put this in given Recurrence Equation. Now,   T (n) \u22642clog +n       \u2264cnlogn-cnlog2+n       =cn logn-n (clog2-1)       \u2264cn logn for (c\u22651) Thus T (n) = O (n logn).</p>"},{"location":"DAA/UNIT_2/#2-iteration-methods","title":"2. Iteration Methods","text":"<p>It means to expand the recurrence and express it as a summation of terms of n and initial condition.</p> <p>Example1:  Consider the Recurrence</p> <ol> <li>T (n) = 1  if n=1</li> <li>= 2T (n-1) if n&gt;1</li> </ol> <p>Solution:</p> <p>T (n) = 2T (n-1)       = 2[2T (n-2)] = 22T (n-2)       = 4[2T (n-3)] = 23T (n-3)       = 8[2T (n-4)] = 24T (n-4)   (Eq.1)</p> <p>Repeat the procedure for i times</p> <p>T (n) = 2i T (n-i) Put n-i=1 or i= n-1 in    (Eq.1) T (n) = 2n-1 T (1)       = 2n-1 .1    {T (1) =1 .....given}       = 2n-1 </p> <p>Example2:  Consider the Recurrence</p> <ol> <li>T (n) = T (n-1) +1 and T (1) = \u03b8 (1).</li> </ol> <p>Solution:</p> <p>T (n) = T (n-1) +1        = (T (n-2) +1) +1 = (T (n-3) +1) +1+1        = T (n-4) +4 = T (n-5) +1+4        = T (n-5) +5= T (n-k) + k Where k = n-1    T (n-k) = T (1) = \u03b8 (1)    T (n) = \u03b8 (1) + (n-1) = 1+n-1=n= \u03b8 (n).</p>"},{"location":"DAA/UNIT_2/#solutions-of-recurrence-relations-by-master-methods","title":"Solutions of recurrence relations by Master Methods","text":"<p>The Master Method is used for solving the following types of recurrence</p> <p>T (n) = a T+ f (n) with a\u22651 and b\u22651 be constant &amp; f(n) be a function and  can be interpreted as</p> <p>Let T (n) is defined on non-negative integers by the recurrence.</p> <p>T (n) = a T+ f (n)</p> <p>In the function to the analysis of a recursive algorithm, the constants and function take on the following significance:</p> <ul> <li>n is the size of the problem.</li> <li>a is the number of subproblems in the recursion.</li> <li>n/b is the size of each subproblem. (Here it is assumed that all subproblems are essentially the same size.)</li> <li>f (n) is the sum of the work done outside the recursive calls, which includes the sum of dividing the problem and the sum of combining the solutions to the subproblems.</li> <li>It is not possible always bound the function according to the requirement, so we make three cases which will tell us what kind of bound we can apply on the function.</li> </ul>"},{"location":"DAA/UNIT_2/#master-theorem","title":"Master Theorem:","text":"<p>It is possible to complete an asymptotic tight bound in these three cases:</p> <p></p> <p>Case1:  If f (n) =    for some constant \u03b5 &gt;0, then it follows that:</p> <p>T (n) = \u0398 </p> <p>Example:</p> <p>T (n) = 8 T  apply master theorem on it.</p> <p>Solution:</p> <p>Compare T (n) = 8 T  with   T (n) = a T   a = 8, b=2, f (n) = 1000 n2, logba = log28 = 3  Put all the values in: f (n) =       1000 n2 = O (n3-\u03b5 )       If we choose \u03b5=1, we get: 1000 n2 = O (n3-1) = O (n2)</p> <p>Since this equation holds, the first case of the master theorem applies to the given recurrence relation, thus resulting in the conclusion:</p> <p>T (n) = \u0398     Therefore: T (n) = \u0398 (n3) </p> <p>Case 2:  If it is true, for some constant k \u2265 0 that:</p> <p>F (n) = \u0398  then it follows that: T (n) = \u0398 </p> <p>Example:</p> <p>T (n) = 2 , solve the recurrence by using the master method. As compare the given problem with T (n) = a T a = 2, b=2, k=0, f (n) = 10n, logba = log22 =1  Put all the values in f (n) =\u0398 , we will get      10n = \u0398 (n1) = \u0398 (n) which is true. Therefore: T (n) = \u0398        = \u0398 (n log n)</p> <p>Case 3:  If it is true f(n) = \u03a9    for some constant \u03b5 &gt;0 and it also true that: a f    for some constant c&lt;1 for large value of n ,then :</p> <ol> <li>T (n) = \u0398((f (n))</li> </ol> <p>Example:  Solve the recurrence relation:</p> <p>T (n) = 2 </p> <p>Solution:</p> <p>Compare the given problem with T (n) = a T  a= 2, b =2, f (n) = n2, logba = log22 =1  Put all the values in f (n) = \u03a9  ..... (Eq. 1) If we insert all the value in (Eq.1), we will get    n2 = \u03a9(n1+\u03b5) put \u03b5 =1, then the equality will hold.   n2 = \u03a9(n1+1) = \u03a9(n2) Now we will also check the second condition:   2  If we will choose c =1/2, it is true:     \u2200 n \u22651  So it follows: T (n) = \u0398 ((f (n))     T (n) = \u0398(n2)</p>"},{"location":"DAA/UNIT_2/#divide-and-conquer","title":"Divide and Conquer","text":"<p>To understand the divide and conquer design strategy of algorithms, let us use a simple real world example. Consider an instance where we need to brush a type C curly hair and remove all the knots from it. To do that, the first step is to section the hair in smaller strands to make the combing easier than combing the hair altogether. The same technique is applied on algorithms.</p> <p>Divide and conquer approach breaks down a problem into multiple sub-problems recursively until it cannot be divided further. These sub-problems are solved first and the solutions are merged together to form the final solution.</p> <p>The common procedure for the divide and conquer design technique is as follows \u2212</p> <ul> <li> <p>Divide  \u2212 We divide the original problem into multiple sub-problems until they cannot be divided further.</p> </li> <li> <p>Conquer  \u2212 Then these subproblems are solved separately with the help of recursion</p> </li> <li> <p>Combine  \u2212 Once solved, all the subproblems are merged/combined together to form the final solution of the original problem.</p> </li> </ul> <p>There are several ways to give input to the divide and conquer algorithm design pattern. Two major data structures used are \u2212  arrays  and  linked lists. Their usage is explained as</p>"},{"location":"DAA/UNIT_2/#arrays-as-input","title":"Arrays as Input","text":"<p>There are various ways in which various algorithms can take input such that they can be solved using the divide and conquer technique. Arrays are one of them. In algorithms that require input to be in the form of a list, like various sorting algorithms, array data structures are most commonly used.</p> <p>In the input for a sorting algorithm below, the array input is divided into subproblems until they cannot be divided further.</p> <p></p> <p>Then, the subproblems are sorted (the conquer step) and are merged to form the solution of the original array back (the combine step).</p> <p></p> <p>Since arrays are indexed and linear data structures, sorting algorithms most popularly use array data structures to receive input.</p>"},{"location":"DAA/UNIT_2/#binary-search-algorithm","title":"Binary Search Algorithm","text":"<p>Binary search is a fast search algorithm with run-time complexity of \u039f(log n). This search algorithm works on the principle of divide and conquer, since it divides the array into half before searching. For this algorithm to work properly, the data collection should be in the sorted form.</p> <p>Binary search looks for a particular key value by comparing the middle most item of the collection. If a match occurs, then the index of item is returned. But if the middle item has a value greater than the key value, the right sub-array of the middle item is searched. Otherwise, the left sub-array is searched. This process continues recursively until the size of a subarray reduces to zero.</p> <p></p>"},{"location":"DAA/UNIT_2/#binary-search-algorithm_1","title":"Binary Search Algorithm","text":"<p>Binary Search algorithm is an interval searching method that performs the searching in intervals only. The input taken by the binary search algorithm must always be in a sorted array since it divides the array into subarrays based on the greater or lower values. The algorithm follows the procedure below \u2212</p> <p>Step 1  \u2212 Select the middle item in the array and compare it with the key value to be searched. If it is matched, return the position of the median.</p> <p>Step 2  \u2212 If it does not match the key value, check if the key value is either greater than or less than the median value.</p> <p>Step 3  \u2212 If the key is greater, perform the search in the right sub-array; but if the key is lower than the median value, perform the search in the left sub-array.</p> <p>Step 4  \u2212 Repeat Steps 1, 2 and 3 iteratively, until the size of sub-array becomes 1.</p> <p>Step 5  \u2212 If the key value does not exist in the array, then the algorithm returns an unsuccessful search.</p>"},{"location":"DAA/UNIT_2/#pseudocode","title":"Pseudocode","text":"<p>The pseudocode of binary search algorithms should look like this \u2212</p> <p>Procedure binary_search    A \u2190 sorted array    n \u2190 size of array    x \u2190 value to be searched</p> <p>Set lowerBound = 1    Set upperBound = n</p> <p>while x not found       if upperBound &lt; lowerBound          EXIT: x does not exists.</p> <pre><code>  set midPoint = lowerBound + ( upperBound - lowerBound ) / 2\n\n  if A[midPoint] &lt; x\n     set lowerBound = midPoint + 1\n\n  if A[midPoint] &gt; x\n     set upperBound = midPoint - 1\n\n  if A[midPoint] = x\n     EXIT: x found at location midPoint\n</code></pre> <p>end while end procedure</p>"},{"location":"DAA/UNIT_2/#analysis","title":"Analysis","text":"<p>Since the binary search algorithm performs searching iteratively, calculating the time complexity is not as easy as the linear search algorithm.</p> <p>The input array is searched iteratively by dividing into multiple sub-arrays after every unsuccessful iteration. Therefore, the recurrence relation formed would be of a dividing function.</p>"},{"location":"DAA/UNIT_2/#quick-sort","title":"Quick sort","text":"<p>It is an algorithm of Divide &amp; Conquer type.</p> <p>Divide:  Rearrange the elements and split arrays into two sub-arrays and an element in between search that each element in left sub array is less than or equal to the average element and each element in the right sub- array is larger than the middle element.</p> <p>Conquer:  Recursively, sort two sub arrays.</p> <p>Combine:  Combine the already sorted array.</p>"},{"location":"DAA/UNIT_2/#algorithm","title":"Algorithm:","text":"<ol> <li>QUICKSORT (array A, int m, int n)</li> <li>1  if (n &gt; m)</li> <li>2 then</li> <li>3 i \u2190 a random index from [m,n]</li> <li>4 swap A [i] with A[m]</li> <li>5 o \u2190 PARTITION (A, m, n)</li> <li>6 QUICKSORT (A, m, o - 1)</li> <li>7 QUICKSORT (A, o + 1, n)</li> </ol>"},{"location":"DAA/UNIT_2/#partition-algorithm","title":"Partition Algorithm:","text":"<p>Partition algorithm rearranges the sub arrays in a place.</p> <ol> <li>PARTITION (array A, int m, int n)</li> <li>1 x \u2190 A[m]</li> <li>2 o \u2190 m</li> <li>3  for p \u2190 m + 1 to n</li> <li>4  do  if (A[p] &lt; x)</li> <li>5 then o \u2190 o + 1</li> <li>6 swap A[o] with A[p]</li> <li>7 swap A[m] with A[o]</li> <li>8  return o</li> </ol> <p>Figure: shows the execution trace partition algorithm</p> <p></p>"},{"location":"DAA/UNIT_2/#merge-sort-algorithm","title":"Merge Sort Algorithm","text":"<p>In this article, we will discuss the merge sort Algorithm. Merge sort is the sorting technique that follows the divide and conquer approach. This article will be very helpful and interesting to students as they might face merge sort as a question in their examinations. In coding or technical interviews for software engineers, sorting algorithms are widely asked. So, it is important to discuss the topic.</p> <p>Merge sort is similar to the quick sort algorithm as it uses the divide and conquer approach to sort the elements. It is one of the most popular and efficient sorting algorithm. It divides the given list into two equal halves, calls itself for the two halves and then merges the two sorted halves. We have to define the  merge()  function to perform the merging.</p> <p>The sub-lists are divided again and again into halves until the list cannot be divided further. Then we combine the pair of one element lists into two-element lists, sorting them in the process. The sorted two-element pairs is merged into the four-element lists, and so on until we get the sorted list.</p> <p>Now, let's see the algorithm of merge sort.</p>"},{"location":"DAA/UNIT_2/#algorithm_1","title":"Algorithm","text":"<p>In the following algorithm,  arr  is the given array,  beg  is the starting element, and  end  is the last element of the array.</p> <ol> <li> <p>MERGE_SORT(arr, beg, end)</p> </li> <li> <p>if beg &lt; end</p> </li> <li>set mid = (beg + end)/2</li> <li>MERGE_SORT(arr, beg, mid)</li> <li>MERGE_SORT(arr, mid + 1, end)</li> <li>MERGE (arr, beg, mid, end)</li> <li> <p>end of if</p> </li> <li> <p>END MERGE_SORT</p> </li> </ol> <p>The important part of the merge sort is the  MERGE  function. This function performs the merging of two sorted sub-arrays that are  A[beg\u2026mid]  and  A[mid+1\u2026end], to build one sorted array  A[beg\u2026end]. So, the inputs of the  MERGE  function are  A[], beg, mid,  and  end.</p> <p>The implementation of the  MERGE  function is given as follows -</p> <ol> <li>/ Function to merge the subarrays of a[] /</li> <li>void merge(int a[], int beg, int mid, int end)</li> <li>{</li> <li>int i, j, k;</li> <li>int n1 = mid - beg + 1;</li> <li> <p>int n2 = end - mid;</p> </li> <li> <p>int LeftArray[n1], RightArray[n2]; //temporary arrays</p> </li> <li> <p>/ copy data to temp arrays /</p> </li> <li>for (int i = 0; i &lt; n1; i++)</li> <li>LeftArray[i] = a[beg + i];</li> <li>for (int j = 0; j &lt; n2; j++)</li> <li> <p>RightArray[j] = a[mid + 1 + j];</p> </li> <li> <p>i = 0, / initial index of first sub-array /</p> </li> <li>j = 0; / initial index of second sub-array /</li> <li> <p>k = beg; / initial index of merged sub-array /</p> </li> <li> <p>while (i &lt; n1 &amp;&amp; j &lt; n2)</p> </li> <li>{</li> <li>if(LeftArray[i] &lt;= RightArray[j])</li> <li>{</li> <li>a[k] = LeftArray[i];</li> <li>i++;</li> <li>}</li> <li>else</li> <li>{</li> <li>a[k] = RightArray[j];</li> <li>j++;</li> <li>}</li> <li>k++;</li> <li>}</li> <li>while (i&lt;n1)</li> <li>{</li> <li>a[k] = LeftArray[i];</li> <li>i++;</li> <li>k++;</li> <li> <p>}</p> </li> <li> <p>while (j&lt;n2)</p> </li> <li>{</li> <li>a[k] = RightArray[j];</li> <li>j++;</li> <li>k++;</li> <li>}</li> <li>}</li> </ol>"},{"location":"DAA/UNIT_2/#working-of-merge-sort-algorithm","title":"Working of Merge sort Algorithm","text":"<p>Now, let's see the working of merge sort Algorithm.</p> <p>To understand the working of the merge sort algorithm, let's take an unsorted array. It will be easier to understand the merge sort via an example.</p> <p>Let the elements of array are -</p> <p></p> <p>According to the merge sort, first divide the given array into two equal halves. Merge sort keeps dividing the list into equal parts until it cannot be further divided.</p> <p>As there are eight elements in the given array, so it is divided into two arrays of size 4.</p> <p></p> <p>Now, again divide these two arrays into halves. As they are of size 4, so divide them into new arrays of size 2.</p> <p></p> <p>Now, again divide these arrays to get the atomic value that cannot be further divided.</p> <p></p> <p>Now, combine them in the same manner they were broken.</p> <p>In combining, first compare the element of each array and then combine them into another array in sorted order.</p> <p>So, first compare 12 and 31, both are in sorted positions. Then compare 25 and 8, and in the list of two values, put 8 first followed by 25. Then compare 32 and 17, sort them and put 17 first followed by 32. After that, compare 40 and 42, and place them sequentially.</p> <p></p> <p>In the next iteration of combining, now compare the arrays with two data values and merge them into an array of found values in sorted order.</p> <p></p> <p>Now, there is a final merging of the arrays. After the final merging of above arrays, the array will look like -</p> <p></p> <p>Now, the array is completely sorted.</p>"},{"location":"DAA/UNIT_2/#merge-sort-complexity","title":"Merge sort complexity","text":"<p>Now, let's see the time complexity of merge sort in best case, average case, and in worst case. We will also see the space complexity of the merge sort.</p>"},{"location":"DAA/UNIT_2/#1-time-complexity","title":"1. Time Complexity","text":"Case Time Complexity Best Case O(n * log n) Average Case O(n * log n) Worst Case O(n * log n) <ul> <li>Best Case Complexity -  It occurs when there is no sorting required, i.e. the array is already sorted. The best-case time complexity of merge sort is  O(n*logn).</li> <li>Average Case Complexity -  It occurs when the array elements are in jumbled order that is not properly ascending and not properly descending. The average case time complexity of merge sort is  O(n*logn).</li> <li>Worst Case Complexity -  It occurs when the array elements are required to be sorted in reverse order. That means suppose you have to sort the array elements in ascending order, but its elements are in descending order. The worst-case time complexity of merge sort is  O(n*logn).</li> </ul>"},{"location":"DAA/UNIT_2/#2-space-complexity","title":"2. Space Complexity","text":"Property Value Space Complexity O(n) Stable YES <ul> <li>The space complexity of merge sort is O(n). It is because, in merge sort, an extra variable is required for swapping.</li> </ul>"},{"location":"DAA/UNIT_2/#maximum-and-minimum-finding","title":"Maximum and Minimum finding","text":"<p>Let us consider a simple problem that can be solved by divide and conquer technique.</p>"},{"location":"DAA/UNIT_2/#maximum-and-minimum-finding_1","title":"Maximum and Minimum finding","text":"<p>The Max-Min Problem in algorithm analysis is finding the maximum and minimum value in an array.</p>"},{"location":"DAA/UNIT_2/#solution","title":"Solution","text":"<p>To find the maximum and minimum numbers in a given array  numbers[]  of size  n, the following algorithm can be used. First we are representing the  naive method  and then we will present  divide and conquer approach.</p>"},{"location":"DAA/UNIT_2/#naive-method","title":"Naive Method","text":"<p>Naive method is a basic method to solve any problem. In this method, the maximum and minimum number can be found separately. To find the maximum and minimum numbers, the following straightforward algorithm can be used.</p> <p>Algorithm: Max-Min-Element (numbers[])  max := numbers[1]  min := numbers[1] </p> <p>for i = 2 to n do     if numbers[i] &gt; max then       max := numbers[i]     if numbers[i] &lt; min then       min := numbers[i]  return (max, min) </p>"},{"location":"DAA/UNIT_2/#example","title":"Example","text":"<p>Following are the implementations of the above approach in various programming languages \u2212</p>"},{"location":"DAA/UNIT_2/#c","title":"C","text":""},{"location":"DAA/UNIT_2/#include","title":"include  <p>struct Pair {     int max;     int min; }; // Function to find maximum and minimum using the naive algorithm struct Pair maxMinNaive(int arr[], int n) {     struct Pair result;     result.max = arr[0];     result.min = arr[0];     // Loop through the array to find the maximum and minimum values     for (int i = 1; i &lt; n; i++) {         if (arr[i] &gt; result.max) {             result.max = arr[i]; // Update the maximum value if a larger element is found         }         if (arr[i] &lt; result.min) {             result.min = arr[i]; // Update the minimum value if a smaller element is found         }     }     return result; // Return the pair of maximum and minimum values } int main() {     int arr[] = {6, 4, 26, 14, 33, 64, 46};     int n = sizeof(arr) / sizeof(arr[0]);     struct Pair result = maxMinNaive(arr, n);     printf(\"Maximum element is: %d\\n\", result.max);     printf(\"Minimum element is: %d\\n\", result.min);     return 0; }</p>","text":""},{"location":"DAA/UNIT_2/#output","title":"Output","text":"<p>Maximum element is: 64 Minimum element is: 4</p>"},{"location":"DAA/UNIT_2/#reference","title":"Reference","text":"<p>https://www.javatpoint.com/daa-recurrence-relation https://www.javatpoint.com/daa-master-method https://www.tutorialspoint.com/data_structures_algorithms/divide_and_conquer.htm https://www.tutorialspoint.com/design_and_analysis_of_algorithms/design_and_analysis_of_algorithms_binary_search_method.htm https://www.javatpoint.com/daa-quick-sort https://www.javatpoint.com/merge-sort https://www.tutorialspoint.com/design_and_analysis_of_algorithms/design_and_analysis_of_algorithms_max_min_problem.htm</p>"},{"location":"DAA/UNIT_3/","title":"COMING SOON!","text":""},{"location":"DAA/UNIT_4/","title":"COMING SOON!","text":""},{"location":"DAA/UNIT_5/","title":"COMING SOON!","text":""},{"location":"DAA/cae1/","title":"COMING SOON!","text":""},{"location":"DAA/cae2/","title":"COMING SOON!","text":""},{"location":"DAA/cae3/","title":"COMING SOON!","text":""},{"location":"DAR/","title":"Lab Manual","text":""},{"location":"OS/","title":"OPERATING SYSTEM","text":"Unit Topic Duration UNIT I Introduction 8 Evolution of OS, Types of OS, Basic h/w support necessary for modern operating systems, services provided by OS, system programs and system calls, system design and implementation UNIT II Process &amp; Its Scheduling 8 Process concept, process control block, Types of scheduler, context switch, threads, multithreading model, goals of scheduling and different scheduling algorithms UNIT III Process management and synchronization 8 Process management and synchronization: Concurrency conditions, Critical section problem, software and hardware solution, semaphores, conditional critical regions and monitors, classical inter process communication problems UNIT IV Deadlock 7 Deadlock definitions, Prevention, Avoidance, detection and Recovery, Goals of Protection, access matrix, Deadlock implementation UNIT V File systems 8 File systems: File concept, Access methods space allocation strategies, disk arm scheduling strategies. Contiguous allocation, Relocation, Paging, Segmentation, Segmentation with paging, demand paging, Virtual Memory Concepts, page faults and instruction restart, page replacement algorithms, working sets, Locality of reference, Thrashing, Garbage Collection"},{"location":"OS/#lab-manual","title":"Lab Manual","text":""},{"location":"OS/UNIT_1/","title":"Unit1","text":""},{"location":"OS/UNIT_1/#evolution-of-operating-systems","title":"Evolution of Operating Systems","text":"<p>Operating Systems have evolved in past years. It went through several changes before getting its original form. These changes in the operating system are known as the *evolution of operating systems*.OS improve itself with the invention of new technology. Basically , OS added the feature of new technology and making itself more powerful. Let us see the evolution of operating system year-wise in detail:</p>"},{"location":"OS/UNIT_1/#first-generation-1945-1955","title":"First Generation (1945-1955)","text":"<p>It is the beginning of the development of electronic computing systems which are substitutes for mechanical computing systems. Because of the drawbacks in mechanical computing systems like, the speed of humans to calculate is limited and humans can easily make mistakes. In this generation there is no operating system, so the computer system is given instructions which must be done directly.</p> <p>Example \u2212  Type of operating system  and devices used is Plug Boards.</p>"},{"location":"OS/UNIT_1/#second-generation-1955-1965","title":"Second Generation (1955-1965)","text":"<p>The  Batch processing system  was introduced in the second generation, where a job or a task that can be done in a series, and then executed sequentially. In this generation, the computer system is not equipped with an operating system, but several operating system functions exist like FMS and IBSYS.</p> <p>Example \u2212 Type of operating system and devices used is Batch systems.</p>"},{"location":"OS/UNIT_1/#third-generation-1965-1980","title":"Third Generation (1965-1980)","text":"<p>The development of the operating system was developed to serve multiple users at once in the third generation. Here the interactive users can communicate through an online terminal to a computer, so the operating system becomes multi-user and multiprogramming.</p> <p>Example \u2212 Type of operating system and devices used is Multiprogramming.</p>"},{"location":"OS/UNIT_1/#fourth-generation-1980-now","title":"Fourth Generation (1980-Now)","text":"<p>In this generation the operating system is used for computer network where users are aware of the existence of computers that are connected to one another.</p> <p>At this generation users are also comforted with a  Graphical User Interface (GUI), which is an extremely comfortable graphical computer interface, and the era of distributed computing has also begun.</p> <p>With the occurrence of new wearable devices like Smart Watches, Smart Glasses, VRGears, and others, the demand for conventional operating systems has also increased.</p> <p>And, with the onset of new devices like wearable devices, which includes Smart Watches, Smart Glasses, VR gears etc, the demand for unconventional operating systems is also rising.</p> <p>Example \u2212 Type of operating system and devices used is personal computers</p> <p> </p>"},{"location":"OS/UNIT_1/#types-of-operating-systems-os","title":"Types of Operating Systems (OS)","text":"<p>An operating system is a well-organized collection of programs that manages the computer hardware. It is a type of system software that is responsible for the smooth functioning of the computer system.</p> <p></p>"},{"location":"OS/UNIT_1/#batch-operating-system","title":"Batch Operating System","text":"<p>In the 1970s, Batch processing was very popular. In this technique, similar types of jobs were batched together and executed in time. People were used to having a single computer which was called a mainframe.</p> <p>In Batch operating system, access is given to more than one person; they submit their respective jobs to the system for the execution.</p> <p>The system put all of the jobs in a queue on the basis of first come first serve and then executes the jobs one by one. The users collect their respective output when all the jobs get executed.</p> <p></p> <p>The purpose of this operating system was mainly to transfer control from one job to another as soon as the job was completed. It contained a small set of programs called the resident monitor that always resided in one part of the main memory. The remaining part is used for servicing jobs.</p> <p></p>"},{"location":"OS/UNIT_1/#advantages-of-batch-os","title":"Advantages of Batch OS","text":"<ul> <li>The use of a resident monitor improves computer efficiency as it eliminates CPU time between two jobs.</li> </ul>"},{"location":"OS/UNIT_1/#disadvantages-of-batch-os","title":"Disadvantages of Batch OS","text":"<p>1. Starvation</p> <p>Batch processing suffers from starvation.</p> <p>For Example:</p> <p></p> <p>There are five jobs J1, J2, J3, J4, and J5, present in the batch. If the execution time of J1 is very high, then the other four jobs will never be executed, or they will have to wait for a very long time. Hence the other processes get starved.</p> <p>2. Not Interactive</p> <p>Batch Processing is not suitable for jobs that are dependent on the user's input. If a job requires the input of two numbers from the console, then it will never get it in the batch processing scenario since the user is not present at the time of execution.</p>"},{"location":"OS/UNIT_1/#multiprogramming-operating-system","title":"Multiprogramming Operating System","text":"<p>Multiprogramming is an extension to batch processing where the CPU is always kept busy. Each process needs two types of system time: CPU time and IO time.</p> <p>In a multiprogramming environment, when a process does its I/O, The CPU can start the execution of other processes. Therefore, multiprogramming improves the efficiency of the system.</p> <p></p>"},{"location":"OS/UNIT_1/#advantages-of-multiprogramming-os","title":"Advantages of Multiprogramming OS","text":"<ul> <li>Throughout the system, it increased as the CPU always had one program to execute.</li> <li>Response time can also be reduced.</li> </ul>"},{"location":"OS/UNIT_1/#disadvantages-of-multiprogramming-os","title":"Disadvantages of Multiprogramming OS","text":"<ul> <li>Multiprogramming systems provide an environment in which various systems resources are used efficiently, but they do not provide any user interaction with the computer system.</li> </ul>"},{"location":"OS/UNIT_1/#multiprocessing-operating-system","title":"Multiprocessing Operating System","text":"<p>In Multiprocessing, Parallel computing is achieved. There are more than one processors present in the system which can execute more than one process at the same time. This will increase the throughput of the system.</p> <p></p> <p>In Multiprocessing, Parallel computing is achieved. More than one processor present in the system can execute more than one process simultaneously, which will increase the throughput of the system.</p> <p></p> <p>Advantages of Multiprocessing operating system:</p> <ul> <li>Increased reliability:  Due to the multiprocessing system, processing tasks can be distributed among several processors. This increases reliability as if one processor fails, the task can be given to another processor for completion.</li> <li>Increased throughout:  As several processors increase, more work can be done in less.</li> </ul> <p>Disadvantages of Multiprocessing operating System</p> <ul> <li>Multiprocessing operating system is more complex and sophisticated as it takes care of multiple CPUs simultaneously.</li> </ul>"},{"location":"OS/UNIT_1/#multitasking-operating-system","title":"Multitasking Operating System","text":"<p>The multitasking operating system is a logical extension of a multiprogramming system that enables  multiple  programs simultaneously. It allows a user to perform more than one computer task at the same time.</p> <p></p>"},{"location":"OS/UNIT_1/#advantages-of-multitasking-operating-system","title":"Advantages of Multitasking operating system","text":"<ul> <li>This operating system is more suited to supporting multiple users simultaneously.</li> <li>The multitasking operating systems have well-defined memory management.</li> </ul>"},{"location":"OS/UNIT_1/#disadvantages-of-multitasking-operating-system","title":"Disadvantages of Multitasking operating system","text":"<ul> <li>The multiple processors are busier at the same time to complete any task in a multitasking environment, so the CPU generates more heat.</li> </ul>"},{"location":"OS/UNIT_1/#network-operating-system","title":"Network Operating System","text":"<p>An Operating system, which includes software and associated protocols to communicate with other computers via a network conveniently and cost-effectively, is called Network Operating System.</p> <p></p>"},{"location":"OS/UNIT_1/#advantages-of-network-operating-system","title":"Advantages of Network Operating System","text":"<ul> <li>In this type of operating system, network traffic reduces due to the division between clients and the server.</li> <li>This type of system is less expensive to set up and maintain.</li> </ul>"},{"location":"OS/UNIT_1/#disadvantages-of-network-operating-system","title":"Disadvantages of Network Operating System","text":"<ul> <li>In this type of operating system, the failure of any node in a system affects the whole system.</li> <li>Security and performance are important issues. So trained network administrators are required for network administration.</li> </ul>"},{"location":"OS/UNIT_1/#real-time-operating-system","title":"Real Time Operating System","text":"<p>In Real-Time Systems, each job carries a certain deadline within which the job is supposed to be completed, otherwise, the huge loss will be there, or even if the result is produced, it will be completely useless.</p> <p></p> <p>The Application of a Real-Time system exists in the case of military applications, if you want to drop a missile, then the missile is supposed to be dropped with a certain precision.</p> <p></p>"},{"location":"OS/UNIT_1/#advantages-of-real-time-operating-system","title":"Advantages of Real-time operating system:","text":"<ul> <li>Easy to layout, develop and execute real-time applications under the real-time operating system.</li> <li>In a Real-time operating system, the maximum utilization of devices and systems.</li> </ul>"},{"location":"OS/UNIT_1/#disadvantages-of-real-time-operating-system","title":"Disadvantages of Real-time operating system:","text":"<ul> <li>Real-time operating systems are very costly to develop.</li> <li>Real-time operating systems are very complex and can consume critical CPU cycles.</li> </ul>"},{"location":"OS/UNIT_1/#time-sharing-operating-system","title":"Time-Sharing Operating System","text":"<p>In the Time Sharing operating system, computer resources are allocated in a time-dependent fashion to several programs simultaneously. Thus it helps to provide a large number of user's direct access to the main computer. It is a logical extension of multiprogramming. In time-sharing, the CPU is switched among multiple programs given by different users on a scheduled basis.</p> <p></p> <p>A time-sharing operating system allows many users to be served simultaneously, so sophisticated CPU scheduling schemes and Input/output management are required.</p> <p>Time-sharing operating systems are very difficult and expensive to build.</p>"},{"location":"OS/UNIT_1/#advantages-of-time-sharing-operating-system","title":"Advantages of Time Sharing Operating System","text":"<ul> <li>The time-sharing operating system provides effective utilization and sharing of resources.</li> <li>This system reduces CPU idle and response time.</li> </ul>"},{"location":"OS/UNIT_1/#disadvantages-of-time-sharing-operating-system","title":"Disadvantages of Time Sharing Operating System","text":"<ul> <li>Data transmission rates are very high in comparison to other methods.</li> <li>Security and integrity of user programs loaded in memory and data need to be maintained as many users access the system at the same time.</li> </ul>"},{"location":"OS/UNIT_1/#distributed-operating-system","title":"Distributed Operating System","text":"<p>The Distributed Operating system is not installed on a single machine, it is divided into parts, and these parts are loaded on different machines. A part of the distributed Operating system is installed on each machine to make their communication possible. Distributed Operating systems are much more complex, large, and sophisticated than Network operating systems because they also have to take care of varying networking protocols.</p> <p></p>"},{"location":"OS/UNIT_1/#advantages-of-distributed-operating-system","title":"Advantages of Distributed Operating System","text":"<ul> <li>The distributed operating system provides sharing of resources.</li> <li>This type of system is fault-tolerant.</li> </ul>"},{"location":"OS/UNIT_1/#disadvantages-of-distributed-operating-system","title":"Disadvantages of Distributed Operating System","text":"<ul> <li>Protocol overhead can dominate computation cost.</li> </ul> <p>Modern operating systems require hardware support to perform various essential functions. The specific hardware requirements can vary depending on the type and complexity of the operating system, but here are some fundamental hardware support elements necessary for a modern operating system:</p> <ol> <li> <p>Processor (CPU): A modern operating system needs to support the processor architecture of the hardware it runs on. It should be able to manage and schedule tasks efficiently across multiple processor cores if the system has a multi-core CPU.</p> </li> <li> <p>Memory (RAM): The operating system needs to be able to manage and allocate system memory (RAM) for running applications and the OS itself. Virtual memory management is also crucial for handling memory paging and swapping.</p> </li> <li> <p>Storage Devices: Operating systems need support for various storage devices, such as hard drives (HDDs), solid-state drives (SSDs), and other storage technologies. This involves device drivers and file system support for managing data storage and retrieval.</p> </li> <li> <p>Input/Output (I/O) Devices: Support for a variety of input and output devices is essential. This includes drivers for peripherals like keyboards, mice, monitors, printers, network interfaces, and other external devices.</p> </li> <li> <p>Interrupt Handling: The operating system must be able to handle hardware interrupts generated by devices. Interrupts are signals that hardware devices send to the CPU to gain its attention.</p> </li> <li> <p>Device Drivers: Device drivers are essential software components that enable the operating system to communicate with and control hardware devices. These drivers act as intermediaries between the operating system's kernel and the hardware.</p> </li> <li> <p>Graphics Processing Unit (GPU): For systems with graphical user interfaces (GUIs), support for GPUs is necessary. This includes graphics drivers and APIs for rendering graphics and managing display output.</p> </li> <li> <p>Network Support: Modern operating systems require networking support to enable communication between devices. This involves network drivers, protocols (such as TCP/IP), and networking services.</p> </li> <li> <p>Power Management: Support for power management features, such as sleep, hibernate, and dynamic frequency scaling, is crucial for energy efficiency in laptops and other portable devices.</p> </li> <li> <p>Security Features: Hardware support for security features like hardware-level encryption, secure boot, and Trusted Platform Module (TPM) can enhance the overall security of the system.</p> </li> <li> <p>Clock and Timer Support: The operating system relies on accurate timing information for scheduling tasks and managing system events. Support for system clocks and timers is crucial.</p> </li> <li> <p>BIOS/UEFI Firmware: The operating system interacts with the system's firmware (BIOS or UEFI) during the boot process. Compatibility with the system's firmware is necessary for a successful boot and initialization.</p> </li> </ol> <p>These are general hardware requirements, and the specific details may vary based on the architecture and design of the operating system. Modern operating systems are designed to be versatile and compatible with a wide range of hardware configurations.</p>"},{"location":"OS/UNIT_1/#operating-system-services","title":"Operating System Services","text":"<p>Operating system is a software that acts as an intermediary between the user and computer hardware. It is a program with the help of which we are able to run various applications. It is the one program that is running all the time. Every computer must have an operating system to smoothly execute other programs. The OS coordinates the use of the hardware and application programs for various users. It provides a platform for other application programs to work. The operating system is a set of special programs that run on a computer system that allows it to work properly. It controls input-output devices, execution of programs, managing files, etc.</p>"},{"location":"OS/UNIT_1/#program-execution","title":"Program Execution","text":"<p>It is the Operating System that manages how a program is going to be executed. It loads the program into the memory after which it is executed. The order in which they are executed depends on the CPU Scheduling Algorithms. A few are FCFS, SJF, etc. When the program is in execution, the Operating System also handles deadlock i.e. no two processes come for execution at the same time. The Operating System is responsible for the smooth execution of both user and system programs. The Operating System utilizes various resources available for the efficient running of all types of functionalities.</p>"},{"location":"OS/UNIT_1/#input-output-operations","title":"Input Output Operations","text":"<p>Operating System manages the input-output operations and establishes communication between the user and device drivers. Device drivers are software that is associated with hardware that is being managed by the OS so that the sync between the devices works properly. It also provides access to input-output devices to a program when needed.</p>"},{"location":"OS/UNIT_1/#communication-between-processes","title":"*Communication between Processes*","text":"<p>The Operating system manages the communication between processes. Communication between processes includes data transfer among them. If the processes are not on the same computer but connected through a computer network, then also their communication is managed by the Operating System itself.</p>"},{"location":"OS/UNIT_1/#file-management","title":"File Management","text":"<p>The operating system helps in managing files also. If a program needs access to a file, it is the operating system that grants access. These permissions include read-only, read-write, etc. It also provides a platform for the user to create, and delete files. The Operating System is responsible for making decisions regarding the storage of all types of data or files, i.e, floppy disk/hard disk/pen drive, etc. The Operating System decides how the data should be manipulated and stored.</p>"},{"location":"OS/UNIT_1/#memory-management","title":"Memory Management","text":"<p>Let\u2019s understand memory management by OS in simple way. Imagine a cricket team with limited number of player . The team manager (OS) decide whether the upcoming player will be in playing 11 ,playing 15 or will not be included in team , based on his performance . In the same way, OS first check whether the upcoming program fulfil all requirement to get memory space or not ,if all things good, it checks how much memory space will be sufficient for program and then load the program into memory at certain location. And thus , it prevents program from using unnecessary memory.</p>"},{"location":"OS/UNIT_1/#process-management","title":"Process Management","text":"<p>Let\u2019s understand the process management in unique way. Imagine, our kitchen stove as the (CPU) where all cooking(execution) is really happen and chef as the (OS) who uses kitchen-stove(CPU) to cook different dishes(program). The chef(OS) has to cook different dishes(programs) so he ensure that any particular dish(program) does not take long time(unnecessary time) and all dishes(programs) gets a chance to cooked(execution) .The chef(OS) basically scheduled time for all dishes(programs) to run kitchen(all the system) smoothly and thus cooked(execute) all the different dishes(programs) efficiently.</p>"},{"location":"OS/UNIT_1/#secuirity-and-privacy","title":"Secuirity and Privacy","text":"<ul> <li> <p>*Secuirity :* OS keep our computer safe from an unauthorised user by adding secuirity layer to it.Basically, Secuirity is nothing but just a layer of protection which protect computer from bad guys like viruses and hackers. OS provide us defenses like firewalls and anti-virus software and ensure good safety of computer and personal information.</p> </li> <li> <p>*Privacy :* OS give us facility to keep our essential information hidden like having a lock on our door, where only you can enter and other are not allowed . Basically , it respect our secrets and provide us facility to keep it safe.</p> </li> </ul>"},{"location":"OS/UNIT_1/#resource-management","title":"Resource Management","text":"<p>System resources are shared between various processes. It is the Operating system that manages resource sharing. It also manages the CPU time among processes using CPU Scheduling Algorithms. It also helps in the memory management of the system. It also controls input-output devices. The OS also ensures the proper use of all the resources available by deciding which resource to be used by whom.</p>"},{"location":"OS/UNIT_1/#user-interface","title":"User Interface","text":"<p>User interface is essential and all operating systems provide it. Users either interface with the operating system through the command-line interface or graphical user interface or GUI. The command interpreter executes the next user-specified command.</p> <p>A GUI offers the user a mouse-based window and menu system as an interface.</p>"},{"location":"OS/UNIT_1/#networking","title":"Networking","text":"<p>This service enables communication between devices on a network, such as connecting to the internet, sending and receiving data packets, and managing network connections.</p>"},{"location":"OS/UNIT_1/#error-handling","title":"Error Handling","text":"<p>The Operating System also handles the error occurring in the CPU, in Input-Output devices, etc. It also ensures that an error does not occur frequently and fixes the errors. It also prevents the process from coming to a deadlock. It also looks for any type of error or bugs that can occur while any task. The well-secured OS sometimes also acts as a countermeasure for preventing any sort of breach of the Computer System from any external source and probably handling them.</p>"},{"location":"OS/UNIT_1/#time-management","title":"Time Management","text":"<p>Imagine traffic light as (OS), which indicates all the cars(programs) whether it should be stop(red)=&gt;(simple queue) , start(yellow)=&gt;(ready queue),move(green)=&gt;(under execution) and this light (control) changes after a certain interval of time at each side of the road(computer system) so that the cars(program) from all side of road move smoothly without traffic.</p>"},{"location":"OS/UNIT_1/#what-is-a-system-program","title":"What is a system program?","text":"<p>In an operating system a user is able to use different types of system programs and the system program is responsible for all the application software performance of the computer.</p> <p>The system programs are responsible for the development and execution of a program and they can be used by the help of system calls because system calls define different types of system programs for different tasks.</p> <ul> <li> <p>File management  \u2212 These programs create, delete, copy, rename, print, exit and generally manipulate the files and directory.</p> </li> <li> <p>Status information  \u2212 It is the information regarding input, output process, storage and the CPU utilization time how the process will be calculated in how much memory required to perform a task is known by status information.</p> </li> <li> <p>Programming language supports  \u2212 compiler, assembler, interrupt are programming language support used in the operating system for a particular purpose in the computer.</p> </li> <li> <p>Programming Loading and execution  \u2212 The needs to enter the program and after the loading of a program it needs to execute the output of the programs and this task is also performed by system calls by the help of system programs.</p> </li> <li> <p>Communication  \u2212 These services are provided by the user because by using this number of devices communicates with each other by the help of device or wireless and communication is necessary for the operating system.</p> </li> <li> <p>Background services  \u2212 There are different types of services available on the operating system for communication and background service is used to change the background of your window and it also works for scanning and detecting viruses in the computer.</p> </li> </ul>"},{"location":"OS/UNIT_1/#purpose-of-using-system-program","title":"Purpose of using system program","text":"<p>System programs communicate and coordinate the activities and functions of hardware and software of a system and also controls the operations of the hardware. An operating system is one of the examples of system software. Operating system controls the computer hardware and acts like an interface between the application software\u2019s.</p>"},{"location":"OS/UNIT_1/#introduction-of-system-call","title":"Introduction of System Call","text":"<p>In computing, a *system call is a programmatic way in which a computer program requests a service from the kernel of the operating system it is executed on. A system call is a way for programs to interact with the operating system. A computer program makes a system call when it makes a request to the operating system\u2019s kernel. System call provides* the services of the operating system to the user programs via Application Program Interface(API). It provides an interface between a process and an operating system to allow user-level processes to request services of the operating system. System calls are the only entry points into the kernel system. All programs needing resources must use system calls.</p> <p>A user program can interact with the operating system using a system call. A number of services are requested by the program, and the OS responds by launching a number of systems calls to fulfill the request. A system call can be written in high-level languages like C or Pascal or in assembly language. If a high-level language is used, the operating system may directly invoke system calls, which are predefined functions.</p> <p>A system call is a mechanism used by programs to request services from the operating system (OS). In simpler terms, it is a way for a program to interact with the underlying system, such as accessing hardware resources or performing privileged operations.</p> <p>A system call is initiated by the program executing a specific instruction, which triggers a switch to kernel mode, allowing the program to request a service from the OS. The OS then handles the request, performs the necessary operations, and returns the result back to the program.</p> <p>System calls are essential for the proper functioning of an operating system, as they provide a standardized way for programs to access system resources. Without system calls, each program would need to implement its own methods for accessing hardware and system services, leading to inconsistent and error-prone behavior.</p>"},{"location":"OS/UNIT_1/#services-provided-by-system-calls","title":"*Services Provided by System Calls*","text":"<ul> <li>Process creation and management</li> <li>Main memory management</li> <li>File Access, Directory, and File system management</li> <li>Device handling(I/O)</li> <li>Protection</li> <li>Networking, etc.<ul> <li>*Process control:* end, abort, create, terminate, allocate, and free memory.</li> <li>*File management:* create, open, close, delete, read files,s, etc.</li> <li>*Device management*</li> <li>*Information maintenance*</li> <li>*Communication*</li> </ul> </li> </ul>"},{"location":"OS/UNIT_1/#features-of-system-calls","title":"Features of System Calls","text":"<ul> <li>*Interface:* System calls provide a well-defined interface between user programs and the operating system. Programs make requests by calling specific functions, and the operating system responds by executing the requested service and returning a result.</li> <li>*Protection:* System calls are used to access privileged operations that are not available to normal user programs. The operating system uses this privilege to protect the system from malicious or unauthorized access.</li> <li>*Kernel Mode:* When a system call is made, the program is temporarily switched from user mode to kernel mode. In kernel mode, the program has access to all system resources, including hardware, memory, and other processes.</li> <li>*Context Switching:* A system call requires a context switch, which involves saving the state of the current process and switching to the kernel mode to execute the requested service. This can introduce overhead, which can impact system performance.</li> <li>*Error Handling:* System calls can return error codes to indicate problems with the requested service. Programs must check for these errors and handle them appropriately.</li> <li>*Synchronization:* System calls can be used to synchronize access to shared resources, such as files or network connections. The operating system provides synchronization mechanisms, such as locks or semaphores, to ensure that multiple programs can access these resources safely.</li> </ul>"},{"location":"OS/UNIT_1/#design-approaches-in-operating-system","title":"Design approaches in Operating System","text":"<p>The operating system may be implemented with the assistance of several structures. The structure of the operating system is mostly determined by how the many common components of the OS are integrated and merged into the kernel. In this article, you will learn the following structure of the OS. Various structures are used in the design of the operating system. These structures are as follows:</p> <ol> <li>Simple Structure</li> <li>Micro-Kernel Structure</li> <li>Layered Structure</li> </ol>"},{"location":"OS/UNIT_1/#simple-structure","title":"Simple Structure","text":"<p>Such OS's are small, simple, and limited, with no well-defined structure. There is a lack of separation between the interfaces and levels of functionality. The MS-DOS is the best example of such an operating system. Application programs in MS-DOS can access basic I/O functions. If one of the user programs fails on these OSs, the complete system crashes. Below is the diagram of the MS-DOS structure that may help you understand the simple structure.</p> <p></p>"},{"location":"OS/UNIT_1/#advantages-and-disadvantages-of-simple-structure","title":"Advantages and Disadvantages of Simple Structure","text":"<p>There are various advantages and disadvantages of the Simple Structure. Some advantages and disadvantages of the Simple Structure are as follows:</p> <p>Advantages</p> <ol> <li>It provides superior application performance due to the limited interfaces between the application program and the hardware.</li> <li>It is simple for kernel developers to create such an operating system.</li> </ol> <p>Disadvantages</p> <ol> <li>The structure is quite complex because there are no apparent boundaries between modules.</li> <li>It does not impose data concealment in the operating system.</li> </ol>"},{"location":"OS/UNIT_1/#micro-kernel-structure","title":"Micro-Kernel Structure","text":"<p>This micro-kernel structure creates the OS by eliminating all non-essential kernel components and implementing them as user programs and systems. Therefore, a smaller kernel is known as a micro-kernel.</p> <p>The benefits of this micro-kernel structure are that all new services must be added to userspace rather than the kernel, and the kernel does not require to be updated. Therefore, it is more secure and trustworthy. If a service fails, the remainder of the OS is unaffected. Mac OS is the best instance of this type of operating system.</p>"},{"location":"OS/UNIT_1/#advantages-and-disadvantages-of-micro-kernel-structure","title":"Advantages and Disadvantages of Micro-Kernel Structure","text":"<p>There are various advantages and disadvantages of the Micro-Kernel Structure. Some advantages and disadvantages of the Micro-Kernel Structure are as follows:</p> <p>Advantages</p> <ol> <li>It allows the OS to be portable across platforms.</li> <li>They can be effectively tested because the microkernels are small.</li> </ol> <p>Disadvantages</p> <ol> <li>The performance of the system suffers as the level of inter-module communication rises.</li> </ol>"},{"location":"OS/UNIT_1/#layered-structure","title":"Layered Structure","text":"<p>An operating system can be divided into sections while retaining far more control over the system. The OS is divided into layers in this arrangement (levels). The hardware is on the  bottom layer (layer 0), and the user interface is on the  top layer (layer N). These layers are designed in such a way that each layer only requires the functions of the lower-level layers. Debugging is simplified because if lower-level layers are debugged, and an error occurs during debugging, the error must occur only on that layer. The lower-level layers have been thoroughly tested.</p> <p></p> <p>UNIX is the best example of the Layered Structure. The main disadvantage of this structure is that data must be updated and sent on to each layer, which adds overhead to the system. Furthermore, careful planning of the layers is required because a layer may use only lower-level layers.</p>"},{"location":"OS/UNIT_1/#advantages-and-disadvantages-of-layered-structure","title":"Advantages and Disadvantages of Layered Structure","text":"<p>There are various advantages and disadvantages of the Layered Structure. Some advantages and disadvantages of the Layered Structure are as follows:</p> <p>Advantages</p> <ol> <li>Layering makes it easier to improve the OS as the implementation of a layer may be changed easily without affecting the other layers.</li> <li>Debugging and system verification are simple to carry out.</li> </ol> <p>Disadvantages</p> <ol> <li>When compared to a simple structure, this structure degrades application performance.</li> <li>It needs better planning to construct the layers because higher layers only utilize the functionalities of lower layers.</li> </ol>"},{"location":"OS/UNIT_1/#modular-structure-or-approach","title":"Modular structure or approach","text":"<p>It is regarded as the best approach for an operating system. It involves designing a modular kernel. It is comparable to a layered structure in that each kernel has specified and protected interfaces, but it is more flexible because a module may call any other module. The kernel contains only a limited number of basic components, and extra services are added to the kernel as dynamically loadable modules either during runtime or at boot time.</p>"},{"location":"OS/UNIT_1/#references","title":"References","text":"<p>https://www.javatpoint.com/types-of-operating-systems https://www.geeksforgeeks.org/evolution-of-operating-system/ https://www.tutorialspoint.com/what-is-the-operating-system-evolution https://www.geeksforgeeks.org/operating-system-services/ https://www.tutorialspoint.com/what-is-a-system-program https://www.geeksforgeeks.org/introduction-of-system-call/ https://www.javatpoint.com/design-approaches-in-operating-system</p>"},{"location":"OS/UNIT_2/","title":"Unit2","text":""},{"location":"OS/UNIT_2/#definition-of-process","title":"Definition of Process","text":"<p>Basically, a process is a simple program.</p> <p>An active program which running now on the Operating System is known as the process. The Process is the base of all computing things. Although process is relatively similar to the computer code but, the method is not the same as computer code. A process is a \"active\" entity, in contrast to the program, which is sometimes thought of as some sort of \"passive\" entity. The properties that the process holds include the state of the hardware, the RAM, the CPU, and other attributes.</p>"},{"location":"OS/UNIT_2/#process-in-an-operating-system","title":"Process in an Operating System","text":"<p>A process is actively running software or a computer code. Any procedure must be carried out in a precise order. An entity that helps in describing the fundamental work unit that must be implemented in any system is referred to as a process.</p> <p>In other words, we create computer programs as text files that, when executed, create processes that carry out all of the tasks listed in the program.</p> <p>When a program is loaded into memory, it may be divided into the four components stack, heap, text, and data to form a process. The simplified depiction of a process in the main memory is shown in the diagram below.</p> <p></p>"},{"location":"OS/UNIT_2/#stack","title":"Stack","text":"<p>The process stack stores temporary information such as method or function arguments, the return address, and local variables.</p> <p>Heap</p> <p>This is the memory where a process is dynamically allotted while it is running.</p> <p>Text</p> <p>This consists of the information stored in the processor's registers as well as the most recent activity indicated by the program counter's value.</p> <p>Data</p> <p>In this section, both global and static variables are discussed.</p>"},{"location":"OS/UNIT_2/#process-table-and-process-control-block-pcb","title":"Process Table and Process Control Block (PCB)","text":"<p>While creating a process, the operating system performs several operations. To identify the processes, it assigns a process identification number (PID) to each process. As the operating system supports multi-programming, it needs to keep track of all the processes. For this task, the process control block (PCB) is used to track the process\u2019s execution status. Each block of memory contains information about the process state, program counter, stack pointer, status of opened files, scheduling algorithms, etc.</p> <p>All this information is required and must be saved when the process is switched from one state to another. When the process makes a transition from one state to another, the operating system must update information in the process\u2019s PCB. A process control block (PCB) contains information about the process, i.e. registers, quantum, priority, etc. The process table is an array of PCBs, that means logically contains a PCB for all of the current processes in the system.</p> <p></p> <ol> <li>*Pointer:* It is a stack pointer that is required to be saved when the process is switched from one state to another to retain the current position of the process.</li> <li>*Process state:* It stores the respective state of the process.</li> <li>*Process number:* Every process is assigned a unique id known as process ID or PID which stores the process identifier.</li> <li>*Program counter: It stores the counter,:* which contains the address of the next instruction that is to be executed for the process.</li> <li>*Register:* These are the CPU register which include the accumulator, base, registers, and general-purpose registers.</li> <li>*Memory limits:* This field contains the information about memory management system used by the operating system. This may include page tables, segment tables, etc.</li> <li>*Open files list :* This information includes the list of files opened for a process.</li> </ol>"},{"location":"OS/UNIT_2/#additional-points-to-consider-for-process-control-block-pcb","title":"*Additional Points to Consider for Process Control Block (PCB)*","text":"<ul> <li>*Interrupt handling:* The PCB also contains information about the interrupts that a process may have generated and how they were handled by the operating system.</li> <li>*Context switching:* The process of switching from one process to another is called context switching. The PCB plays a crucial role in context switching by saving the state of the current process and restoring the state of the next process.</li> <li>*Real-time systems:* Real-time operating systems may require additional information in the PCB, such as deadlines and priorities, to ensure that time-critical processes are executed in a timely manner.</li> <li>*Virtual memory management:* The PCB may contain information about a process\u2019s virtual memory management, such as page tables and page fault handling.</li> <li>*Inter-process communication:* The PCB can be used to facilitate inter-process communication by storing information about shared resources and communication channels between processes.</li> <li>*Fault tolerance:* Some operating systems may use multiple copies of the PCB to provide fault tolerance in case of hardware failures or software errors.</li> </ul>"},{"location":"OS/UNIT_2/#advantages-","title":"Advantages-","text":"<ol> <li>*Efficient process management:* The process table and PCB provide an efficient way to manage processes in an operating system. The process table contains all the information about each process, while the PCB contains the current state of the process, such as the program counter and CPU registers.</li> <li>*Resource management:* The process table and PCB allow the operating system to manage system resources, such as memory and CPU time, efficiently. By keeping track of each process\u2019s resource usage, the operating system can ensure that all processes have access to the resources they need.</li> <li>*Process synchronization:* The process table and PCB can be used to synchronize processes in an operating system. The PCB contains information about each process\u2019s synchronization state, such as its waiting status and the resources it is waiting for.</li> <li>*Process scheduling:* The process table and PCB can be used to schedule processes for execution. By keeping track of each process\u2019s state and resource usage, the operating system can determine which processes should be executed next.</li> </ol>"},{"location":"OS/UNIT_2/#disadvantages-","title":"Disadvantages-","text":"<ol> <li>*Overhead:* The process table and PCB can introduce overhead and reduce system performance. The operating system must maintain the process table and PCB for each process, which can consume system resources.</li> <li>*Complexity:* The process table and PCB can increase system complexity and make it more challenging to develop and maintain operating systems. The need to manage and synchronize multiple processes can make it more difficult to design and implement system features and ensure system stability.</li> <li>*Scalability:* The process table and PCB may not scale well for large-scale systems with many processes. As the number of processes increases, the process table and PCB can become larger and more difficult to manage efficiently.</li> <li>*Security:* The process table and PCB can introduce security risks if they are not implemented correctly. Malicious programs can potentially access or modify the process table and PCB to gain unauthorized access to system resources or cause system instability.</li> <li>*Miscellaneous accounting and status data \u2013* This field includes information about the amount of CPU used, time constraints, jobs or process number, etc. The process control block stores the register content also known as execution content of the processor when it was blocked from running. This execution content architecture enables the operating system to restore a process\u2019s execution context when the process returns to the running state. When the process makes a transition from one state to another, the operating system updates its information in the process\u2019s PCB. The operating system maintains pointers to each process\u2019s PCB in a process table so that it can access the PCB quickly.</li> </ol>"},{"location":"OS/UNIT_2/#different-types-of-process-schedulers","title":"Different Types of Process Schedulers","text":"<p>Process Scheduling handles the selection of a process for the processor on the basis of a scheduling algorithm and also the removal of a process from the processor. It is an important part of multiprogramming operating system.</p> <p>There are many scheduling queues that are used in process scheduling. When the processes enter the system, they are put into the job queue. The processes that are ready to execute in the main memory are kept in the ready queue. The processes that are waiting for the I/O device are kept in the I/O device queue.</p> <p>The different schedulers that are used for process scheduling are \u2212</p>"},{"location":"OS/UNIT_2/#long-term-scheduler","title":"Long Term Scheduler","text":"<p>The job scheduler or long-term scheduler selects processes from the storage pool in the secondary memory and loads them into the ready queue in the main memory for execution.</p> <p>The long-term scheduler controls the degree of multiprogramming. It must select a careful mixture of I/O bound and CPU bound processes to yield optimum system throughput. If it selects too many CPU bound processes then the I/O devices are idle and if it selects too many I/O bound processes then the processor has nothing to do.</p> <p>The job of the long-term scheduler is very important and directly affects the system for a long time.</p>"},{"location":"OS/UNIT_2/#short-term-scheduler","title":"Short Term Scheduler","text":"<p>The short-term scheduler selects one of the processes from the ready queue and schedules them for execution. A scheduling algorithm is used to decide which process will be scheduled for execution next.</p> <p>The short-term scheduler executes much more frequently than the long-term scheduler as a process may execute only for a few milliseconds.</p> <p>The choices of the short term scheduler are very important. If it selects a process with a long burst time, then all the processes after that will have to wait for a long time in the ready queue. This is known as starvation and it may happen if a wrong decision is made by the short-term scheduler.</p> <p>A diagram that demonstrates long-term and short-term schedulers is given as follows \u2212</p>"},{"location":"OS/UNIT_2/#medium-term-scheduler","title":"Medium Term Scheduler","text":"<p>The medium-term scheduler swaps out a process from main memory. It can again swap in the process later from the point it stopped executing. This can also be called as suspending and resuming the process.</p> <p>This is helpful in reducing the degree of multiprogramming. Swapping is also useful to improve the mix of I/O bound and CPU bound processes in the memory.</p> <p>A diagram that demonstrates medium-term scheduling is given as follows \u2212</p> <p></p>"},{"location":"OS/UNIT_2/#context-switching-in-os-operating-system","title":"Context Switching in OS (Operating System)","text":"<p>The Context switching is a technique or method used by the operating system to switch a process from one state to another to execute its function using CPUs in the system. When switching perform in the system, it stores the old running process's status in the form of registers and assigns the  CPU  to a new process to execute its tasks. While a new process is running in the system, the previous process must wait in a ready queue. The execution of the old process starts at that point where another process stopped it. It defines the characteristics of a multitasking operating system in which multiple processes shared the same  CPU  to perform multiple tasks without the need for additional processors in the system.</p>"},{"location":"OS/UNIT_2/#the-need-for-context-switching","title":"The need for Context switching","text":"<p>A context switching helps to share a single CPU across all processes to complete its execution and store the system's tasks status. When the process reloads in the system, the execution of the process starts at the same point where there is conflicting.</p> <p>Following are the reasons that describe the need for context switching in the Operating system.</p> <ol> <li>The switching of one process to another process is not directly in the system. A context switching helps the operating system that switches between the multiple processes to use the CPU's resource to accomplish its tasks and store its context. We can resume the service of the process at the same point later. If we do not store the currently running process's data or context, the stored data may be lost while switching between processes.</li> <li>If a high priority process falls into the ready queue, the currently running process will be shut down or stopped by a high priority process to complete its tasks in the system.</li> <li>If any running process requires I/O resources in the system, the current process will be switched by another process to use the CPUs. And when the I/O requirement is met, the old process goes into a ready state to wait for its execution in the CPU. Context switching stores the state of the process to resume its tasks in an operating system. Otherwise, the process needs to restart its execution from the initials level.</li> <li>If any interrupts occur while running a process in the operating system, the process status is saved as registers using context switching. After resolving the interrupts, the process switches from a wait state to a ready state to resume its execution at the same point later, where the operating system interrupted occurs.</li> <li>A context switching allows a single CPU to handle multiple process requests simultaneously without the need for any additional processors.</li> </ol>"},{"location":"OS/UNIT_2/#steps-for-context-switching","title":"Steps for Context Switching","text":"<p>There are several steps involves in context switching of the processes. The following diagram represents the context switching of two processes, P1 to P2, when an interrupt, I/O needs, or priority-based process occurs in the ready queue of PCB.</p> <p></p> <p>As we can see in the diagram, initially, the P1 process is running on the CPU to execute its task, and at the same time, another process, P2, is in the ready state. If an error or interruption has occurred or the process requires input/output, the P1 process switches its state from running to the waiting state. Before changing the state of the process P1, context switching saves the context of the process P1 in the form of registers and the program counter to the  PCB1. After that, it loads the state of the P2 process from the ready state of the  PCB2  to the running state.</p> <p>The following steps are taken when switching Process P1 to Process 2:</p> <ol> <li>First, thes context switching needs to save the state of process P1 in the form of the program counter and the registers to the PCB (Program Counter Block), which is in the running state.</li> <li>Now update PCB1 to process P1 and moves the process to the appropriate queue, such as the ready queue, I/O queue and waiting queue.</li> <li>After that, another process gets into the running state, or we can select a new process from the ready state, which is to be executed, or the process has a high priority to execute its task.</li> <li>Now, we have to update the PCB (Process Control Block) for the selected process P2. It includes switching the process state from ready to running state or from another state like blocked, exit, or suspend.</li> <li>If the CPU already executes process P2, we need to get the status of process P2 to resume its execution at the same time point where the system interrupt occurs.</li> </ol> <p>Similarly, process P2 is switched off from the CPU so that the process P1 can resume execution. P1 process is reloaded from PCB1 to the running state to resume its task at the same point. Otherwise, the information is lost, and when the process is executed again, it starts execution at the initial level.</p>"},{"location":"OS/UNIT_2/#thread-in-operating-system","title":"Thread in Operating System","text":"<p>Within a program, a *Thread* is a separate execution path. It is a lightweight process that the operating system can schedule and run concurrently with other threads. The operating system creates and manages threads, and they share the same memory and resources as the program that created them. This enables multiple threads to collaborate and work efficiently within a single program.</p> <p>A thread is a single sequence stream within a process. Threads are also called lightweight processes as they possess some of the properties of processes. Each thread belongs to exactly one process. In an operating system that supports multithreading, the process can consist of many threads. But threads can be effective only if CPU is more than 1 otherwise two threads have to context switch for that single CPU.</p>"},{"location":"OS/UNIT_2/#why-do-we-need-thread","title":"Why Do We Need Thread?","text":"<ul> <li>Threads run in parallel improving the application performance. Each such thread has its own CPU state and stack, but they share the address space of the process and the environment.</li> <li>Threads can share common data so they do not need to use interprocess communication. Like the processes, threads also have states like ready, executing, blocked, etc.</li> <li>Priority can be assigned to the threads just like the process, and the highest priority thread is scheduled first.</li> <li>Each thread has its own Thread Control Block (TCB). Like the process, a context switch occurs for the thread, and register contents are saved in (TCB). As threads share the same address space and resources, synchronization is also required for the various activities of the thread.</li> </ul>"},{"location":"OS/UNIT_2/#multi-threading-models","title":"Multi-Threading Models","text":"<p>Multithreading allows the execution of multiple parts of a program at the same time. These parts are known as threads and are lightweight processes available within the process. Therefore, multithreading leads to maximum utilization of the CPU by multitasking.</p> <p>The main models for multithreading are one to one model, many to one model and many to many model. Details about these are given as follows \u2212</p>"},{"location":"OS/UNIT_2/#one-to-one-model","title":"One to One Model","text":"<p>The one to one model maps each of the user threads to a kernel thread. This means that many threads can run in parallel on multiprocessors and other threads can run when one thread makes a blocking system call.</p> <p>A disadvantage of the one to one model is that the creation of a user thread requires a corresponding kernel thread. Since a lot of kernel threads burden the system, there is restriction on the number of threads in the system.</p> <p>A diagram that demonstrates the one to one model is given as follows \u2212</p> <p></p>"},{"location":"OS/UNIT_2/#many-to-one-model","title":"Many to One Model","text":"<p>The many to one model maps many of the user threads to a single kernel thread. This model is quite efficient as the user space manages the thread management.</p> <p>A disadvantage of the many to one model is that a thread blocking system call blocks the entire process. Also, multiple threads cannot run in parallel as only one thread can access the kernel at a time.</p> <p>A diagram that demonstrates the many to one model is given as follows \u2212</p> <p></p>"},{"location":"OS/UNIT_2/#many-to-many-model","title":"Many to Many Model","text":"<p>The many to many model maps many of the user threads to a equal number or lesser kernel threads. The number of kernel threads depends on the application or machine.</p> <p>The many to many does not have the disadvantages of the one to one model or the many to one model. There can be as many user threads as required and their corresponding kernel threads can run in parallel on a multiprocessor.</p> <p>A diagram that demonstrates the many to many model is given as follows \u2212</p> <p></p>"},{"location":"OS/UNIT_2/#goals-of-scheduling","title":"Goals of scheduling","text":"<p>The scheduling of processes in an operating system is a critical function that aims to achieve several goals to ensure efficient and effective utilization of system resources. The primary goals of scheduling in an operating system include:</p> <ol> <li>Maximizing CPU Utilization:</li> <li>The primary goal is to keep the CPU as busy as possible to ensure high system throughput.</li> <li> <p>Idle CPU time represents wasted resources, and efficient scheduling aims to minimize the idle time.</p> </li> <li> <p>Fairness:</p> </li> <li>Scheduling should be fair to all processes, ensuring that no process is unfairly starved of CPU time.</li> <li> <p>Fairness is essential to prevent certain processes from monopolizing system resources.</p> </li> <li> <p>Minimizing Turnaround Time:</p> </li> <li>Turnaround time is the total time taken to execute a process, including waiting time and execution time.</li> <li> <p>Scheduling algorithms aim to minimize turnaround time to improve the overall system performance.</p> </li> <li> <p>Minimizing Waiting Time:</p> </li> <li>Waiting time is the time a process spends waiting in the ready queue before it gets CPU time.</li> <li> <p>Scheduling algorithms strive to minimize waiting time to enhance system responsiveness.</p> </li> <li> <p>Minimizing Response Time:</p> </li> <li>Response time is the time it takes for the system to respond to a user request or an event.</li> <li> <p>Scheduling algorithms target minimizing response time to provide a more interactive and responsive user experience.</p> </li> <li> <p>Maximizing Throughput:</p> </li> <li>Throughput is a measure of the number of processes that can be completed in a unit of time.</li> <li> <p>Scheduling aims to maximize throughput to ensure efficient use of system resources.</p> </li> <li> <p>Ensuring Deadlines and Priorities:</p> </li> <li> <p>In real-time systems, meeting deadlines is crucial. Scheduling must consider task priorities and deadlines to ensure timely execution of critical tasks.</p> </li> <li> <p>Balancing Resource Utilization:</p> </li> <li> <p>Scheduling should aim to balance the utilization of various system resources, such as CPU, memory, and I/O devices, to prevent bottlenecks.</p> </li> <li> <p>Adaptability and Responsiveness:</p> </li> <li>Scheduling algorithms should be adaptive to varying workloads and responsive to changes in the system environment.</li> <li> <p>Dynamic scheduling strategies adjust to workload changes to optimize system performance.</p> </li> <li> <p>Energy Efficiency:</p> <ul> <li>In mobile and battery-powered devices, scheduling algorithms may aim to minimize energy consumption by efficiently managing power states and transitions.</li> </ul> </li> <li> <p>Minimizing Starvation:</p> <ul> <li>Starvation occurs when a process is unable to get CPU time for an extended period. Scheduling aims to prevent starvation and ensure all processes get a fair share of resources.</li> </ul> </li> <li> <p>Load Balancing:</p> <ul> <li>Load balancing involves distributing processes evenly across multiple processors or cores to prevent overloading some resources while leaving others underutilized.</li> </ul> </li> </ol> <p>By achieving these goals, the scheduling component of an operating system plays a crucial role in optimizing the overall system performance and ensuring a responsive and efficient computing environment. Different scheduling algorithms may be employed based on the specific requirements and characteristics of the system.</p>"},{"location":"OS/UNIT_2/#scheduling-algorithms-in-os-operating-system","title":"Scheduling Algorithms in OS (Operating System)","text":"<p>There are various algorithms which are used by the Operating System to schedule the processes on the processor in an efficient way.</p>"},{"location":"OS/UNIT_2/#the-purpose-of-a-scheduling-algorithm","title":"The Purpose of a Scheduling algorithm","text":"<ol> <li>Maximum CPU utilization</li> <li>Fare allocation of CPU</li> <li>Maximum throughput</li> <li>Minimum turnaround time</li> <li>Minimum waiting time</li> <li>Minimum response time</li> </ol> <p>There are the following algorithms which can be used to schedule the jobs.</p>"},{"location":"OS/UNIT_2/#1-first-come-first-serve","title":"1. First Come First Serve","text":"<p>It is the simplest algorithm to implement. The process with the minimal arrival time will get the CPU first. The lesser the arrival time, the sooner will the process gets the CPU. It is the non-preemptive type of scheduling.</p>"},{"location":"OS/UNIT_2/#2-round-robin","title":"2. Round Robin","text":"<p>In the Round Robin scheduling algorithm, the OS defines a time quantum (slice). All the processes will get executed in the cyclic way. Each of the process will get the CPU for a small amount of time (called time quantum) and then get back to the ready queue to wait for its next turn. It is a preemptive type of scheduling.</p>"},{"location":"OS/UNIT_2/#3-shortest-job-first","title":"3. Shortest Job First","text":"<p>The job with the shortest burst time will get the CPU first. The lesser the burst time, the sooner will the process get the CPU. It is the non-preemptive type of scheduling.</p>"},{"location":"OS/UNIT_2/#4-shortest-remaining-time-first","title":"4. Shortest remaining time first","text":"<p>It is the preemptive form of SJF. In this algorithm, the OS schedules the Job according to the remaining time of the execution.</p>"},{"location":"OS/UNIT_2/#5-priority-based-scheduling","title":"5. Priority based scheduling","text":"<p>In this algorithm, the priority will be assigned to each of the processes. The higher the priority, the sooner will the process get the CPU. If the priority of the two processes is same then they will be scheduled according to their arrival time.</p>"},{"location":"OS/UNIT_2/#6-highest-response-ratio-next","title":"6. Highest Response Ratio Next","text":"<p>In this scheduling Algorithm, the process with highest response ratio will be scheduled next. This reduces the starvation in the system.</p>"},{"location":"OS/UNIT_2/#references","title":"References","text":"<p>https://www.javatpoint.com/what-is-the-process-in-operating-system https://www.geeksforgeeks.org/process-table-and-process-control-block-pcb/ https://www.tutorialspoint.com/different-types-of-process-schedulers https://www.javatpoint.com/what-is-the-context-switching-in-the-operating-system https://www.geeksforgeeks.org/thread-in-operating-system/ https://www.tutorialspoint.com/multi-threading-models https://www.javatpoint.com/os-scheduling-algorithms</p>"},{"location":"OS/UNIT_3/","title":"COMING SOON!","text":""},{"location":"OS/UNIT_4/","title":"COMING SOON!","text":""},{"location":"OS/UNIT_5/","title":"COMING SOON!","text":""},{"location":"OS/cae1/","title":"Question bank","text":""},{"location":"OS/cae1/#1-explain-operating-system-history","title":"1. Explain Operating System History?","text":"<p>Operating systems have a rich history that dates back to the earliest days of computing. Here's a brief overview:</p> <p>Early Computers (1940s-1950s): - The first electronic computers, such as the ENIAC and UNIVAC, were huge machines designed for specific tasks like calculations and data processing. - These early computers didn't have operating systems in the modern sense. Programs were written directly in machine code and executed one at a time.</p> <p>Batch Processing Systems (1950s-1960s): - As computers became more widespread, the need for more efficient use of resources arose. - Batch processing systems were developed to queue up tasks (or jobs) and execute them in batches. - Operating systems like the IBM OS/360 were created to manage this process, handling tasks such as job scheduling, memory management, and I/O operations.</p> <p>Time-Sharing Systems (1960s-1970s): - Time-sharing systems allowed multiple users to interact with a computer simultaneously. - This era saw the development of operating systems like MULTICS and later Unix, which introduced features like virtual memory, file systems, and a hierarchical directory structure.</p> <p>Personal Computers (1980s-Present): - The advent of personal computers led to the development of operating systems like MS-DOS, Mac OS, and eventually Windows and Linux. - Graphical user interfaces (GUIs) became standard, making computers more accessible to non-technical users. - Today, operating systems continue to evolve with advancements in technology, including mobile operating systems like Android and iOS, as well as cloud-based operating systems for distributed computing.</p>"},{"location":"OS/cae1/#2-draw-operating-system-component-diagram-and-explain-in-details","title":"2. Draw operating system component diagram and explain in details?","text":"<p>Component Diagrams  are used to show code modules of a system in  Unified Modeling Language (UML). They are generally used for modeling subsystems. It represents how each and every component acts during execution and running of a system program. They are also used to show and represent structure and organization of all components. These code modules include application program, ActiveX control, Java Beans, backend databases, or some ASP programs. The component diagrams represent implementation of view models. The component diagrams are for representing interfaces and dependencies among software architecture. The word component simply means modules of a class that usually represents an independent subsystem. These components have ability to interface with rest of system. The component diagram is used to explain working and behavior of various components of a system and is static diagrams of UML. They are also used for subsystem modeling. The main purpose of component diagram is simply to show relationship among various components of a system.</p> <p>The component and interface are as shown below :Example \u2013  Following is a component diagram for the \u2018On-line Course Registration\u2019 system. This diagram shows conceptual view of server-side components.Advantages :</p> <ul> <li>Component diagrams are very simple, standardized, and very easy to understand.</li> <li>It is also useful in representing implementation of system.</li> <li>These are very useful when you want to make a design of some device that contains an input-output socket.</li> <li>Use of reusable components also helps in reducing overall development cost.</li> <li>It is very easy to modify and update implementation without causing any other side effects.</li> </ul> <p>Disadvantages :</p> <ul> <li>They cannot be used for designing Software like web pages, applications, etc.</li> <li>It also requires sponsoring equipment and actuators for each and every component.</li> </ul>"},{"location":"OS/cae1/#3-explain-batch-operating-system-in-detail","title":"3. Explain Batch Operating System in detail?","text":"<p>A batch operating system is a type of operating system that executes jobs in batches without user interaction. Here's a detailed explanation:</p> <ul> <li> <p>Definition: In a batch operating system, tasks or jobs are collected into batches and executed without direct user interaction. Each batch typically consists of multiple tasks, and the operating system executes these tasks in sequence.</p> </li> <li> <p>Job Submission: Users submit their jobs to the system through job control languages or batch queues. These jobs are stored in a job queue until they can be executed.</p> </li> <li> <p>Job Scheduling: The operating system scheduler selects jobs from the job queue based on priority, resource availability, and other criteria. It then allocates resources (such as CPU time and memory) to each job for execution.</p> </li> <li> <p>Job Execution: Once a job is selected for execution, the operating system loads the necessary program and data into memory and begins executing the job. The job continues until it completes or encounters an error.</p> </li> <li> <p>Job Management: The operating system manages the execution of multiple jobs simultaneously, ensuring that each job receives its fair share of resources. It may also handle job dependencies and priorities to optimize system performance.</p> </li> <li> <p>Output Processing: After a job completes, the operating system handles the output, which may include printing results or storing them in files. The output is typically directed to designated devices or storage locations.</p> </li> <li> <p>Examples: Early mainframe computers, such as the IBM 360 series, used batch operating systems like OS/360. These systems were commonly used for tasks such as payroll processing, accounting, and scientific computing.</p> </li> <li> <p>Advantages:</p> </li> <li>Efficient resource utilization: Batch processing allows the system to execute jobs continuously, maximizing CPU and I/O device utilization.</li> <li>Streamlined workflow: Users can submit multiple jobs for processing without waiting for each job to complete, improving overall system throughput.</li> <li> <p>Automated execution: Batch operating systems automate the execution of jobs, reducing the need for manual intervention and increasing system reliability.</p> </li> <li> <p>Disadvantages:</p> </li> <li>Lack of interactivity: Batch operating systems lack user interaction during job execution, making them unsuitable for tasks requiring real-time response or user input.</li> <li>Long turnaround times: Jobs may spend significant time waiting in the job queue before execution, leading to longer turnaround times for users.</li> <li>Limited flexibility: Batch processing is best suited for repetitive, non-interactive tasks, limiting the types of applications that can be run efficiently.</li> </ul>"},{"location":"OS/cae1/#4-explain-multi-programming-and-multitask-operating-system","title":"4. Explain Multi-programming and multitask operating system?","text":"<p>Multi-programming and multitasking are techniques used in operating systems to improve system efficiency and user productivity. Here's an explanation of each:</p> <ul> <li>Multi-programming:</li> <li>Definition: Multi-programming is a technique where multiple programs are loaded into memory simultaneously, allowing the CPU to switch between them for execution.</li> <li>Objective: The primary goal of multi-programming is to maximize CPU utilization by keeping the CPU busy with productive work at all times.</li> <li>Operation: In a multi-programmed system, the operating system maintains a pool of ready-to-execute programs in memory. When a program needs to perform I/O operations or encounters a blocking condition, the operating system switches to another program that can execute immediately.</li> <li>Advantages: </li> <li>Improved CPU utilization: Multi-programming ensures that the CPU is always busy executing programs, reducing idle time and improving overall system throughput.</li> <li>Faster response times: By allowing multiple programs to execute concurrently, multi-programming can reduce the response time for individual tasks.</li> <li>Enhanced system efficiency: Multi-programming enables efficient use of system resources, allowing multiple users or tasks to share the available computing resources     Examples: Mainframe operating systems like IBM z/OS and UNIX-like operating systems such as Linux and FreeBSD employ multi-programming techniques to manage multiple concurrent processes.</li> <li> <p>Multitasking:</p> </li> <li> <p>Definition: Multitasking is a broader concept that encompasses the simultaneous execution of multiple tasks or processes within a single computing environment.</p> </li> <li>Objective: The primary goal of multitasking is to improve user productivity by allowing users to perform multiple tasks concurrently without interference.</li> <li>Operation: In a multitasking operating system, the CPU switches rapidly between multiple tasks, giving the illusion of parallel execution. Each task is allocated a time slice or quantum during which it can execute before being preempted.</li> <li>Advantages:</li> <li>Increased productivity: Multitasking allows users to perform multiple tasks simultaneously, such as browsing the web while listening to music or editing documents.</li> <li>Enhanced responsiveness: Users can switch between tasks seamlessly, leading to a more responsive computing experience.</li> <li>Efficient resource utilization: Multitasking optimizes resource usage by allowing multiple tasks to share system resources such as CPU time and memory.</li> <li>Examples: Modern desktop operating systems like Windows, macOS, and Linux support multitasking, enabling users to run multiple applications concurrently on their computers. I summary, multi-programming focuses on maximizing CPU utilization by keeping the CPU busy with productive work, while multitasking allows users to perform multiple tasks simultaneously within a single computing environment, improving user productivity and system responsiveness.</li> </ul>"},{"location":"OS/cae1/#5-explain-distributed-os-and-real-time-os","title":"5.  Explain distributed OS and Real-time OS?","text":"<ul> <li> <p>Distributed Operating System (DOS):</p> </li> <li> <p>Definition: A distributed operating system is a type of operating system that manages resources and coordinates communication between multiple independent computers interconnected via a network.</p> </li> <li>Objective: The primary goal of a distributed operating system is to provide a unified computing environment across a network of computers, allowing users and applications to access resources transparently.</li> <li>Features:<ul> <li>Transparency: Distributed operating systems hide the complexities of network communication and resource management from users and applications, providing a seamless computing experience.</li> <li>Scalability: Distributed operating systems can scale horizontally by adding more nodes to the network, allowing for increased computing power and resource availability.</li> <li>Fault tolerance: Distributed operating systems are designed to withstand failures in individual nodes or network components, ensuring continued operation and data integrity.</li> </ul> </li> <li>Examples: Distributed operating systems include Google's Kubernetes, Microsoft's Windows Distributed File System (DFS), and the Apache Hadoop distributed file system (HDFS).</li> <li> <p>Real-time Operating System (RTOS):</p> </li> <li> <p>Definition: A real-time operating system is a type of operating system that guarantees a deterministic response time for processing tasks, ensuring that critical tasks are completed within predefined deadlines.</p> </li> <li>Objective: The primary goal of a real-time operating system is to provide timely and predictable responses to external events or stimuli, making it suitable for applications with stringent timing requirements.</li> <li>Characteristics:<ul> <li>Determinism: Real-time operating systems prioritize tasks based on their deadlines, ensuring that critical tasks are executed within specified time constraints.</li> <li>Low latency: Real-time operating systems minimize processing delays and overhead, allowing tasks to respond quickly to external events.</li> <li>Predictability: Real-time operating systems provide predictable performance under varying workloads and system conditions, enabling accurate timing analysis and scheduling.</li> </ul> </li> <li>Types:<ul> <li>Hard real-time: In hard real-time systems, missing task deadlines can lead to system failure or unacceptable consequences. Examples include control systems for aircraft and medical devices.</li> <li>Soft real-time: In soft real-time systems, missing task deadlines may degrade system performance but do not result in catastrophic failure. Examples include multimedia streaming and video games.</li> </ul> </li> <li>Examples: Real-time operating systems include VxWorks, FreeRTOS, and QNX Neutrino, which are commonly used in embedded systems, industrial automation, and mission-critical applications. In ummary, distributed operating systems manage resources and coordinate communication between multiple computers interconnected via a network, while real-time operating systems guarantee deterministic response times for processing tasks, making them suitable for applications with stringent timing requirements.</li> </ul>"},{"location":"OS/cae1/#6-draw-and-explain-working-of-system-call","title":"6. Draw and explain working of System call?","text":"<p>System Call</p> <p>A system call is a method for a computer program to request a service from the kernel of the  operating system  on which it is running. A system call is a method of interacting with the operating system via programs. A system call is a request from computer software to an operating system's kernel.</p> <p>The  Application Program Interface (API)  connects the operating system's functions to user programs. It acts as a link between the operating system and a process, allowing user-level programs to request operating system services. The kernel system can only be accessed using system calls. System calls are required for any programs that use resources.</p> <p>There are various examples of Windows and Unix system calls. These are as listed below in the table:</p> Process Windows Unix Process Control CreateProcess() Fork() ExitProcess() Exit() WaitForSingleObject() Wait() File Manipulation CreateFile() Open() ReadFile() Read() WriteFile() Write() CloseHandle() Close() Device Management SetConsoleMode() Ioctl() ReadConsole() Read() WriteConsole() Write() Information Maintenance GetCurrentProcessID() Getpid() SetTimer() Alarm() Sleep() Sleep() Communication CreatePipe() Pipe() CreateFileMapping() Shmget() MapViewOfFile() Mmap() Protection SetFileSecurity() Chmod() InitializeSecurityDescriptor() Umask() SetSecurityDescriptorgroup() Chown() <p>Types of System Calls</p> <p>Process Control Process control is the system call that is used to direct the processes. Some process control examples include creating, load, abort, end, execute, process, terminate the process, etc.</p> <p>File Management File management is a system call that is used to handle the files. Some file management examples include creating files, delete files, open, close, read, write, etc.</p> <p>Device Management Device management is a system call that is used to deal with devices. Some examples of device management include read, device, write, get device attributes, release device, etc.</p> <p>Information Maintenance Information maintenance is a system call that is used to maintain information. There are some examples of information maintenance, including getting system data, set time or date, get time or date, set system data, etc.</p> <p>Communication Communication is a system call that is used for communication. There are some examples of communication, including create, delete communication connections, send, receive messages, etc.</p>"},{"location":"OS/cae1/#7-list-out-and-explain-types-of-system-calls","title":"7. List out and explain types of system calls?","text":"<p>System calls are functions provided by the operating system that allow applications to request services from the operating system's kernel. There are several types of system calls, including:</p> <ol> <li>Process Control:</li> <li> <p>These system calls are used to manage processes, such as creating or terminating processes, waiting for process termination, and getting or setting process attributes.</p> </li> <li> <p>File Management:</p> </li> <li> <p>These system calls are used to manage files and directories, including opening, closing, reading from, writing to, and manipulating file attributes.</p> </li> <li> <p>Device Management:</p> </li> <li> <p>These system calls control devices connected to the system, such as reading from or writing to devices, requesting device status, or controlling device operations.</p> </li> <li> <p>Information Maintenance:</p> </li> <li> <p>These system calls provide information about the system or processes, such as getting or setting the system time, querying system or process attributes, or getting system configuration information.</p> </li> <li> <p>Communication:</p> </li> <li> <p>These system calls allow processes to communicate with each other, either within the same system (interprocess communication) or between different systems (network communication).</p> </li> <li> <p>Memory Management:</p> </li> <li>These system calls control memory allocation and deallocation, allowing processes to allocate or release memory, map files into memory, or manipulate memory protection settings.</li> </ol> <p>Each type of system call serves a specific purpose and provides a standardized interface for applications to interact with the operating system kernel, abstracting away low-level details and ensuring portability and security.</p>"},{"location":"OS/cae1/#8-explain-user-mode-and-kernel-mode","title":"8. Explain user mode and kernel mode?","text":"<p>User Mode: - User mode is the mode in which most applications run. In this mode, applications have limited access to system resources and cannot directly execute privileged instructions or access kernel memory. - User mode provides a safe environment for applications to run without risking the stability and security of the system. Applications typically interact with the operating system through system calls when they need access to privileged resources or services.</p> <p>Kernel Mode: - Kernel mode is the privileged mode in which the operating system kernel runs. In this mode, the kernel has full access to system resources and can execute privileged instructions, access hardware devices, and manage system resources directly. - Kernel mode provides the necessary privileges for the operating system to perform critical system functions, such as process management, memory management, and device I/O operations.</p> <p>Key Differences: - Access to Resources: User mode applications have restricted access to system resources and must request access through system calls, while the kernel has unrestricted access to all system resources. - Privileged Instructions: User mode cannot execute privileged instructions directly, while kernel mode can execute privileged instructions that control hardware and system behavior. - Protection: User mode provides isolation and protection between applications, preventing one application from affecting the stability or security of other applications or the system, while kernel mode has full control over system resources and can enforce protection mechanisms.</p>"},{"location":"OS/cae1/#9-compare-user-mode-and-system-mode","title":"9. Compare user mode and system mode?","text":"<p>User Mode: - User mode is the mode in which most applications run. - Applications in user mode have limited access to system resources. - User mode provides a safe environment for applications to run without risking the stability and security of the system. - Applications interact with the operating system through system calls to access privileged resources or services. - User mode provides isolation between applications, preventing one application from affecting the stability or security of other applications or the system.</p> <p>System Mode (Kernel Mode): - System mode, also known as kernel mode, is the privileged mode in which the operating system kernel runs. - The kernel has full access to system resources and can execute privileged instructions, access hardware devices, and manage system resources directly. - Kernel mode provides the necessary privileges for the operating system to perform critical system functions, such as process management, memory management, and device I/O operations. - The kernel enforces protection mechanisms to ensure system stability and security, controlling access to system resources and preventing unauthorized actions. - System mode is responsible for managing system-wide resources and providing essential services to user mode applications.</p> <p>In summary, user mode is the mode in which applications run with limited access to system resources, while system mode (kernel mode) is the privileged mode in which the operating system kernel runs, with full access to system resources and control over system behavior.</p>"},{"location":"OS/cae1/#10-draw-and-explain-the-process-life-cycle-or-process-state-diagram","title":"10. Draw and explain the process life cycle or process state diagram ?","text":"<p>Process States State Diagram</p> <p></p> <p>The process, from its creation to completion, passes through various states. The minimum number of states is five.</p> <p>The names of the states are not standardized although the process may be in one of the following states during execution.</p> <ol> <li> <p>New A program which is going to be picked up by the OS into the main memory is called a new process.</p> </li> <li> <p>Ready Whenever a process is created, it directly enters in the ready state, in which, it waits for the CPU to be assigned. The OS picks the new processes from the secondary memory and put all of them in the main memory.</p> </li> </ol> <p>The processes which are ready for the execution and reside in the main memory are called ready state processes. There can be many processes present in the ready state.</p> <ol> <li> <p>Running One of the processes from the ready state will be chosen by the OS depending upon the scheduling algorithm. Hence, if we have only one CPU in our system, the number of running processes for a particular time will always be one. If we have n processors in the system then we can have n processes running simultaneously.</p> </li> <li> <p>Block or wait From the Running state, a process can make the transition to the block or wait state depending upon the scheduling algorithm or the intrinsic behavior of the process.</p> </li> </ol> <p>When a process waits for a certain resource to be assigned or for the input from the user then the OS move this process to the block or wait state and assigns the CPU to the other processes.</p> <ol> <li> <p>Completion or termination When a process finishes its execution, it comes in the termination state. All the context of the process (Process Control Block) will also be deleted the process will be terminated by the Operating system.</p> </li> <li> <p>Suspend ready A process in the ready state, which is moved to secondary memory from the main memory due to lack of the resources (mainly primary memory) is called in the suspend ready state.</p> </li> </ol> <p>If the main memory is full and a higher priority process comes for the execution then the OS have to make the room for the process in the main memory by throwing the lower priority process out into the secondary memory. The suspend ready processes remain in the secondary memory until the main memory gets available.</p> <ol> <li>Suspend wait Instead of removing the process from the ready queue, it's better to remove the blocked process which is waiting for some resources in the main memory. Since it is already waiting for some resource to get available hence it is better if it waits in the secondary memory and make room for the higher priority process. These processes complete their execution once the main memory gets available and their wait is finished.</li> </ol>"},{"location":"OS/cae1/#11-draw-process-control-block-and-explain-in-detail","title":"11. Draw process control block and explain in detail ?","text":"<p>Process Control Block is a data structure that contains information of the process related to it. The process control block is also known as a task control block, entry of the process table, etc.</p> <p>It is very important for process management as the data structuring for processes is done in terms of the PCB. It also defines the current state of the operating system.</p> <p>Structure of the Process Control Block The process control stores many data items that are needed for efficient process management. Some of these data items are explained with the help of the given diagram \u2212</p> <p></p> <p>The following are the data items \u2212</p> <p>Process State This specifies the process state i.e. new, ready, running, waiting or terminated.</p> <p>Process Number This shows the number of the particular process.</p> <p>Program Counter This contains the address of the next instruction that needs to be executed in the process.</p> <p>Registers This specifies the registers that are used by the process. They may include accumulators, index registers, stack pointers, general purpose registers etc.</p> <p>List of Open Files These are the different files that are associated with the process</p> <p>CPU Scheduling Information The process priority, pointers to scheduling queues etc. is the CPU scheduling information that is contained in the PCB. This may also include any other scheduling parameters.</p> <p>Memory Management Information The memory management information includes the page tables or the segment tables depending on the memory system used. It also contains the value of the base registers, limit registers etc.</p> <p>I/O Status Information This information includes the list of I/O devices used by the process, the list of files etc.</p> <p>Accounting information The time limits, account numbers, amount of CPU used, process numbers etc. are all a part of the PCB accounting information.</p>"},{"location":"OS/cae1/#12-explain-process-switching","title":"12. Explain process Switching?","text":"<p>Process switching is the mechanism by which the operating system switches the CPU from one process to another. This switching allows multiple processes to share the CPU's execution time, enabling multitasking and concurrent execution of multiple programs. Here's how process switching works:</p> <ol> <li> <p>Interrupt Handling: Process switching typically begins with an interrupt or an exception. Interrupts can be generated by hardware devices, such as a timer interrupt indicating the end of a time slice, or by software, such as a system call requesting a service from the operating system.</p> </li> <li> <p>Context Switching: When an interrupt occurs, the CPU saves the context of the currently executing process, including its program counter, register values, and other relevant state information, onto the process's stack or control block.</p> </li> <li> <p>Scheduling: The operating system's scheduler selects the next process to execute based on scheduling algorithms and policies. This decision may consider factors such as process priority, CPU burst duration, and system load.</p> </li> <li> <p>Loading New Process: Once the next process is selected, the operating system loads the saved context of the selected process from its control block or process table into the CPU registers, preparing it for execution.</p> </li> <li> <p>Execution: The CPU resumes execution of the selected process from the point where it was interrupted, allowing the process to continue executing until it completes its quantum, encounters a blocking condition, or is preempted by another process.</p> </li> <li> <p>Repeat: The process of switching between processes continues as long as there are runnable processes in the system and the CPU scheduler determines that a context switch is necessary.</p> </li> </ol> <p>Process switching is a fundamental operation in multitasking operating systems, enabling efficient sharing of CPU resources among multiple processes and providing users with the illusion of concurrent execution of multiple programs.</p>"},{"location":"OS/cae1/#13-draw-queuing-diagram-and-explain-it","title":"13. Draw Queuing diagram and explain it?","text":"<p>Process Queues The Operating system manages various types of queues for each of the process states. The PCB related to the process is also stored in the queue of the same state. If the Process is moved from one state to another state then its PCB is also unlinked from the corresponding queue and added to the other state queue in which the transition is made.</p> <p></p> <p>There are the following queues maintained by the Operating system.</p> <ol> <li> <p>Job Queue In starting, all the processes get stored in the job queue. It is maintained in the secondary memory. The long term scheduler (Job scheduler) picks some of the jobs and put them in the primary memory.</p> </li> <li> <p>Ready Queue Ready queue is maintained in primary memory. The short term scheduler picks the job from the ready queue and dispatch to the CPU for the execution.</p> </li> <li> <p>Waiting Queue When the process needs some IO operation in order to complete its execution, OS changes the state of the process from running to waiting. The context (PCB) associated with the process gets stored on the waiting queue which will be used by the Processor when the process finishes the IO.</p> </li> </ol>"},{"location":"OS/cae1/#14-draw-and-explain-mid-term-scheduler","title":"14.  Draw and explain mid-term scheduler?","text":"<p>The long-term execution of processes in a computer system is managed by a medium-term scheduler, also referred to as a mid-term scheduler. Based on a set of predetermined criteria and priorities, this kind of scheduler decides which processes should be executed next.</p> <p>Typically, processes that are blocked or waiting must be managed by the medium-term scheduler. These processes are not running right now, but they are still awaiting the occurrence of an event in order to start running. Which of these blocked processes should be unblocked and allowed to continue running is up to the medium-term scheduler to decide.</p> <p>The system\u2019s overall resource utilization must be managed via the medium-term scheduler. This entails keeping track of how much memory, CPU, and other resources are being used by the various processes and modifying resource allocation as needed.</p> <p>The operating system kernel often houses the medium-term scheduler\u2019s implementation. It is in charge of controlling the system\u2019s overall resource utilization as well as the scheduling of programs that are stalled or waiting.</p> <p></p> <p>Responsibilities of Medium Term Scheduler The medium-term scheduler\u2019s responsibility for ensuring equitable resource distribution among all processes is one of its main responsibilities. This is necessary to guarantee that every process has an equal chance to run and prevent any one process from using up all of the system resources. The medium-term scheduler\u2019s responsibility for ensuring effective process execution is another crucial task. This may entail modifying the priority of processes based on their present condition or resource utilization, or modifying the resource distribution to various processes based on their present requirements. So, the operating system\u2019s medium-term scheduler controls the scheduling and resource distribution of processes that are blocked or waiting. It aids in ensuring that resources are distributed equally throughout all of the processes and that they are carried out effectively.</p>"},{"location":"OS/cae1/#15-compare-process-and-program","title":"15. Compare process and program?","text":"Parameters Program Process Definition A Program is an organized set of operations designed to accomplish a specific objective. A Process is the active execution of a program. Resource Management A Program uses only its memory for storage. A Process requires substantial resources. Nature A program is inherently passive and will not function until executed. A process is an instance of a program being executed. Overheads A Program does not incur significant overhead. A Process incurs substantial overhead. Creation A new program can be created independently, without the need to duplicate an existing one. The creation of a new process necessitates the duplication of the parent process. Lifespan A Program has a relatively long lifespan as it is stored in memory and can only be deleted manually. A Process has a short lifespan, as it ends once the task is completed. Resources Required A Program does not require resources as it is saved on disk files. A Process uses resources such as memory address, I/O, disk, CPU, printer, etc. Entity Type A Program is a static or passive entity found on a computer's secondary memory. A Process is a dynamic or active entity found on a computer's primary memory. Control Block There is no control block for Programs. A Process has its own control block, known as the Process Control Block."},{"location":"OS/cae1/#16-compare-process-and-thread","title":"16. Compare process and thread?","text":"S.NO Process Description Thread Description 1. Process means any program is in execution. Thread means a segment of a process. 2. The process takes more time to terminate. The thread takes less time to terminate. 3. It takes more time for creation. It takes less time for creation. 4. It also takes more time for context switching. It takes less time for context switching. 5. The process is less efficient in terms of communication. Thread is more efficient in terms of communication. 6. Multiprogramming holds the concepts of multi-process. We don\u2019t need multi programs in action for multiple threads because a single process consists of multiple threads. 7. The process is isolated. Threads share memory. 8. The process is called the heavyweight process. A Thread is lightweight as each thread in a process shares code, data, and resources. 9. Process switching uses an interface in an operating system. Thread switching does not require calling an operating system and causes an interrupt to the kernel. 10. If one process is blocked then it will not affect the execution of other processes. If a user-level thread is blocked, then all other user-level threads are blocked. 11. The process has its own Process Control Block, Stack, and Address Space. Thread has Parents\u2019 PCB, its own Thread Control Block, and Stack and common Address space. 12. Changes to the parent process do not affect child processes. Since all threads of the same process share address space and other resources so any changes to the main thread may affect the behavior of the other threads of the process. 13. A system call is involved in it. No system call is involved, it is created using APIs. 14. The process does not share data with each other. Threads share data with each other."},{"location":"OS/cae1/#17draw-and-explain-working-of-single-and-multi-threaded-model","title":"17.Draw and explain working of single and multi-threaded model?","text":"<p>A thread is a light weight process which is similar to a process where every process can have one or more threads. Each thread contains a Stack and a Thread Control Block. There are four basic thread models : </p> <ol> <li> <p>User Level Single Thread Model : </p> <ul> <li>Each process contains a single thread.</li> <li>Single process is itself a single thread.</li> <li>process table contains an entry for every process by maintaining its PCB.</li> </ul> <p></p> </li> <li> <p>User Level Multi Thread Model : </p> <ul> <li>Each process contains multiple threads.</li> <li>All threads of the process are scheduled by a thread library at user level.</li> <li>Thread switching can be done faster than process switching.</li> <li>Thread switching is independent of operating system which can be done within a process.</li> <li>Blocking one thread makes blocking of entire process.</li> <li>Thread table maintains Thread Control Block of each thread of a process.</li> <li>Thread scheduling happens within a process and not known to Kernel.</li> </ul> <p></p> </li> <li> <p>Kernel Level Single Thread Model : </p> <ul> <li>Each process contains a single thread.</li> <li>Thread used here is kernel level thread.</li> <li>Process table works as thread table.</li> </ul> <p></p> </li> <li> <p>Kernel Level Multi Thread Model : </p> <ul> <li>Thread scheduling is done at kernel level.</li> <li>Fine grain scheduling is done on a thread basis.</li> <li>If a thread blocks, another thread can be scheduled without blocking the whole process.</li> <li>Thread scheduling at Kernel process is slower compared to user level thread scheduling.</li> <li>Thread switching involves switch.</li> </ul> <p></p> </li> </ol> <p>Sure, let's address each question one by one:</p>"},{"location":"OS/cae1/#18-list-out-and-explain-multi-threaded-model","title":"18. List out and explain multi-threaded model?","text":"<p>Multi-threaded Model:</p> <ul> <li>In a multi-threaded model, a process is divided into multiple threads of execution, each capable of running independently.</li> <li>Threads within the same process share the same memory space, allowing them to access shared data and resources directly.</li> <li>Multi-threading enables concurrent execution of multiple tasks within a single process, improving efficiency and responsiveness.</li> <li>Threads can communicate with each other through shared memory or synchronization mechanisms provided by the operating system.</li> </ul> <p>Advantages of Multi-threaded Model:</p> <ol> <li>Improved Responsiveness: Multi-threading allows applications to remain responsive even while performing CPU-intensive tasks by utilizing multiple threads.</li> <li>Enhanced Resource Utilization: Threads within the same process can share resources efficiently, reducing overhead and improving overall system performance.</li> <li>Simplified Programming Model: Multi-threading simplifies programming by allowing developers to parallelize tasks within a single process, avoiding the complexities of inter-process communication.</li> <li>Enhanced Scalability: Multi-threading enables applications to scale across multiple CPU cores, leveraging parallelism to improve throughput and scalability.</li> </ol> <p>Example:</p> <p>Consider a web server application. In a multi-threaded model, the server can create a separate thread for each incoming client connection. Each thread handles the client's requests independently, allowing the server to serve multiple clients concurrently without blocking other clients.</p>"},{"location":"OS/cae1/#19-explain-fcfs-and-sjf-cpu-scheduling-algorithm-with-example","title":"19. Explain FCFS and SJF CPU scheduling algorithm with example?","text":"<p>FCFS (First-Come, First-Served):</p> <ul> <li>In FCFS scheduling, processes are executed in the order they arrive in the ready queue.</li> <li>It is a non-preemptive scheduling algorithm, meaning once a process starts executing, it continues until it completes or enters the waiting state.</li> <li>Example:</li> <li>Consider three processes arriving in the order P1, P2, and P3, with burst times of 10, 5, and 8 milliseconds, respectively.</li> <li>The scheduling order would be P1, P2, and P3, and the average waiting time would be ((0 + 10) + (10 + 5) + (10 + 5 + 8)) / 3 = 32/3 milliseconds.</li> </ul> <p>SJF (Shortest Job First):</p> <ul> <li>In SJF scheduling, the process with the shortest burst time is selected for execution next.</li> <li>It is a non-preemptive or preemptive scheduling algorithm, depending on whether new shorter jobs can preempt currently running jobs.</li> <li>Example:</li> <li>Consider three processes with burst times of 6, 3, and 8 milliseconds, respectively.</li> <li>The scheduling order would be P2, P1, and P3, and the average waiting time would be ((0 + 3) + (3 + 6) + (3 + 6 + 8)) / 3 = 25/3 milliseconds.</li> </ul>"},{"location":"OS/cae1/#20-solve-fcfs-and-sjf-cpu-scheduling-algorithm-for-given-example","title":"20. Solve FCFS and SJF CPU scheduling algorithm for given example?","text":"<p>FCFS Example:</p> <ul> <li>Given Processes: P1, P2, P3</li> <li>Burst Times: 10, 5, 8 milliseconds respectively</li> <li>FCFS Scheduling:</li> <li>P1 starts at time 0, completes at time 10</li> <li>P2 starts at time 10, completes at time 15</li> <li>P3 starts at time 15, completes at time 23</li> <li>Average Waiting Time: ((0 + 10) + (10 + 5) + (10 + 5 + 8)) / 3 = 32/3 milliseconds.</li> </ul> <p>SJF Example:</p> <ul> <li>Given Processes: P1, P2, P3</li> <li>Burst Times: 6, 3, 8 milliseconds respectively</li> <li>SJF Scheduling:</li> <li>P2 starts at time 0, completes at time 3</li> <li>P1 starts at time 3, completes at time 9</li> <li>P3 starts at time 9, completes at time 17</li> <li>Average Waiting Time: ((0 + 3) + (3 + 6) + (3 + 6 + 8)) / 3 = 25/3 milliseconds.</li> </ul>"},{"location":"OS/cae1/#21-explain-priority-and-round-robin-cpu-scheduling-algorithm-with-example","title":"21. Explain Priority and Round Robin CPU scheduling algorithm with example?","text":"<p>Priority Scheduling:</p> <ul> <li>Priority scheduling assigns priorities to processes and selects the process with the highest priority for execution.</li> <li>It can be either preemptive or non-preemptive, where higher priority processes can preempt lower priority ones.</li> <li>Example:</li> <li>Consider three processes with priorities P1 (high), P2 (medium), and P3 (low).</li> <li>The scheduling order would be P1, P2, and P3, assuming P1 has the highest priority.</li> </ul> <p>Round Robin Scheduling:</p> <ul> <li>Round Robin scheduling allocates a fixed time slice (quantum) to each process in a circular manner.</li> <li>If a process doesn't complete within its time slice, it's preempted and placed back in the ready queue.</li> <li>Example:</li> <li>Consider three processes with time slices of 10 milliseconds each.</li> <li>Each process gets 10 milliseconds of CPU time before being preempted and placed back in the ready queue.</li> </ul>"},{"location":"OS/cae2/","title":"COMING SOON!","text":""},{"location":"OS/cae3/","title":"COMING SOON!","text":""},{"location":"TNM/","title":"TRANSFORM NUMERICAL METHOD","text":"Unit Topic Duration Unit I Laplace Transform 8 Laplace transform definition and their properties, transform of derivatives and integrals, evaluation of integrals by Laplace Transform, Laplace transforms of periodic function, Unit step function, Unit Impulse function, Inverse Laplace Transform and its properties, convolution theorem, applications of Laplace transforms to solve ordinary differential equations Unit II Fourier Transform 8 Complex exponential form of Fourier series, Fourier integral theorem, Fourier Sine &amp; Cosine integrals, Fourier transform, Fourier Sine and Cosine transforms and their inverses, Properties of Fourier Transform, Discrete Fourier Transform. Applications of Transforms to boundary value Problems Unit III Z-Transform 8 Definition, properties of Z- Transforms, Inverse Z- Transform and relation between Z transform and Laplace Transform. Convolution Theorem, Application of Z-Transform to solve difference equations with constant coefficients Unit IV Numerical Solution of Equations 8 Numerical solutions of algebraic and transcendental equations. Iteration method, Bisection method, Regula-Falsi method, Newton-Raphson\u2019s method and their convergences, solution of system of linear equations by Gauss elimination method, gauss Jordan method, gauss Seidel iteration method Unit V Numerical Solution of Ordinary Differential Equations 8 Picard\u2019s method, Taylor series method, Euler\u2019s method, Modified Euler\u2019s method, Range\u2019s method, Runge-Kutta fourth order method, Predicator\u2013corrector methods, Milne\u2019s method. Solution of Simultaneous first order and higher order differential equations"},{"location":"TNM/UNIT_1/","title":"Unit1","text":"<p>Handwritten Notes Provided By Shrinivas Narhare</p>"},{"location":"TNM/UNIT_2/","title":"Unit2","text":"<p>Handwritten Notes Provided By Shrinivas Narhare</p>"},{"location":"TNM/UNIT_3/","title":"Unit3","text":"<p>Handwritten Notes Provided By Shrinivas Narhare</p>"},{"location":"TNM/UNIT_4/","title":"Unit4","text":"<p>Handwritten Notes Provided By Shrinivas Narhare</p>"},{"location":"TNM/UNIT_5/","title":"Unit5","text":"<p>Handwritten Notes Provided By Shrinivas Narhare</p>"},{"location":"TNM/cae1/","title":"Question bank","text":""},{"location":"TNM/cae2/","title":"COMING SOON!","text":""},{"location":"TNM/cae3/","title":"COMING SOON!","text":""}]}